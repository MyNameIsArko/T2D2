{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T09:46:31.194271Z",
     "start_time": "2024-05-14T09:46:28.404470Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import threading\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Tuple\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "import cv2\n",
    "# from tensorboardX import SummaryWriter\n",
    "# from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7809a363e30f2a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_name = 'MsPacman-v5'\n",
    "obs_shape = (1, 84, 84)\n",
    "\n",
    "lr = 1e-4\n",
    "eps = 1e-3\n",
    "grad_norm = 40\n",
    "batch_size = 64\n",
    "learning_starts = 50000\n",
    "save_interval = 500\n",
    "target_net_update_interval = 2000\n",
    "gamma = 0.997\n",
    "prio_exponent = 0.9\n",
    "importance_sampling_exponent = 0.6\n",
    "\n",
    "training_steps = 100000\n",
    "buffer_capacity = 1000000\n",
    "max_episode_steps = 27000\n",
    "actor_update_interval = 400\n",
    "block_length = 400 \n",
    "\n",
    "num_actors = 8\n",
    "base_eps = 0.4\n",
    "alpha = 7\n",
    "log_interval = 10\n",
    "\n",
    "# sequence setting\n",
    "burn_in_steps = 40\n",
    "learning_steps = 40\n",
    "forward_steps = 5\n",
    "seq_len = burn_in_steps + learning_steps + forward_steps\n",
    "\n",
    "# network setting\n",
    "hidden_dim = 512\n",
    "\n",
    "render = False\n",
    "save_plot = True\n",
    "test_epsilon = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6457872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoopResetEnv(gym.Wrapper):\n",
    "    def __init__(self, env, noop_max=30):\n",
    "        \"\"\"start the game with no-op actions to provide random starting positions\n",
    "        No-op is assumed to be action 0.\n",
    "        \"\"\"\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        self.noop_max = noop_max\n",
    "        self.override_num_noops = None\n",
    "        self.noop_action = 0\n",
    "        assert env.unwrapped.get_action_meanings()[0] == 'NOOP'\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        \"\"\" Do no-op action for a number of steps in [1, noop_max].\"\"\"\n",
    "        self.env.reset(**kwargs)\n",
    "        if self.override_num_noops is not None:\n",
    "            noops = self.override_num_noops\n",
    "        else:\n",
    "            noops = np.random.randint(1, self.noop_max + 1) #pylint: disable=E1101\n",
    "        assert noops > 0\n",
    "        obs = None\n",
    "        for _ in range(noops):\n",
    "            obs, _, terminated, truncated, _ = self.env.step(self.noop_action)\n",
    "            if terminated or truncated:\n",
    "                obs = self.env.reset(**kwargs)\n",
    "        return obs, {}\n",
    "\n",
    "    def step(self, action):\n",
    "        return self.env.step(action)\n",
    "\n",
    "\n",
    "\n",
    "class WarpFrame(gym.ObservationWrapper):\n",
    "    def __init__(self, env, width=84, height=84):\n",
    "        \"\"\"\n",
    "        Warp frames to 84x84 as done in the Nature paper and later work.\n",
    "        \"\"\"\n",
    "        super().__init__(env)\n",
    "        self._width = width\n",
    "        self._height = height\n",
    "\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=0,\n",
    "            high=255,\n",
    "            shape=(1, self._height, self._width),\n",
    "            dtype=np.uint8,\n",
    "        )\n",
    "\n",
    "    def observation(self, obs):\n",
    "\n",
    "        obs = cv2.resize(\n",
    "            obs, (self._width, self._height), interpolation=cv2.INTER_AREA\n",
    "        )\n",
    "\n",
    "        obs = np.expand_dims(obs, 0)\n",
    "\n",
    "        return obs\n",
    "\n",
    "\n",
    "def create_env(env_name=game_name, noop_start=True, render=False):\n",
    "\n",
    "    env = gym.make(f'ALE/{env_name}', obs_type='grayscale', frameskip=4, repeat_action_probability=0, full_action_space=False, render_mode='human' if render else 'rgb_array')\n",
    "\n",
    "    env = WarpFrame(env)\n",
    "    if noop_start:\n",
    "        env = NoopResetEnv(env)\n",
    "\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36cbf333688b51ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriorityTree:\n",
    "    def __init__(self, capacity, prio_exponent, is_exponent):\n",
    "        self.num_layers = 1\n",
    "        while capacity > 2**(self.num_layers - 1):\n",
    "            self.num_layers += 1\n",
    "        \n",
    "        self.ptree = np.zeros(2**self.num_layers - 1, dtype=np.float64)\n",
    "        \n",
    "        self.prio_exponent = prio_exponent\n",
    "        self.is_exponent = is_exponent\n",
    "    \n",
    "    def update(self, idxes: np.ndarray, td_error: np.ndarray) -> None:\n",
    "        priorities = td_error ** self.prio_exponent\n",
    "        \n",
    "        idxes = idxes + 2**(self.num_layers - 1) - 1\n",
    "        self.ptree[idxes] = priorities\n",
    "        \n",
    "        for _ in range(self.num_layers - 1):\n",
    "            idxes = (idxes - 1) // 2\n",
    "            idxes = np.unique(idxes)\n",
    "            self.ptree[idxes] = self.ptree[2 * idxes + 1] + self.ptree[2 * idxes + 2]\n",
    "    \n",
    "    def sample(self, num_samples: int) -> tuple[np.ndarray, np.ndarray]:\n",
    "        p_sum = self.ptree[0]\n",
    "        interval = p_sum / num_samples\n",
    "        \n",
    "        prefixsums = np.arange(0, p_sum, interval, dtype=np.float64) + np.random.uniform(0, interval, num_samples)\n",
    "        \n",
    "        idxes = np.zeros(num_samples, dtype=np.int64)\n",
    "        for _ in range(self.num_layers-1):\n",
    "            nodes = self.ptree[2 * idxes + 1]\n",
    "            idxes = np.where(prefixsums < nodes, 2 * idxes + 1, 2 * idxes + 2)\n",
    "            prefixsums = np.where(idxes%2 == 0, prefixsums - self.ptree[idxes-1], prefixsums)\n",
    "        \n",
    "        priorities = self.ptree[idxes]\n",
    "        min_p = np.min(priorities)\n",
    "        is_weigths = np.power(priorities/min_p, -self.is_exponent)\n",
    "        \n",
    "        idxes -= 2**(self.num_layers - 1) - 1\n",
    "        \n",
    "        return idxes, is_weigths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d92553642b4f78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Block:\n",
    "    obs: np.array\n",
    "    last_action: np.array\n",
    "    last_reward: np.array\n",
    "    action: np.array\n",
    "    n_step_reward: np.array\n",
    "    gamma: np.array\n",
    "    hidden: np.array\n",
    "    num_sequences: int\n",
    "    burn_in_steps: np.array\n",
    "    learning_steps: np.array\n",
    "    forward_steps: np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6533684a57fe978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, sample_queue_list, batch_queue, priority_queue, alpha=prio_exponent, beta=importance_sampling_exponent):\n",
    "        self.buffer_capacity = buffer_capacity\n",
    "        self.sequence_len = learning_steps\n",
    "        self.num_sequences = buffer_capacity // self.sequence_len\n",
    "        self.block_len = block_length\n",
    "        self.num_blocks = self.buffer_capacity // self.block_len\n",
    "        self.seq_pre_block = self.block_len // self.sequence_len\n",
    "        \n",
    "        self.block_ptr = 0\n",
    "        \n",
    "        self.priority_tree = PriorityTree(self.num_sequences, alpha, beta)\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.env_steps = 0\n",
    "        \n",
    "        self.num_episodes = 0\n",
    "        self.episode_reward = 0\n",
    "        \n",
    "        self.training_steps = 0\n",
    "        self.last_training_steps = 0\n",
    "        self.sum_loss = 0\n",
    "        \n",
    "        self.lock = threading.Lock()\n",
    "        \n",
    "        self.size = 0\n",
    "        self.last_size = 0\n",
    "        \n",
    "        self.buffer = [None] * self.num_blocks\n",
    "        \n",
    "        self.sample_queue_list = sample_queue_list\n",
    "        self.batch_queue = batch_queue\n",
    "        self.priority_queue = priority_queue\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def run(self):\n",
    "        background_thread = threading.Thread(target=self.add_data, daemon=True)\n",
    "        background_thread.start()\n",
    "        \n",
    "        background_thread = threading.Thread(target=self.prepare_data, daemon=True)\n",
    "        background_thread.start()\n",
    "        \n",
    "        background_thread = threading.Thread(target=self.update_data, daemon=True)\n",
    "        background_thread.start()\n",
    "\n",
    "        writer_thread = threading.Thread(target=self.write_stats, daemon=True)\n",
    "        writer_thread.start()\n",
    "        \n",
    "        while True:\n",
    "            print(f'Buffer size: {self.size}')\n",
    "            print(f'Buffer update speed: {(self.size - self.last_size) / log_interval}/s')\n",
    "            self.last_size = self.size\n",
    "            print(f'Number of environment steps: {self.env_steps}')\n",
    "            if self.num_episodes != 0:\n",
    "                print(f'Average episode return: {self.episode_reward / self.num_episodes:.4f}')\n",
    "                self.episode_reward = 0\n",
    "                self.num_episodes = 0\n",
    "            print(f'Number of training steps: {self.training_steps}')\n",
    "            print(f'Training speed: {(self.training_steps - self.last_training_steps) / log_interval}/s')\n",
    "            if self.training_steps != self.last_training_steps:\n",
    "                print(f'Loss: {self.sum_loss/(self.training_steps-self.last_training_steps):.4f}')\n",
    "                self.last_training_steps = self.training_steps\n",
    "                self.sum_loss = 0\n",
    "            self.last_env_steps = self.env_steps\n",
    "            print()\n",
    "            \n",
    "            if self.training_steps == training_steps:\n",
    "                break\n",
    "            else:\n",
    "                time.sleep(log_interval)\n",
    "    \n",
    "    def write_stats(self):\n",
    "        # writer = SummaryWriter(f'logs/r2d2__{game_name}')\n",
    "        os.makedirs(f'logs/r2d2/{game_name}', exist_ok=True)\n",
    "        while True:\n",
    "            # writer.add_scalar('buffer/size', self.size, self.env_steps)\n",
    "            with open(f'logs/r2d2/{game_name}/buffer_size.txt', 'a') as f:\n",
    "                f.write(f'{self.size} {self.env_steps}\\n')\n",
    "            \n",
    "            # writer.add_scalar('buffer/update_speed', (self.size - self.last_size) / log_interval, self.env_steps)\n",
    "            with open(f'logs/r2d2/{game_name}/buffer_update_speed.txt', 'a') as f:\n",
    "                f.write(f'{(self.size - self.last_size) / log_interval} {self.env_steps}\\n')\n",
    "            \n",
    "            # writer.add_scalar('environment/steps', self.env_steps, self.env_steps)\n",
    "            with open(f'logs/r2d2/{game_name}/environment_steps.txt', 'a') as f:\n",
    "                f.write(f'{self.env_steps}\\n')\n",
    "\n",
    "            if self.num_episodes != 0:\n",
    "                # writer.add_scalar('episode/return', self.episode_reward / self.num_episodes, self.env_steps)\n",
    "                with open(f'logs/r2d2/{game_name}/episode_return.txt', 'a') as f:\n",
    "                    f.write(f'{self.episode_reward / self.num_episodes} {self.env_steps}\\n')\n",
    "\n",
    "            # writer.add_scalar('training/steps', self.training_steps, self.env_steps)\n",
    "            with open(f'logs/r2d2/{game_name}/training_steps.txt', 'a') as f:\n",
    "                f.write(f'{self.training_steps} {self.env_steps}\\n')\n",
    "\n",
    "            # writer.add_scalar('training/speed', (self.training_steps - self.last_training_steps) / log_interval, self.env_steps)\n",
    "            with open(f'logs/r2d2/{game_name}/training_speed.txt', 'a') as f:\n",
    "                f.write(f'{(self.training_steps - self.last_training_steps) / log_interval} {self.env_steps}\\n')\n",
    "\n",
    "            if self.training_steps != self.last_training_steps:\n",
    "                # writer.add_scalar('training/loss', self.sum_loss/(self.training_steps-self.last_training_steps), self.env_steps)\n",
    "                with open(f'logs/r2d2/{game_name}/training_loss.txt', 'a') as f:\n",
    "                    f.write(f'{self.sum_loss/(self.training_steps-self.last_training_steps)} {self.env_steps}\\n')\n",
    "\n",
    "            time.sleep(log_interval)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        while self.size < learning_starts:\n",
    "            time.sleep(1)\n",
    "        \n",
    "        while True:\n",
    "            if not self.batch_queue.full():\n",
    "                data = self.sample_batch()\n",
    "                self.batch_queue.put(data)\n",
    "            else:\n",
    "                time.sleep(0.1)\n",
    "    \n",
    "    def add_data(self):\n",
    "        while True:\n",
    "            for sample_queue in self.sample_queue_list:\n",
    "                if not sample_queue.empty():\n",
    "                    data = sample_queue.get_nowait()\n",
    "                    self.add(*data)\n",
    "    \n",
    "    def update_data(self):\n",
    "        while True:\n",
    "            if not self.priority_queue.empty():\n",
    "                data = self.priority_queue.get_nowait()\n",
    "                self.update_priorities(*data)\n",
    "            else:\n",
    "                time.sleep(0.1)\n",
    "    \n",
    "    def add(self, block: Block, priority: np.array, episode_reward: float):\n",
    "        with self.lock:\n",
    "            idxes = np.arange(self.block_ptr * self.seq_pre_block, (self.block_ptr + 1) * self.seq_pre_block, dtype=np.int64)\n",
    "            \n",
    "            self.priority_tree.update(idxes, priority)\n",
    "            \n",
    "            if self.buffer[self.block_ptr] is not None:\n",
    "                self.size -= np.sum(self.buffer[self.block_ptr].learning_steps).item()\n",
    "            \n",
    "            self.size += np.sum(block.learning_steps).item()\n",
    "            \n",
    "            self.buffer[self.block_ptr] = block\n",
    "            \n",
    "            self.env_steps += np.sum(block.learning_steps, dtype=np.int32)\n",
    "            \n",
    "            self.block_ptr = (self.block_ptr + 1) % self.num_blocks\n",
    "            \n",
    "            if episode_reward:\n",
    "                self.episode_reward += episode_reward\n",
    "                self.num_episodes += 1\n",
    "    \n",
    "    def sample_batch(self):\n",
    "        batch_obs, batch_last_action, batch_last_reward, batch_hidden, batch_action, batch_reward, batch_gamma = [], [], [], [], [], [], []\n",
    "        burn_in_steps, learning_steps, forward_steps = [], [], []\n",
    "\n",
    "        with self.lock:\n",
    "\n",
    "            idxes, is_weights = self.priority_tree.sample(self.batch_size)\n",
    "\n",
    "            block_idxes = idxes // self.seq_pre_block\n",
    "            sequence_idxes = idxes % self.seq_pre_block\n",
    "\n",
    "\n",
    "            for block_idx, sequence_idx  in zip(block_idxes, sequence_idxes):\n",
    "\n",
    "                block = self.buffer[block_idx]\n",
    "\n",
    "                assert sequence_idx < block.num_sequences, 'index is {} but size is {}'.format(sequence_idx, self.seq_pre_block_buf[block_idx])\n",
    "\n",
    "                burn_in_step = block.burn_in_steps[sequence_idx]\n",
    "                learning_step = block.learning_steps[sequence_idx]\n",
    "                forward_step = block.forward_steps[sequence_idx]\n",
    "                \n",
    "                start_idx = block.burn_in_steps[0] + np.sum(block.learning_steps[:sequence_idx])\n",
    "\n",
    "                obs = block.obs[start_idx-burn_in_step:start_idx+learning_step+forward_step]\n",
    "                last_action = block.last_action[start_idx-burn_in_step:start_idx+learning_step+forward_step]\n",
    "                last_reward = block.last_reward[start_idx-burn_in_step:start_idx+learning_step+forward_step]\n",
    "                obs, last_action, last_reward = torch.from_numpy(obs), torch.from_numpy(last_action), torch.from_numpy(last_reward)\n",
    "                \n",
    "                start_idx = np.sum(block.learning_steps[:sequence_idx])\n",
    "                end_idx = start_idx + block.learning_steps[sequence_idx]\n",
    "                action = block.action[start_idx:end_idx]\n",
    "                reward = block.n_step_reward[start_idx:end_idx]\n",
    "                gamma = block.gamma[start_idx:end_idx]\n",
    "                hidden = block.hidden[sequence_idx]\n",
    "                \n",
    "                batch_obs.append(obs)\n",
    "                batch_last_action.append(last_action)\n",
    "                batch_last_reward.append(last_reward)\n",
    "                batch_action.append(action)\n",
    "                batch_reward.append(reward)\n",
    "                batch_gamma.append(gamma)\n",
    "                batch_hidden.append(hidden)\n",
    "\n",
    "                burn_in_steps.append(burn_in_step)\n",
    "                learning_steps.append(learning_step)\n",
    "                forward_steps.append(forward_step)\n",
    "\n",
    "            batch_obs = pad_sequence(batch_obs, batch_first=True)\n",
    "            batch_last_action = pad_sequence(batch_last_action, batch_first=True)\n",
    "            batch_last_reward = pad_sequence(batch_last_reward, batch_first=True)\n",
    "\n",
    "            is_weights = np.repeat(is_weights, learning_steps)\n",
    "\n",
    "\n",
    "            data = (\n",
    "                batch_obs,\n",
    "                batch_last_action,\n",
    "                batch_last_reward,\n",
    "                torch.from_numpy(np.stack(batch_hidden)).transpose(0, 1),\n",
    "\n",
    "                torch.from_numpy(np.concatenate(batch_action)).unsqueeze(1),\n",
    "                torch.from_numpy(np.concatenate(batch_reward)),\n",
    "                torch.from_numpy(np.concatenate(batch_gamma)),\n",
    "\n",
    "                torch.ByteTensor(burn_in_steps),\n",
    "                torch.ByteTensor(learning_steps),\n",
    "                torch.ByteTensor(forward_steps),\n",
    "\n",
    "                idxes,\n",
    "                torch.from_numpy(is_weights.astype(np.float32)),\n",
    "                self.block_ptr,\n",
    "\n",
    "                self.env_steps\n",
    "            )\n",
    "\n",
    "        return data\n",
    "\n",
    "    def update_priorities(self, idxes: np.ndarray, td_errors: np.ndarray, old_ptr: int, loss: float):\n",
    "        \"\"\"Update priorities of sampled transitions\"\"\"\n",
    "        with self.lock:\n",
    "\n",
    "            # discard the idxes that already been replaced by new data in replay buffer during training\n",
    "            if self.block_ptr > old_ptr:\n",
    "                # range from [old_ptr, self.seq_ptr)\n",
    "                mask = (idxes < old_ptr*self.seq_pre_block) | (idxes >= self.block_ptr*self.seq_pre_block)\n",
    "                idxes = idxes[mask]\n",
    "                td_errors = td_errors[mask]\n",
    "            elif self.block_ptr < old_ptr:\n",
    "                # range from [0, self.seq_ptr) & [old_ptr, self,capacity)\n",
    "                mask = (idxes < old_ptr*self.seq_pre_block) & (idxes >= self.block_ptr*self.seq_pre_block)\n",
    "                idxes = idxes[mask]\n",
    "                td_errors = td_errors[mask]\n",
    "\n",
    "            self.priority_tree.update(idxes, td_errors)\n",
    "\n",
    "        self.training_steps += 1\n",
    "        self.sum_loss += loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18211db5539ae96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AgentState:\n",
    "    obs: torch.tensor\n",
    "    action_dim: int\n",
    "    last_action: torch.tensor = field(init=False)\n",
    "    last_reward: torch.tensor = torch.zeros((1, 1), dtype=torch.float32)\n",
    "    hidden_state: tuple[torch.tensor, torch.tensor] | None = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.last_action = torch.zeros((1, self.action_dim), dtype=torch.float32)\n",
    "\n",
    "    def update(self, obs, last_action, last_reward, hidden):\n",
    "        self.obs = torch.from_numpy(obs).unsqueeze(0)\n",
    "        self.last_action = torch.tensor([[1 if i == last_action else 0 for i in range(self.action_dim)]],\n",
    "                                        dtype=torch.float32)\n",
    "        self.last_reward = torch.tensor([[last_reward]], dtype=torch.float32)\n",
    "        self.hidden_state = hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aec4addf644e7b99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T09:46:31.204482Z",
     "start_time": "2024-05-14T09:46:31.200932Z"
    }
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, observation_dim, action_dim, hidden_dim=hidden_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.action_dim = action_dim\n",
    "        self.obs_shape = observation_dim\n",
    "        self.max_forward_steps = 5\n",
    "\n",
    "        self.feature = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 8, 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 64, 4, 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64, 64, 3, 1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3136, 512),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        self.recurrent = nn.LSTM(512 + action_dim + 1, hidden_dim, batch_first=True)\n",
    "\n",
    "        self.advantage = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(hidden_dim, action_dim)\n",
    "        )\n",
    "\n",
    "        self.value = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, state: AgentState):\n",
    "        latent = self.feature(state.obs / 255)\n",
    "        recurrent_input = torch.cat([latent, state.last_action, state.last_reward], dim=1)\n",
    "        \n",
    "        _, recurrent_output = self.recurrent(recurrent_input, state.hidden_state)\n",
    "        \n",
    "        hidden = recurrent_output[0]\n",
    "        \n",
    "        adv = self.advantage(hidden)\n",
    "        val = self.value(hidden)\n",
    "        q_value = val + adv - adv.mean(1, keepdim=True)\n",
    "        \n",
    "        return q_value, recurrent_output\n",
    "\n",
    "    def calculate_q_(self, obs, last_action, last_reward, hidden_state, burn_in_steps, learning_steps, forward_steps):\n",
    "        # obs shape: (batch_size, seq_len, obs_shape)\n",
    "        batch_size, max_seq_len, *_ = obs.size()\n",
    "\n",
    "        obs = obs.reshape(-1, *self.obs_shape)\n",
    "        last_action = last_action.view(-1, self.action_dim)\n",
    "        last_reward = last_reward.view(-1, 1)\n",
    "        latent = self.feature(obs)\n",
    "\n",
    "        seq_len = burn_in_steps + learning_steps + forward_steps\n",
    "\n",
    "        recurrent_input = torch.cat((latent, last_action, last_reward), dim=1)\n",
    "        recurrent_input = recurrent_input.view(batch_size, max_seq_len, -1)\n",
    "\n",
    "        recurrent_input = pack_padded_sequence(recurrent_input, seq_len, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        self.recurrent.flatten_parameters()\n",
    "        recurrent_output, _ = self.recurrent(recurrent_input, hidden_state)\n",
    "\n",
    "        recurrent_output, _ = pad_packed_sequence(recurrent_output, batch_first=True)\n",
    "\n",
    "        seq_start_idx = burn_in_steps + self.max_forward_steps\n",
    "        forward_pad_steps = torch.minimum(self.max_forward_steps - forward_steps, learning_steps)\n",
    "\n",
    "        hidden = []\n",
    "        for hidden_seq, start_idx, end_idx, padding_length in zip(recurrent_output, seq_start_idx, seq_len, forward_pad_steps):\n",
    "            hidden.append(hidden_seq[start_idx:end_idx])\n",
    "            if padding_length > 0:\n",
    "                hidden.append(hidden_seq[end_idx-1:end_idx].repeat(padding_length, 1))\n",
    "\n",
    "        hidden = torch.cat(hidden)\n",
    "\n",
    "        assert hidden.size(0) == torch.sum(learning_steps)\n",
    "\n",
    "        adv = self.advantage(hidden)\n",
    "        val = self.value(hidden)\n",
    "        q_value = val + adv - adv.mean(1, keepdim=True)\n",
    "\n",
    "        return q_value\n",
    "\n",
    "    def calculate_q(self, obs, last_action, last_reward, hidden_state, burn_in_steps, learning_steps):\n",
    "        # obs shape: (batch_size, seq_len, obs_shape)\n",
    "        batch_size, max_seq_len, *_ = obs.size()\n",
    "\n",
    "        obs = obs.reshape(-1, *self.obs_shape)\n",
    "        last_action = last_action.view(-1, self.action_dim)\n",
    "        last_reward = last_reward.view(-1, 1)\n",
    "\n",
    "        latent = self.feature(obs)\n",
    "\n",
    "        seq_len = burn_in_steps + learning_steps\n",
    "\n",
    "        recurrent_input = torch.cat((latent, last_action, last_reward), dim=1)\n",
    "        recurrent_input = recurrent_input.view(batch_size, max_seq_len, -1)\n",
    "        recurrent_input = pack_padded_sequence(recurrent_input, seq_len, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        # self.recurrent.flatten_parameters()\n",
    "        recurrent_output, _ = self.recurrent(recurrent_input, hidden_state)\n",
    "\n",
    "        recurrent_output, _ = pad_packed_sequence(recurrent_output, batch_first=True)\n",
    "\n",
    "        hidden = torch.cat([output[burn_in:burn_in+learning] for output, burn_in, learning in zip(recurrent_output, burn_in_steps, learning_steps)], dim=0)\n",
    "\n",
    "        adv = self.advantage(hidden)\n",
    "        val = self.value(hidden)\n",
    "\n",
    "        q_value = val + adv - adv.mean(1, keepdim=True)\n",
    "\n",
    "        return q_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0029246daacd7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mixed_td_errors(td_error, learning_steps):\n",
    "    \n",
    "    start_idx = 0\n",
    "    mixed_td_errors = np.empty(learning_steps.shape, dtype=td_error.dtype)\n",
    "    for i, steps in enumerate(learning_steps):\n",
    "        mixed_td_errors[i] = 0.9*td_error[start_idx:start_idx+steps].max() + 0.1*td_error[start_idx:start_idx+steps].mean()\n",
    "        start_idx += steps\n",
    "    \n",
    "    return mixed_td_errors\n",
    "\n",
    "class Learner:\n",
    "    def __init__(self, batch_queue, priority_queue, model, grad_norm: int = grad_norm,\n",
    "                lr: float = lr, eps:float = eps, game_name: str = game_name,\n",
    "                target_net_update_interval: int = target_net_update_interval, save_interval: int = save_interval):\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.online_net = deepcopy(model)\n",
    "        self.online_net.to(self.device)\n",
    "        self.online_net.train()\n",
    "        self.target_net = deepcopy(self.online_net)\n",
    "        self.target_net.eval()\n",
    "        self.optimizer = torch.optim.Adam(self.online_net.parameters(), lr=lr, eps=eps)\n",
    "        self.loss_fn = nn.MSELoss(reduction='none')\n",
    "        self.grad_norm = grad_norm\n",
    "        self.batch_queue = batch_queue\n",
    "        self.priority_queue = priority_queue\n",
    "        self.num_updates = 0\n",
    "        self.done = False\n",
    "\n",
    "        self.target_net_update_interval = target_net_update_interval\n",
    "        self.save_interval = save_interval\n",
    "\n",
    "        self.batched_data = []\n",
    "\n",
    "        self.shared_model = model\n",
    "\n",
    "        self.game_name = game_name\n",
    "\n",
    "    def store_weights(self):\n",
    "        self.shared_model.load_state_dict(self.online_net.state_dict())\n",
    "\n",
    "    def prepare_data(self):\n",
    "\n",
    "        while True:\n",
    "            if not self.batch_queue.empty() and len(self.batched_data) < 4:\n",
    "                data = self.batch_queue.get_nowait()\n",
    "                self.batched_data.append(data)\n",
    "            else:\n",
    "                time.sleep(0.1)\n",
    "\n",
    "    def run(self):\n",
    "        background_thread = threading.Thread(target=self.prepare_data, daemon=True)\n",
    "        background_thread.start()\n",
    "        time.sleep(2)\n",
    "\n",
    "        start_time = time.time()\n",
    "        while self.num_updates < training_steps:\n",
    "            \n",
    "            while not self.batched_data:\n",
    "                time.sleep(1)\n",
    "            data = self.batched_data.pop(0)\n",
    "\n",
    "            batch_obs, batch_last_action, batch_last_reward, batch_hidden, batch_action, batch_n_step_reward, batch_n_step_gamma, burn_in_steps, learning_steps, forward_steps, idxes, is_weights, old_ptr, env_steps = data\n",
    "            batch_obs, batch_last_action, batch_last_reward = batch_obs.to(self.device), batch_last_action.to(self.device), batch_last_reward.to(self.device)\n",
    "            batch_hidden, batch_action = batch_hidden.to(self.device), batch_action.to(self.device)\n",
    "            batch_n_step_reward, batch_n_step_gamma = batch_n_step_reward.to(self.device), batch_n_step_gamma.to(self.device)\n",
    "            is_weights = is_weights.to(self.device)\n",
    "\n",
    "            batch_obs, batch_last_action = batch_obs.float(), batch_last_action.float()\n",
    "            batch_action = batch_action.long()\n",
    "            burn_in_steps, learning_steps, forward_steps = burn_in_steps, learning_steps, forward_steps\n",
    "\n",
    "            batch_hidden = (batch_hidden[:1], batch_hidden[1:])\n",
    "\n",
    "            batch_obs = batch_obs / 255\n",
    "\n",
    "            # double q learning\n",
    "            with torch.no_grad():\n",
    "                batch_action_ = self.online_net.calculate_q_(batch_obs, batch_last_action, batch_last_reward, batch_hidden, burn_in_steps, learning_steps, forward_steps).argmax(1).unsqueeze(1)\n",
    "                batch_q_ = self.target_net.calculate_q_(batch_obs, batch_last_action, batch_last_reward, batch_hidden, burn_in_steps, learning_steps, forward_steps).gather(1, batch_action_).squeeze(1)\n",
    "            \n",
    "            target_q = self.value_rescale(batch_n_step_reward + batch_n_step_gamma * self.inverse_value_rescale(batch_q_))\n",
    "            # target_q = batch_n_step_reward + batch_n_step_gamma * batch_q_\n",
    "\n",
    "            batch_q = self.online_net.calculate_q(batch_obs, batch_last_action, batch_last_reward, batch_hidden, burn_in_steps, learning_steps).gather(1, batch_action).squeeze(1)\n",
    "            \n",
    "            loss = (is_weights * self.loss_fn(batch_q, target_q)).mean()\n",
    "\n",
    "            \n",
    "            td_errors = (target_q-batch_q).detach().clone().squeeze().abs().cpu().float().numpy()\n",
    "\n",
    "            priorities = calculate_mixed_td_errors(td_errors, learning_steps.numpy())\n",
    "\n",
    "            # automatic mixed precision training\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(self.online_net.parameters(), self.grad_norm)\n",
    "            self.optimizer.step()\n",
    "\n",
    "            self.num_updates += 1\n",
    "\n",
    "            self.priority_queue.put((idxes, priorities, old_ptr, loss.item()))\n",
    "\n",
    "            # store new weights in shared memory\n",
    "            if self.num_updates % 4 == 0:\n",
    "                self.store_weights()\n",
    "\n",
    "            # update target net\n",
    "            if self.num_updates % self.target_net_update_interval == 0:\n",
    "                self.target_net.load_state_dict(self.online_net.state_dict())\n",
    "            \n",
    "            # save model \n",
    "            if self.num_updates % self.save_interval == 0:\n",
    "                os.makedirs(f'models/r2d2/{game_name}', exist_ok=True)\n",
    "                torch.save((self.online_net.state_dict(), self.num_updates, env_steps, (time.time()-start_time)/60), os.path.join(f'models/r2d2/{game_name}', '{}.pth'.format(self.num_updates)))\n",
    "\n",
    "    @staticmethod\n",
    "    def value_rescale(value, eps=1e-3):\n",
    "        return value.sign()*((value.abs()+1).sqrt()-1) + eps*value\n",
    "\n",
    "    @staticmethod\n",
    "    def inverse_value_rescale(value, eps=1e-3):\n",
    "        temp = ((1 + 4*eps*(value.abs()+1+eps)).sqrt() - 1) / (2*eps)\n",
    "        return value.sign() * (temp.square() - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e982c17b637a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalBuffer:\n",
    "    def __init__(self, action_dim: int, forward_steps: int = forward_steps,\n",
    "                burn_in_steps = burn_in_steps, learning_steps: int = learning_steps, \n",
    "                gamma: float = gamma, hidden_dim: int = hidden_dim, block_length: int = block_length):\n",
    "        \n",
    "        self.action_dim = action_dim\n",
    "        self.gamma = gamma\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.forward_steps = forward_steps\n",
    "        self.learning_steps = learning_steps\n",
    "        self.burn_in_steps = burn_in_steps\n",
    "        self.block_length = block_length\n",
    "        self.curr_burn_in_steps = 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def reset(self, init_obs: np.ndarray):\n",
    "        self.obs_buffer = [init_obs]\n",
    "        self.last_action_buffer = [np.array([1 if i == 0 else 0 for i in range(self.action_dim)], dtype=bool)]\n",
    "        self.last_reward_buffer = [0]\n",
    "        self.hidden_buffer = [np.zeros((2, self.hidden_dim), dtype=np.float32)]\n",
    "        self.action_buffer = []\n",
    "        self.reward_buffer = []\n",
    "        self.qval_buffer = []\n",
    "        self.curr_burn_in_steps = 0\n",
    "        self.size = 0\n",
    "        self.sum_reward = 0\n",
    "        self.done = False\n",
    "\n",
    "    def add(self, action: int, reward: float, next_obs: np.ndarray, q_value: np.ndarray, hidden_state: np.ndarray):\n",
    "        self.action_buffer.append(action)\n",
    "        self.reward_buffer.append(reward)\n",
    "        self.hidden_buffer.append(hidden_state)\n",
    "        self.obs_buffer.append(next_obs)\n",
    "        self.last_action_buffer.append(np.array([1 if i == action else 0 for i in range(self.action_dim)], dtype=bool))\n",
    "        self.last_reward_buffer.append(reward)\n",
    "        self.qval_buffer.append(q_value)\n",
    "        self.sum_reward += reward\n",
    "        self.size += 1\n",
    "    \n",
    "    def finish(self, last_qval: np.ndarray = None) -> Tuple:\n",
    "        assert self.size <= self.block_length\n",
    "        # assert len(self.last_action_buffer) == self.curr_burn_in_steps + self.size + 1\n",
    "\n",
    "        num_sequences = math.ceil(self.size/self.learning_steps)\n",
    "\n",
    "        max_forward_steps = min(self.size, self.forward_steps)\n",
    "        n_step_gamma = [self.gamma**self.forward_steps] * (self.size-max_forward_steps)\n",
    "\n",
    "        # last_qval is none means episode done \n",
    "        if last_qval is not None:\n",
    "            self.qval_buffer.append(last_qval)\n",
    "            n_step_gamma.extend([self.gamma**i for i in reversed(range(1, max_forward_steps+1))])\n",
    "        else:\n",
    "            self.done = True\n",
    "            self.qval_buffer.append(np.zeros_like(self.qval_buffer[0]))\n",
    "            n_step_gamma.extend([0 for _ in range(max_forward_steps)]) # set gamma to 0 so don't need 'done'\n",
    "\n",
    "        n_step_gamma = np.array(n_step_gamma, dtype=np.float32)\n",
    "\n",
    "        obs = np.stack(self.obs_buffer)\n",
    "        last_action = np.stack(self.last_action_buffer)\n",
    "        last_reward = np.array(self.last_reward_buffer, dtype=np.float32)\n",
    "\n",
    "        hiddens = np.stack(self.hidden_buffer[slice(0, self.size, self.learning_steps)])\n",
    "\n",
    "        actions = np.array(self.action_buffer, dtype=np.uint8)\n",
    "\n",
    "        qval_buffer = np.concatenate(self.qval_buffer)\n",
    "        reward_buffer = self.reward_buffer + [0 for _ in range(self.forward_steps-1)]\n",
    "        n_step_reward = np.convolve(reward_buffer, \n",
    "                                    [self.gamma**(self.forward_steps-1-i) for i in range(self.forward_steps)],\n",
    "                                    'valid').astype(np.float32)\n",
    "\n",
    "        burn_in_steps = np.array([min(i*self.learning_steps+self.curr_burn_in_steps, self.burn_in_steps) for i in range(num_sequences)], dtype=np.uint8)\n",
    "        learning_steps = np.array([min(self.learning_steps, self.size-i*self.learning_steps) for i in range(num_sequences)], dtype=np.uint8)\n",
    "        forward_steps = np.array([min(self.forward_steps, self.size+1-np.sum(learning_steps[:i+1])) for i in range(num_sequences)], dtype=np.uint8)\n",
    "        assert forward_steps[-1] == 1 and burn_in_steps[0] == self.curr_burn_in_steps\n",
    "        # assert last_action.shape[0] == self.curr_burn_in_steps + np.sum(learning_steps) + 1\n",
    "\n",
    "        max_qval = np.max(qval_buffer[max_forward_steps:self.size+1], axis=1)\n",
    "        max_qval = np.pad(max_qval, (0, max_forward_steps-1), 'edge')\n",
    "        target_qval = qval_buffer[np.arange(self.size), actions]\n",
    "\n",
    "        td_errors = np.abs(n_step_reward + n_step_gamma * max_qval - target_qval, dtype=np.float32)\n",
    "        priorities = np.zeros(self.block_length//self.learning_steps, dtype=np.float32)\n",
    "        priorities[:num_sequences] = calculate_mixed_td_errors(td_errors, learning_steps)\n",
    "\n",
    "        # save burn in information for next block\n",
    "        self.obs_buffer = self.obs_buffer[-self.burn_in_steps-1:]\n",
    "        self.last_action_buffer = self.last_action_buffer[-self.burn_in_steps-1:]\n",
    "        self.last_reward_buffer = self.last_reward_buffer[-self.burn_in_steps-1:]\n",
    "        self.hidden_buffer = self.hidden_buffer[-self.burn_in_steps-1:]\n",
    "        self.action_buffer.clear()\n",
    "        self.reward_buffer.clear()\n",
    "        self.qval_buffer.clear()\n",
    "        self.curr_burn_in_steps = len(self.obs_buffer)-1\n",
    "        self.size = 0\n",
    "        \n",
    "        block = Block(obs, last_action, last_reward, actions, n_step_reward, n_step_gamma, hiddens, num_sequences, burn_in_steps, learning_steps, forward_steps)\n",
    "        return [block, priorities, self.sum_reward if self.done else None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de71841dc9e844c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (997092016.py, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[11], line 14\u001b[0;36m\u001b[0m\n\u001b[0;31m    self.mmodels/r2d2/MsPacman-v5/41000.pthax_episode_steps = max_episode_steps\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "class Actor:\n",
    "    def __init__(self, epsilon: float, model, sample_queue,\n",
    "                max_episode_steps: int = max_episode_steps, block_length: int = block_length):\n",
    "\n",
    "        self.env = create_env(game_name)\n",
    "        self.action_dim = self.env.action_space.n\n",
    "        self.model = Network(self.env.observation_space.shape[0], self.action_dim)\n",
    "        self.model.eval()\n",
    "        self.local_buffer = LocalBuffer(self.action_dim)\n",
    "\n",
    "        self.epsilon = epsilon\n",
    "        self.shared_model = model\n",
    "        self.sample_queue = sample_queue\n",
    "        self.mmodels/r2d2/MsPacman-v5/41000.pthax_episode_steps = max_episode_steps\n",
    "        self.block_length = block_length\n",
    "\n",
    "    def run(self):\n",
    "        \n",
    "        actor_steps = 0\n",
    "\n",
    "        while True:\n",
    "\n",
    "            done = False\n",
    "            agent_state = self.reset()\n",
    "            episode_steps = 0\n",
    "\n",
    "            while not done and episode_steps < self.max_episode_steps:\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    q_value, hidden = self.model(agent_state)\n",
    "\n",
    "                if random.random() < self.epsilon:\n",
    "                    action = self.env.action_space.sample()\n",
    "                else:\n",
    "                    action = torch.argmax(q_value, 1).item()\n",
    "\n",
    "                # apply action in env\n",
    "                next_obs, reward, terminated, truncated, _ = self.env.step(action)\n",
    "                done = terminated or truncated\n",
    "\n",
    "                agent_state.update(next_obs, action, reward, hidden)\n",
    "\n",
    "                episode_steps += 1\n",
    "                actor_steps += 1\n",
    "\n",
    "                self.local_buffer.add(action, reward, next_obs, q_value.numpy(), torch.cat(hidden).numpy())\n",
    "\n",
    "                if done:\n",
    "                    block = self.local_buffer.finish()\n",
    "                    print('FINISHED')\n",
    "                    self.sample_queue.put(block)\n",
    "                    print('ADDED')\n",
    "\n",
    "                elif len(self.local_buffer) == self.block_length or episode_steps == self.max_episode_steps:\n",
    "                    with torch.no_grad():\n",
    "                        q_value, hidden = self.model(agent_state)\n",
    "\n",
    "                    block = self.local_buffer.finish(q_value.numpy())\n",
    "\n",
    "                    if self.epsilon > 0.01:\n",
    "                        block[2] = None\n",
    "                    self.sample_queue.put(block)\n",
    "\n",
    "                if actor_steps % actor_update_interval == 0:\n",
    "                    self.update_weights()\n",
    "\n",
    "                \n",
    "    def update_weights(self):\n",
    "        self.model.load_state_dict(self.shared_model.state_dict())\n",
    "    \n",
    "    def reset(self):\n",
    "        obs, _ = self.env.reset()\n",
    "        self.local_buffer.reset(obs)\n",
    "\n",
    "        state = AgentState(torch.from_numpy(obs).unsqueeze(0), self.action_dim)\n",
    "\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea899f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epsilon(actor_id: int, base_eps: float = base_eps, alpha: float = alpha, num_actors: int = num_actors):\n",
    "    exponent = 1 + actor_id / (num_actors-1) * alpha\n",
    "    return base_eps**exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e97fdc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c429da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISHED\n",
      "ADDED\n",
      "FINISHED\n",
      "ADDED\n",
      "FINISHED\n",
      "ADDED\n",
      "FINISHED\n",
      "ADDED\n",
      "FINISHED\n",
      "ADDED\n",
      "FINISHED\n",
      "ADDED\n",
      "FINISHED\n",
      "ADDED\n",
      "FINISHED\n",
      "ADDED\n",
      "FINISHED\n",
      "ADDED\n",
      "FINISHED\n",
      "ADDED\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m queue \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mQueue()\n\u001b[1;32m      5\u001b[0m actor \u001b[38;5;241m=\u001b[39m Actor(epsilon\u001b[38;5;241m=\u001b[39mget_epsilon(\u001b[38;5;241m0\u001b[39m), model\u001b[38;5;241m=\u001b[39mNetwork(observation_dim, action_dim), sample_queue\u001b[38;5;241m=\u001b[39mqueue)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mactor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 38\u001b[0m, in \u001b[0;36mActor.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     35\u001b[0m     action \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(q_value, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# apply action in env\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m next_obs, reward, terminated, truncated, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m done \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n\u001b[1;32m     41\u001b[0m agent_state\u001b[38;5;241m.\u001b[39mupdate(next_obs, action, reward, hidden)\n",
      "Cell \u001b[0;32mIn[3], line 28\u001b[0m, in \u001b[0;36mNoopResetEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.miniforge3/envs/torch/lib/python3.11/site-packages/gymnasium/core.py:522\u001b[0m, in \u001b[0;36mObservationWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: ActType\n\u001b[1;32m    520\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    521\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Modifies the :attr:`env` after calling :meth:`step` using :meth:`self.observation` on the returned observations.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 522\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation(observation), reward, terminated, truncated, info\n",
      "File \u001b[0;32m~/.miniforge3/envs/torch/lib/python3.11/site-packages/gymnasium/wrappers/order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.miniforge3/envs/torch/lib/python3.11/site-packages/gymnasium/wrappers/env_checker.py:51\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.miniforge3/envs/torch/lib/python3.11/site-packages/shimmy/atari_env.py:294\u001b[0m, in \u001b[0;36mAtariEnv.step\u001b[0;34m(self, action_ind)\u001b[0m\n\u001b[1;32m    292\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(frameskip):\n\u001b[0;32m--> 294\u001b[0m     reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43male\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m is_terminal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39male\u001b[38;5;241m.\u001b[39mgame_over(with_truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    296\u001b[0m is_truncated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39male\u001b[38;5;241m.\u001b[39mgame_truncated()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = create_env(game_name)\n",
    "action_dim = env.action_space.n\n",
    "observation_dim = env.observation_space.shape\n",
    "queue = mp.Queue()\n",
    "actor = Actor(epsilon=get_epsilon(0), model=Network(observation_dim, action_dim), sample_queue=queue)\n",
    "actor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f06c5b41ae86fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffer size: 0\n",
      "Buffer update speed: 0.0/s\n",
      "Number of environment steps: 0\n",
      "Number of training steps: 0\n",
      "Training speed: 0.0/s\n",
      "\n",
      "Buffer size: 0\n",
      "Buffer update speed: 0.0/s\n",
      "Number of environment steps: 0\n",
      "Number of training steps: 0\n",
      "Training speed: 0.0/s\n",
      "\n",
      "Buffer size: 3184\n",
      "Buffer update speed: 318.4/s\n",
      "Number of environment steps: 3184\n",
      "Average episode return: 313.3333\n",
      "Number of training steps: 0\n",
      "Training speed: 0.0/s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "env = create_env(game_name)\n",
    "n_observations = env.observation_space.shape\n",
    "n_actions = env.action_space.n\n",
    "env.close()\n",
    "\n",
    "model = Network(n_observations, n_actions)\n",
    "model.share_memory()\n",
    "sample_queue_list = [mp.Queue() for _ in range(num_actors)]\n",
    "batch_queue = mp.Queue(num_actors)\n",
    "priority_queue = mp.Queue(num_actors)\n",
    "\n",
    "buffer = ReplayBuffer(sample_queue_list, batch_queue, priority_queue)\n",
    "learner = Learner(batch_queue, priority_queue, model)\n",
    "actors = [Actor(get_epsilon(i), model, sample_queue_list[i]) for i in range(num_actors)]\n",
    "\n",
    "actor_procs = [mp.Process(target=actor.run) for actor in actors]\n",
    "for proc in actor_procs:\n",
    "    proc.start()\n",
    "\n",
    "buffer_proc = mp.Process(target=buffer.run)\n",
    "buffer_proc.start()\n",
    "\n",
    "learner.run()\n",
    "\n",
    "buffer_proc.join()\n",
    "\n",
    "for proc in actor_procs:\n",
    "    proc.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dddba3",
   "metadata": {},
   "source": [
    "### 3h training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f45d632",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3827c8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(OrderedDict([('feature.0.weight',\n",
       "               tensor([[[[-0.0371,  0.0123, -0.1697,  ...,  0.1115,  0.0864,  0.1812],\n",
       "                         [-0.1043, -0.0305, -0.0850,  ..., -0.0055,  0.0226,  0.0750],\n",
       "                         [-0.0489, -0.0040, -0.1127,  ...,  0.1809,  0.0585,  0.1681],\n",
       "                         ...,\n",
       "                         [-0.0557, -0.1601, -0.0676,  ...,  0.0033,  0.1475,  0.1319],\n",
       "                         [-0.1354, -0.0811,  0.0205,  ...,  0.0745,  0.1512, -0.0095],\n",
       "                         [-0.0553, -0.1634, -0.1402,  ...,  0.0904, -0.0184,  0.0913]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.1590,  0.0389,  0.0741,  ...,  0.1296, -0.0812, -0.0412],\n",
       "                         [ 0.1395,  0.1856,  0.1744,  ..., -0.0885,  0.0530, -0.0815],\n",
       "                         [-0.0555,  0.1859,  0.1497,  ..., -0.0014,  0.0072, -0.0548],\n",
       "                         ...,\n",
       "                         [-0.1403, -0.0312, -0.1396,  ..., -0.0308, -0.1082,  0.0537],\n",
       "                         [-0.0743,  0.1666,  0.1226,  ...,  0.0077,  0.0603,  0.0383],\n",
       "                         [ 0.0605,  0.0409, -0.0240,  ..., -0.0684, -0.0186, -0.0956]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0277, -0.1067, -0.0185,  ...,  0.0042,  0.1005, -0.0052],\n",
       "                         [ 0.0201,  0.0414,  0.1159,  ...,  0.1407,  0.1785,  0.0277],\n",
       "                         [-0.0942, -0.0623,  0.1086,  ..., -0.1031, -0.1659, -0.1213],\n",
       "                         ...,\n",
       "                         [-0.0729,  0.0268,  0.1892,  ...,  0.0934, -0.1012,  0.1151],\n",
       "                         [ 0.0522, -0.0168,  0.1767,  ...,  0.0394,  0.1550,  0.0833],\n",
       "                         [ 0.1056,  0.0957,  0.0252,  ...,  0.0960,  0.1376,  0.1050]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 0.1502,  0.1157,  0.0471,  ...,  0.2267,  0.2560,  0.2107],\n",
       "                         [-0.0523, -0.0381,  0.0543,  ...,  0.1291,  0.2008,  0.0399],\n",
       "                         [-0.0134,  0.0589,  0.0281,  ..., -0.0944, -0.0223, -0.0328],\n",
       "                         ...,\n",
       "                         [-0.0203, -0.0099,  0.0765,  ...,  0.0731, -0.0007,  0.0420],\n",
       "                         [ 0.0392, -0.0524, -0.0005,  ...,  0.0999,  0.0037, -0.0920],\n",
       "                         [ 0.1253, -0.0421,  0.0587,  ...,  0.0150,  0.0513,  0.0885]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0047, -0.0319,  0.0364,  ...,  0.1694,  0.0484,  0.0920],\n",
       "                         [ 0.0440,  0.0092, -0.1748,  ...,  0.0708,  0.0638, -0.0036],\n",
       "                         [ 0.1172,  0.1004, -0.0831,  ...,  0.0167, -0.0805, -0.0260],\n",
       "                         ...,\n",
       "                         [ 0.1511,  0.0149, -0.0882,  ..., -0.0365, -0.0835, -0.0493],\n",
       "                         [-0.0784, -0.0625, -0.1296,  ..., -0.1037, -0.0109, -0.0595],\n",
       "                         [ 0.0810,  0.1377,  0.0308,  ..., -0.0182,  0.0696,  0.0568]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.1266,  0.0674,  0.1371,  ...,  0.1371, -0.0943, -0.0426],\n",
       "                         [ 0.1300,  0.0049, -0.0685,  ..., -0.0026, -0.0295,  0.1055],\n",
       "                         [ 0.1349,  0.0583,  0.0307,  ..., -0.0928, -0.0365,  0.0704],\n",
       "                         ...,\n",
       "                         [ 0.0458,  0.0347,  0.1284,  ...,  0.0731, -0.0156,  0.1553],\n",
       "                         [-0.0708,  0.0134, -0.0142,  ..., -0.0491,  0.1152,  0.0250],\n",
       "                         [-0.0627,  0.0070,  0.1115,  ...,  0.0144,  0.0957, -0.0375]]]])),\n",
       "              ('feature.0.bias',\n",
       "               tensor([ 0.0313, -0.0083, -0.1018,  0.1271,  0.0489, -0.1574,  0.0341, -0.0421,\n",
       "                        0.2265,  0.0098, -0.1475, -0.0412,  0.0609, -0.0119,  0.0191, -0.0215,\n",
       "                        0.0704,  0.1633, -0.1198, -0.1450, -0.0509, -0.1693,  0.0911,  0.0118,\n",
       "                       -0.0766,  0.0935,  0.0887, -0.0792,  0.0223, -0.1352,  0.0696, -0.1357])),\n",
       "              ('feature.2.weight',\n",
       "               tensor([[[[ 2.6704e-02, -1.0933e-02, -7.2439e-02, -4.3134e-02],\n",
       "                         [ 2.3990e-02,  1.4234e-02, -5.6441e-02, -1.5355e-02],\n",
       "                         [-7.4095e-03, -3.7032e-02, -6.5254e-02, -4.3000e-02],\n",
       "                         [ 3.7554e-02, -3.5087e-02, -1.2738e-02, -5.2087e-03]],\n",
       "               \n",
       "                        [[ 1.9309e-02,  3.9934e-02, -2.2735e-02,  6.3413e-02],\n",
       "                         [-5.6103e-02,  2.8110e-03,  1.8757e-02,  2.9338e-02],\n",
       "                         [-9.4655e-03,  4.7207e-02,  1.7627e-02, -9.3792e-03],\n",
       "                         [ 5.1620e-02,  2.3428e-02, -7.4420e-03, -3.5969e-02]],\n",
       "               \n",
       "                        [[-7.6459e-03,  5.1202e-02,  2.5378e-02,  5.8642e-05],\n",
       "                         [-5.6412e-02, -3.0605e-02,  1.8863e-02, -1.9535e-02],\n",
       "                         [ 3.9466e-02,  6.2588e-02,  4.0404e-02,  6.6130e-02],\n",
       "                         [-1.4615e-02,  1.9954e-02, -1.1742e-02, -5.0623e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.8826e-03, -4.9883e-02,  3.7092e-02,  5.4486e-02],\n",
       "                         [-3.6561e-02,  4.2816e-02,  2.3778e-02,  6.2246e-03],\n",
       "                         [-3.4808e-02,  2.3762e-02,  6.7378e-02,  5.4519e-02],\n",
       "                         [-5.5561e-02, -2.9591e-02, -3.0115e-02, -2.2441e-02]],\n",
       "               \n",
       "                        [[-5.7445e-02, -3.5006e-02, -3.5933e-03, -2.6694e-02],\n",
       "                         [-1.8946e-03,  9.9208e-03,  9.6634e-03, -5.4085e-03],\n",
       "                         [ 3.0762e-02, -4.3018e-02,  4.4217e-02, -1.1206e-02],\n",
       "                         [ 4.8475e-02,  1.4329e-02,  2.5176e-02,  1.4349e-02]],\n",
       "               \n",
       "                        [[-7.1993e-02,  1.9763e-02,  7.9679e-02,  4.1314e-02],\n",
       "                         [-9.8865e-02,  5.2728e-02, -2.9499e-02,  1.6825e-02],\n",
       "                         [-1.2738e-02,  2.3680e-02,  7.5831e-02,  1.9319e-02],\n",
       "                         [ 4.1038e-04,  3.3692e-02,  3.7807e-02, -1.4499e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.0052e-01, -7.5206e-03, -3.6699e-02,  8.8763e-02],\n",
       "                         [ 1.7842e-02,  2.2057e-02,  6.6618e-02,  1.9138e-02],\n",
       "                         [ 7.2105e-02,  2.3801e-02, -4.0928e-03, -2.3427e-02],\n",
       "                         [ 2.7002e-02,  5.4154e-02,  1.9700e-02, -1.5345e-02]],\n",
       "               \n",
       "                        [[-8.5808e-03, -3.9277e-02, -4.8374e-02, -1.4417e-02],\n",
       "                         [-3.7337e-02, -2.2390e-03, -4.9985e-02, -4.3436e-02],\n",
       "                         [ 2.6282e-02, -4.1038e-02,  6.4378e-02,  2.8316e-02],\n",
       "                         [-9.8369e-03,  1.0791e-02,  6.0047e-02,  2.1760e-02]],\n",
       "               \n",
       "                        [[-2.9887e-02, -5.5121e-02, -6.0418e-03, -7.1552e-02],\n",
       "                         [-3.0928e-02,  2.1490e-02, -1.5153e-03, -1.9653e-02],\n",
       "                         [-1.4145e-02,  3.4189e-02,  5.1718e-03,  5.3628e-02],\n",
       "                         [ 6.2050e-03,  3.0804e-02,  2.5358e-02, -7.9904e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.1754e-02,  6.2844e-02, -4.8101e-02, -2.2031e-02],\n",
       "                         [ 4.9059e-02, -2.9453e-02, -2.3469e-02, -2.0946e-02],\n",
       "                         [-1.7093e-02,  3.4869e-02,  5.8428e-02, -2.2924e-02],\n",
       "                         [ 3.6569e-02,  3.4692e-02,  4.3237e-02, -2.8372e-02]],\n",
       "               \n",
       "                        [[ 4.5979e-02,  3.8612e-02, -3.5090e-02, -4.3587e-02],\n",
       "                         [ 2.0470e-02, -2.6447e-02,  8.6507e-03,  5.2561e-03],\n",
       "                         [ 2.1350e-03, -2.2761e-02, -1.1983e-03,  5.9636e-02],\n",
       "                         [ 8.2328e-03,  1.1863e-02,  3.3573e-02, -5.3240e-03]],\n",
       "               \n",
       "                        [[ 1.2081e-03,  4.1219e-02, -6.0687e-02,  3.8223e-02],\n",
       "                         [ 4.8565e-02, -5.9716e-03, -7.8213e-02, -3.0962e-02],\n",
       "                         [-4.8483e-02,  2.0229e-03, -2.8264e-02,  6.6117e-02],\n",
       "                         [-6.0503e-02, -3.1436e-02,  2.0656e-02,  3.7816e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.2038e-02,  6.9661e-03, -6.3255e-02,  3.5667e-02],\n",
       "                         [ 6.6625e-03,  3.9203e-02, -7.3316e-02, -6.8829e-02],\n",
       "                         [-2.3635e-02,  1.1099e-02, -3.5607e-02, -6.9568e-02],\n",
       "                         [ 2.8715e-03,  1.7254e-02,  3.9061e-02, -2.3005e-02]],\n",
       "               \n",
       "                        [[ 5.8154e-03, -3.9507e-02, -3.0256e-02, -5.1339e-02],\n",
       "                         [ 1.1276e-01, -1.1786e-02,  4.1728e-02,  1.2323e-02],\n",
       "                         [ 5.3182e-02,  3.5146e-02, -5.0740e-03, -3.6887e-03],\n",
       "                         [ 3.1701e-02, -4.0797e-02, -4.8415e-03,  4.9032e-02]],\n",
       "               \n",
       "                        [[ 4.5222e-02, -1.6763e-02, -2.0211e-02, -8.1668e-03],\n",
       "                         [ 8.5457e-03,  9.1456e-02,  2.9382e-02, -9.5575e-03],\n",
       "                         [-3.0181e-02, -8.1101e-02, -2.2659e-02,  2.7965e-02],\n",
       "                         [-7.7675e-02, -8.6590e-02, -4.9134e-02,  2.6336e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.6885e-02, -6.2115e-02, -4.6633e-02, -6.2172e-03],\n",
       "                         [-1.3596e-02,  6.2675e-02, -1.7860e-02, -3.6644e-02],\n",
       "                         [ 8.4408e-02, -9.1759e-03,  3.0412e-02,  5.8303e-03],\n",
       "                         [-5.6378e-02,  2.9406e-02, -2.3901e-02, -2.9453e-02]],\n",
       "               \n",
       "                        [[-3.8081e-02, -3.4650e-02,  6.4238e-03, -3.0443e-02],\n",
       "                         [-3.6434e-02, -3.9492e-02,  2.2999e-02, -3.0208e-02],\n",
       "                         [ 4.4070e-02,  9.7793e-03,  2.4997e-02, -1.4519e-02],\n",
       "                         [-7.5035e-03,  1.7923e-02, -2.0087e-02, -1.8117e-02]],\n",
       "               \n",
       "                        [[-3.1871e-02, -2.4892e-02, -2.2268e-02,  3.6057e-02],\n",
       "                         [ 2.7110e-02,  3.4623e-02,  4.0461e-02,  1.6695e-02],\n",
       "                         [-2.7195e-02, -2.3991e-03,  8.7751e-03, -5.0292e-02],\n",
       "                         [ 1.2367e-04, -3.1627e-02, -4.1136e-02, -1.6092e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-2.6109e-02,  1.3156e-02, -6.5512e-02, -9.9723e-03],\n",
       "                         [ 5.2677e-02,  3.2286e-03,  3.0113e-03, -1.3584e-03],\n",
       "                         [ 2.6668e-03, -1.8651e-02, -3.9833e-02, -2.5966e-02],\n",
       "                         [-4.6820e-03, -6.0971e-02,  3.4783e-02, -6.6063e-02]],\n",
       "               \n",
       "                        [[-4.8611e-03, -8.6166e-02, -1.8046e-02,  4.2375e-02],\n",
       "                         [-2.2010e-02, -3.6367e-02, -2.6526e-02,  5.1243e-02],\n",
       "                         [ 4.5250e-02,  1.4115e-02, -2.7170e-02,  1.7132e-02],\n",
       "                         [ 3.4167e-02,  4.4735e-02, -3.6007e-02, -1.6282e-02]],\n",
       "               \n",
       "                        [[-7.4191e-02, -6.9623e-02,  3.7818e-02, -6.7828e-03],\n",
       "                         [ 3.3282e-02,  4.9491e-02,  1.7796e-02, -6.0504e-02],\n",
       "                         [ 7.3203e-02,  6.4108e-02,  1.6019e-02,  3.3036e-02],\n",
       "                         [ 4.6731e-03,  6.1500e-02,  4.0698e-02,  5.2158e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.8880e-02, -2.8000e-02,  4.6412e-02,  6.8582e-03],\n",
       "                         [ 1.0906e-02,  2.4251e-02, -1.0190e-01, -4.1223e-04],\n",
       "                         [ 4.6965e-03,  5.8903e-02,  1.9842e-02,  8.1289e-02],\n",
       "                         [ 4.6862e-02, -4.6926e-02,  2.4331e-02, -4.0077e-02]],\n",
       "               \n",
       "                        [[ 3.5368e-02, -1.6440e-03, -7.6350e-03,  9.2039e-03],\n",
       "                         [-3.6459e-03, -3.5187e-02,  5.5695e-02,  4.1025e-02],\n",
       "                         [-4.7505e-02,  3.1415e-02,  1.4938e-02,  4.1503e-03],\n",
       "                         [-2.9747e-02, -1.3903e-02,  2.1717e-03,  1.8435e-02]],\n",
       "               \n",
       "                        [[-1.0910e-02, -2.0353e-02, -1.8778e-02,  2.9213e-02],\n",
       "                         [-3.2027e-02,  1.7212e-02, -6.0252e-02, -2.6371e-02],\n",
       "                         [ 1.8181e-02,  5.9633e-02,  5.4217e-02, -1.1254e-02],\n",
       "                         [ 3.0236e-02,  2.7250e-02,  7.3669e-03,  5.7771e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-8.7271e-02,  4.8708e-03, -2.0666e-01, -4.0407e-02],\n",
       "                         [-5.9706e-02,  6.0825e-03, -5.7451e-02, -8.4085e-02],\n",
       "                         [-7.9138e-03, -2.5467e-02, -1.0743e-01, -1.8165e-02],\n",
       "                         [-4.2466e-02,  1.0683e-03, -6.4457e-02, -1.3894e-02]],\n",
       "               \n",
       "                        [[ 4.7761e-02, -2.6472e-02, -2.4372e-03,  3.1196e-02],\n",
       "                         [-1.7606e-02,  7.9379e-02,  4.3080e-02, -2.3295e-03],\n",
       "                         [ 2.3253e-02, -8.7959e-03,  1.4774e-02, -4.7239e-02],\n",
       "                         [ 3.7127e-02,  2.5612e-02, -5.8248e-02, -4.8855e-02]],\n",
       "               \n",
       "                        [[ 9.5514e-02,  6.1075e-02,  3.2542e-02,  5.4695e-02],\n",
       "                         [-1.8452e-02,  2.1842e-02, -9.4332e-02,  8.4995e-03],\n",
       "                         [ 7.9669e-03,  6.0328e-02, -1.8024e-02,  1.4033e-02],\n",
       "                         [-2.7913e-03,  6.3888e-02,  1.3801e-02,  2.8570e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.0544e-01,  6.0340e-02,  6.1174e-02,  4.3771e-02],\n",
       "                         [ 2.6777e-02,  9.0717e-02, -5.6051e-02, -1.6764e-02],\n",
       "                         [ 5.8664e-02,  7.4118e-02,  5.5969e-02,  3.4165e-02],\n",
       "                         [-6.5207e-03, -2.8236e-02,  1.9533e-04, -1.7275e-02]],\n",
       "               \n",
       "                        [[-1.8202e-02, -2.0183e-02,  1.8370e-02,  2.2009e-02],\n",
       "                         [-1.1382e-02,  4.5512e-02, -2.0499e-02,  1.9593e-02],\n",
       "                         [-1.2538e-02,  6.4548e-02,  9.1806e-04, -3.0124e-02],\n",
       "                         [-4.9416e-02, -2.5844e-02, -3.3404e-02, -6.2517e-02]],\n",
       "               \n",
       "                        [[ 9.9838e-03, -1.1966e-02,  5.9494e-02, -2.9544e-02],\n",
       "                         [ 3.8977e-02,  3.9729e-02,  8.9315e-02, -5.5428e-02],\n",
       "                         [ 5.5682e-03,  2.2613e-02,  1.1132e-02,  4.5408e-02],\n",
       "                         [-9.0726e-03, -2.7192e-02,  2.0980e-02,  4.6217e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0063e-02, -3.5892e-02, -4.8409e-02,  2.5921e-02],\n",
       "                         [ 2.3686e-02,  2.0268e-02, -5.1800e-02, -7.7867e-03],\n",
       "                         [-2.0995e-02, -1.4425e-02, -2.0389e-02,  9.4926e-02],\n",
       "                         [-2.9429e-03, -2.0208e-02, -3.3664e-02,  5.2027e-02]],\n",
       "               \n",
       "                        [[-1.7903e-02, -1.3545e-02,  8.5396e-03, -2.3993e-02],\n",
       "                         [ 3.2466e-02,  4.8815e-02,  1.6971e-02, -3.2860e-02],\n",
       "                         [-7.7890e-03,  2.8444e-02, -2.9765e-02, -2.5531e-02],\n",
       "                         [ 4.6319e-02,  1.4839e-02,  1.0048e-02, -1.3743e-02]],\n",
       "               \n",
       "                        [[-1.4903e-02, -1.7272e-02,  3.0237e-02,  2.7939e-02],\n",
       "                         [ 2.2868e-02,  9.7999e-03,  3.6169e-02, -3.6163e-02],\n",
       "                         [ 1.8686e-02, -1.5699e-02,  3.5920e-04,  4.3584e-02],\n",
       "                         [-2.5910e-02,  1.3753e-02,  1.3633e-02,  8.4079e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-4.3158e-02,  3.0780e-03, -3.5415e-02, -4.6717e-02],\n",
       "                         [ 4.0918e-02,  5.7132e-02,  1.0197e-02, -1.8917e-02],\n",
       "                         [ 2.8167e-02,  2.1296e-02, -2.6526e-02, -1.7588e-04],\n",
       "                         [-1.6996e-03,  1.6775e-02, -3.8667e-02,  6.3486e-04]],\n",
       "               \n",
       "                        [[ 1.9433e-02, -4.0915e-02, -4.7378e-03, -5.1339e-02],\n",
       "                         [-4.5875e-03, -2.0931e-02,  3.1550e-02,  2.7886e-02],\n",
       "                         [ 5.1393e-02,  5.4237e-02, -9.3296e-03, -1.7739e-02],\n",
       "                         [ 3.9954e-02, -1.9946e-02, -2.1227e-02, -1.8760e-02]],\n",
       "               \n",
       "                        [[-1.6047e-02, -3.5423e-02, -3.5928e-02, -2.0472e-02],\n",
       "                         [-3.8503e-02,  2.6707e-02, -3.2762e-02,  1.4813e-02],\n",
       "                         [-2.1124e-02,  1.3825e-03,  7.6696e-03, -1.2455e-02],\n",
       "                         [ 9.6168e-03,  4.1727e-03, -3.8681e-02, -2.9950e-02]]]])),\n",
       "              ('feature.2.bias',\n",
       "               tensor([ 0.0296,  0.0103, -0.0213,  0.0253, -0.0329,  0.0250, -0.0197, -0.0461,\n",
       "                       -0.0530, -0.0391, -0.0200, -0.0589, -0.0686,  0.0341, -0.0708, -0.0158,\n",
       "                        0.0154, -0.0385,  0.0206,  0.0277,  0.0719, -0.0730,  0.0225, -0.0232,\n",
       "                        0.0403, -0.0167, -0.0365,  0.0574, -0.0510, -0.0004, -0.0307,  0.0743,\n",
       "                       -0.0118,  0.0192, -0.0302,  0.0658,  0.0146, -0.0250, -0.0258, -0.0035,\n",
       "                       -0.0283,  0.0232, -0.0447, -0.0407,  0.0350, -0.0109, -0.0251,  0.0168,\n",
       "                        0.0026,  0.0393,  0.0101, -0.0261, -0.0020,  0.0075, -0.0355,  0.0015,\n",
       "                        0.0215, -0.0423, -0.0564,  0.0129,  0.0594, -0.0160, -0.0236,  0.0527])),\n",
       "              ('feature.4.weight',\n",
       "               tensor([[[[-3.0561e-02,  2.0608e-02,  2.7614e-02],\n",
       "                         [ 6.1638e-03,  8.5146e-03, -1.5310e-02],\n",
       "                         [ 5.9199e-02,  3.3866e-02, -6.3487e-02]],\n",
       "               \n",
       "                        [[-5.0760e-02, -6.9421e-03, -2.1282e-02],\n",
       "                         [ 6.4815e-02, -5.3733e-02,  3.8516e-02],\n",
       "                         [-7.8282e-02, -4.5230e-02,  1.6602e-03]],\n",
       "               \n",
       "                        [[ 8.2210e-03,  2.2809e-02, -3.8751e-02],\n",
       "                         [ 5.7329e-02,  1.3285e-02,  1.4572e-03],\n",
       "                         [-2.8608e-02,  1.2021e-02, -4.6068e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.8870e-02,  3.9920e-04,  4.0905e-02],\n",
       "                         [ 2.2434e-02,  3.8460e-03, -2.3890e-02],\n",
       "                         [ 1.4040e-02, -4.3556e-02, -5.9072e-02]],\n",
       "               \n",
       "                        [[-5.9865e-02,  3.7899e-02, -1.3230e-02],\n",
       "                         [-3.2325e-02,  3.8780e-02,  2.0885e-02],\n",
       "                         [ 3.3467e-02,  7.1835e-03, -5.0193e-02]],\n",
       "               \n",
       "                        [[ 3.7228e-02, -3.6324e-02,  2.4124e-02],\n",
       "                         [ 2.6174e-04,  2.3592e-02,  7.9896e-03],\n",
       "                         [-6.8375e-03, -2.0415e-02,  6.0535e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-8.8061e-03,  4.3546e-02, -5.9517e-02],\n",
       "                         [ 1.1230e-03, -2.5934e-03,  2.2889e-02],\n",
       "                         [ 8.9444e-03,  5.8893e-02,  4.4036e-04]],\n",
       "               \n",
       "                        [[ 3.2415e-02, -4.2661e-02,  2.5458e-02],\n",
       "                         [ 1.3798e-02, -4.7154e-03,  5.8952e-02],\n",
       "                         [-3.8827e-02, -5.7604e-02, -1.8215e-02]],\n",
       "               \n",
       "                        [[-1.1111e-02,  4.2990e-02, -4.9271e-02],\n",
       "                         [-1.4314e-02,  1.4265e-02,  3.7061e-02],\n",
       "                         [ 3.2812e-02,  6.2591e-02,  1.8443e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-8.4728e-03,  6.6381e-02,  1.5415e-02],\n",
       "                         [-6.9590e-02, -4.9803e-03,  9.0942e-02],\n",
       "                         [ 3.3815e-02, -3.4270e-02, -6.9748e-02]],\n",
       "               \n",
       "                        [[-5.3511e-02,  6.0391e-02, -4.4992e-02],\n",
       "                         [-3.0666e-02, -1.6352e-02,  5.4616e-02],\n",
       "                         [-6.5180e-02,  2.1695e-02,  6.5924e-02]],\n",
       "               \n",
       "                        [[ 3.9878e-02, -2.3889e-02,  9.8285e-03],\n",
       "                         [-2.6417e-02, -2.6770e-02, -1.5207e-02],\n",
       "                         [ 1.8426e-03,  2.3258e-02, -2.3839e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.0258e-02, -2.0278e-02, -1.9075e-02],\n",
       "                         [-2.1572e-02, -7.0053e-02,  5.0742e-02],\n",
       "                         [-3.5924e-03,  3.3303e-02,  8.2037e-02]],\n",
       "               \n",
       "                        [[-6.0857e-02,  1.2982e-02, -4.6400e-02],\n",
       "                         [-3.7731e-02,  6.6375e-03,  6.9339e-02],\n",
       "                         [ 3.6523e-02, -2.5688e-02, -5.0597e-02]],\n",
       "               \n",
       "                        [[-9.3343e-03, -1.3487e-02, -7.8350e-02],\n",
       "                         [ 8.2165e-02,  1.1400e-03,  1.0158e-01],\n",
       "                         [-6.5469e-02, -3.0793e-04,  5.5857e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 7.6199e-03,  9.9043e-02,  5.5337e-02],\n",
       "                         [-4.1075e-02, -3.4031e-02,  2.4860e-02],\n",
       "                         [ 4.4919e-02, -4.0000e-02,  1.7434e-02]],\n",
       "               \n",
       "                        [[-8.6702e-02,  2.0762e-02, -1.2633e-02],\n",
       "                         [-1.2932e-02, -2.0022e-03, -1.9161e-02],\n",
       "                         [-7.7424e-02, -8.4729e-02, -3.3918e-03]],\n",
       "               \n",
       "                        [[-3.2330e-02,  1.1865e-02,  1.1231e-02],\n",
       "                         [ 2.1319e-02,  1.0440e-02, -4.0678e-02],\n",
       "                         [-2.5749e-02,  1.4901e-02, -4.9953e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 4.8771e-03, -5.5516e-02, -7.8778e-02],\n",
       "                         [ 2.3477e-02, -6.4827e-02,  2.3161e-02],\n",
       "                         [ 3.0080e-02,  1.0299e-01,  2.3606e-02]],\n",
       "               \n",
       "                        [[ 2.1377e-02,  2.8734e-02,  1.0208e-03],\n",
       "                         [-2.2529e-02, -2.7846e-02,  2.5357e-02],\n",
       "                         [-3.2943e-03, -1.8529e-02, -1.9468e-02]],\n",
       "               \n",
       "                        [[ 4.2331e-03, -5.7957e-03, -3.9976e-03],\n",
       "                         [ 5.2777e-02,  3.1167e-02,  5.5166e-02],\n",
       "                         [ 2.9475e-02,  8.5420e-02, -9.0485e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-5.9594e-03, -2.8845e-03, -2.8174e-02],\n",
       "                         [-3.6761e-02,  4.7437e-02, -6.0802e-03],\n",
       "                         [ 3.4358e-02,  3.6849e-02,  3.9396e-02]],\n",
       "               \n",
       "                        [[ 3.3292e-02,  5.5318e-02, -5.8867e-02],\n",
       "                         [ 1.7856e-02,  4.3676e-02, -1.1038e-02],\n",
       "                         [-4.3404e-02, -3.0637e-02, -2.7720e-02]],\n",
       "               \n",
       "                        [[-2.4579e-02, -2.1426e-03, -1.6998e-02],\n",
       "                         [-5.7820e-04,  1.3625e-02, -6.6852e-04],\n",
       "                         [-1.2581e-03,  3.0225e-02, -3.7925e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 5.3248e-02, -2.2631e-02, -3.5471e-02],\n",
       "                         [-9.6220e-03,  2.2828e-02,  2.7262e-02],\n",
       "                         [-5.1738e-02, -4.8986e-02, -6.0719e-03]],\n",
       "               \n",
       "                        [[-3.5031e-02, -2.2527e-02,  3.5666e-02],\n",
       "                         [-5.0761e-02,  1.6040e-02,  8.6513e-02],\n",
       "                         [ 3.2234e-02, -1.6022e-02,  5.8246e-03]],\n",
       "               \n",
       "                        [[-8.5394e-02, -7.3000e-03, -3.4536e-03],\n",
       "                         [ 3.5468e-02,  1.5315e-02,  2.5580e-03],\n",
       "                         [ 1.5883e-02,  4.0540e-02,  7.1864e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-9.7160e-02, -8.9280e-03, -1.8487e-02],\n",
       "                         [ 3.5843e-02, -6.4846e-03,  8.0745e-02],\n",
       "                         [-2.5562e-02, -1.6839e-02, -5.4673e-02]],\n",
       "               \n",
       "                        [[ 6.7987e-02,  6.1690e-02,  1.8089e-02],\n",
       "                         [-2.2481e-02, -1.5379e-02, -6.9785e-02],\n",
       "                         [ 1.0799e-02, -3.2688e-02, -5.3770e-02]],\n",
       "               \n",
       "                        [[ 1.4260e-02,  2.7795e-02,  1.9069e-02],\n",
       "                         [ 2.6988e-03,  2.4406e-04, -2.4651e-02],\n",
       "                         [ 6.5027e-02,  6.8856e-02, -5.6338e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-5.2417e-02, -5.0074e-03,  7.4592e-02],\n",
       "                         [-7.2767e-02,  4.5139e-02,  8.8296e-02],\n",
       "                         [-2.7132e-02, -3.8106e-02,  1.1195e-02]],\n",
       "               \n",
       "                        [[ 4.2862e-03,  1.3721e-04,  3.2691e-02],\n",
       "                         [ 4.5552e-02, -2.1959e-03, -8.4963e-02],\n",
       "                         [-2.4563e-02,  2.2229e-02, -7.0459e-02]],\n",
       "               \n",
       "                        [[-4.2411e-02, -4.7897e-02, -8.6492e-02],\n",
       "                         [ 1.7021e-02, -4.7370e-03,  8.4735e-02],\n",
       "                         [-4.6282e-02, -1.4889e-02,  1.6720e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.9756e-02, -2.8504e-02,  2.3054e-02],\n",
       "                         [-2.9778e-02,  3.7983e-05, -1.2852e-02],\n",
       "                         [ 1.1145e-02, -8.1463e-03, -1.2602e-02]],\n",
       "               \n",
       "                        [[ 2.8839e-02,  1.4864e-02, -7.2069e-02],\n",
       "                         [-2.3758e-02, -2.3030e-02, -2.5603e-02],\n",
       "                         [-6.9714e-03,  6.6500e-03, -3.6780e-02]],\n",
       "               \n",
       "                        [[-2.5446e-02,  3.0886e-03, -3.4371e-02],\n",
       "                         [ 1.2669e-02, -9.5006e-03, -5.1608e-03],\n",
       "                         [-1.1279e-02, -3.7891e-02, -4.3551e-02]]]])),\n",
       "              ('feature.4.bias',\n",
       "               tensor([-0.0018,  0.0314,  0.0209,  0.0190,  0.0214,  0.0226,  0.0034, -0.0428,\n",
       "                        0.0137, -0.0079,  0.0248, -0.0164,  0.0266, -0.0440,  0.0194, -0.0224,\n",
       "                       -0.0183, -0.0361, -0.0396,  0.0415,  0.0284,  0.0251, -0.0118, -0.0416,\n",
       "                        0.0272, -0.0028,  0.0258, -0.0231, -0.0421,  0.0047, -0.0028, -0.0272,\n",
       "                       -0.0607, -0.0176, -0.0306, -0.0336, -0.0083, -0.0090, -0.0197, -0.0279,\n",
       "                        0.0213,  0.0154, -0.0128,  0.0227,  0.0258,  0.0138, -0.0160, -0.0293,\n",
       "                       -0.0318,  0.0101, -0.0045,  0.0355,  0.0084, -0.0274, -0.0145, -0.0150,\n",
       "                        0.0485,  0.0229, -0.0554, -0.0268, -0.0329,  0.0229,  0.0055,  0.0036])),\n",
       "              ('feature.7.weight',\n",
       "               tensor([[-6.6934e-03,  6.7940e-03,  2.7278e-02,  ..., -5.6861e-03,\n",
       "                        -9.2416e-03, -5.6742e-02],\n",
       "                       [ 8.9863e-03, -1.2931e-03,  2.9477e-02,  ..., -3.0968e-02,\n",
       "                        -4.6405e-05, -3.9049e-02],\n",
       "                       [-1.4401e-02, -4.4290e-02,  1.9083e-04,  ..., -1.2716e-02,\n",
       "                         1.2555e-02,  1.2198e-02],\n",
       "                       ...,\n",
       "                       [-1.9463e-02, -1.7401e-02, -1.9302e-02,  ...,  6.7058e-03,\n",
       "                        -2.2262e-03,  1.8268e-02],\n",
       "                       [-1.6657e-02, -1.2933e-02,  2.7062e-02,  ...,  3.1066e-02,\n",
       "                         9.2264e-03,  1.1945e-02],\n",
       "                       [-2.6284e-02, -1.7464e-03, -5.9972e-03,  ..., -3.3875e-02,\n",
       "                         1.9136e-02,  4.0896e-03]])),\n",
       "              ('feature.7.bias',\n",
       "               tensor([ 1.5858e-02, -3.7506e-03,  7.6012e-03, -2.0788e-02,  1.2812e-02,\n",
       "                       -1.3983e-02,  1.2697e-03, -9.3475e-03, -1.4024e-02, -2.8634e-03,\n",
       "                        6.5422e-03,  1.0304e-02, -8.8601e-03,  2.4401e-02, -1.0080e-03,\n",
       "                        1.9151e-02,  1.2997e-02,  1.2498e-02,  3.9755e-03, -1.7795e-03,\n",
       "                       -3.6987e-04, -8.3643e-03, -1.6139e-02,  1.4957e-02,  8.6352e-03,\n",
       "                        2.6254e-02,  1.6442e-02, -1.2398e-02,  1.9406e-03,  5.0691e-03,\n",
       "                        1.4851e-02,  4.3379e-03,  4.7264e-03, -6.1149e-03,  1.1031e-02,\n",
       "                       -5.7916e-03, -8.9081e-03, -1.7952e-03,  1.9139e-03, -1.2143e-02,\n",
       "                        5.3328e-03, -7.3233e-03, -1.7530e-02, -8.6298e-03, -1.8094e-02,\n",
       "                       -1.2410e-03,  4.0492e-03,  4.9092e-03,  1.1275e-02,  1.0883e-02,\n",
       "                        4.5134e-03,  9.6424e-03,  2.0223e-02,  1.2394e-02,  1.0366e-02,\n",
       "                       -1.2120e-04,  3.9912e-03,  1.5204e-02, -9.3860e-03, -4.9428e-03,\n",
       "                        2.3508e-03, -8.9003e-03,  2.4692e-03,  1.5514e-02,  1.5032e-02,\n",
       "                        3.0621e-02, -1.9988e-02,  6.0141e-02, -4.2891e-03,  6.3693e-03,\n",
       "                        1.0320e-02, -6.8895e-03, -1.7575e-03, -1.5486e-02,  1.3018e-02,\n",
       "                        6.0732e-03,  4.8809e-03, -1.3103e-02, -1.7480e-02,  8.4148e-03,\n",
       "                        3.9452e-03, -4.2920e-03, -5.1124e-04,  6.7791e-03, -5.7773e-03,\n",
       "                       -1.3504e-02, -1.0508e-02,  4.9861e-03, -9.4133e-03, -6.5974e-03,\n",
       "                        4.4258e-04,  1.5101e-02, -6.9866e-03,  1.5994e-02, -1.9727e-03,\n",
       "                        2.1492e-02,  8.4450e-03, -1.7650e-02,  1.4896e-02, -6.0581e-03,\n",
       "                       -1.6677e-02, -5.3288e-03, -1.1321e-02,  1.8889e-02,  2.3047e-02,\n",
       "                       -1.0390e-02,  3.6157e-02,  1.2538e-02, -1.2647e-03,  1.1906e-03,\n",
       "                       -1.7376e-02, -2.6939e-03, -8.3694e-03, -6.8904e-03, -1.5513e-03,\n",
       "                        2.8612e-02, -1.8196e-02,  2.2009e-02,  3.7683e-04, -9.8416e-03,\n",
       "                       -6.2260e-03,  8.6839e-03,  3.1736e-02,  1.6940e-02, -1.3612e-02,\n",
       "                        2.9476e-02, -6.1202e-03,  2.4708e-02,  9.6065e-03,  1.9655e-02,\n",
       "                       -1.4114e-02,  6.3087e-03, -6.9090e-03,  1.4483e-02,  2.1307e-03,\n",
       "                        1.6195e-03, -1.7461e-02, -1.3311e-03,  3.4501e-03, -8.7208e-03,\n",
       "                        1.5100e-02,  1.3425e-02, -1.4793e-02,  2.5227e-03, -2.0829e-03,\n",
       "                       -1.3855e-02, -1.6316e-03,  5.4229e-03, -3.7037e-03, -8.6023e-03,\n",
       "                       -1.2133e-02, -1.6291e-03,  3.0918e-02, -9.0935e-03,  2.4328e-03,\n",
       "                        3.4098e-04, -1.0947e-02,  1.2042e-03, -9.3725e-03,  1.3212e-03,\n",
       "                        1.2445e-02, -6.8473e-03, -3.4721e-03, -1.0052e-02, -1.3641e-02,\n",
       "                       -8.6260e-03,  1.1523e-02,  4.6639e-04, -7.4153e-03,  5.7176e-03,\n",
       "                       -1.1716e-02,  1.9572e-02, -8.6084e-03, -8.7782e-03,  2.6596e-02,\n",
       "                       -1.4813e-02,  2.4112e-03,  1.5818e-02, -1.2303e-03,  1.4670e-02,\n",
       "                       -8.5857e-03,  4.9188e-03,  1.8245e-02, -1.2088e-02,  4.0319e-03,\n",
       "                       -1.0417e-02, -1.4445e-03,  9.8254e-03, -8.9001e-03,  1.0292e-02,\n",
       "                        1.0578e-02,  2.6983e-03,  2.0770e-02,  5.8598e-03,  1.6757e-02,\n",
       "                        8.3131e-04,  4.6553e-03,  1.1398e-02, -1.0320e-02,  2.0706e-02,\n",
       "                        1.2914e-02, -1.7789e-02, -5.9605e-03, -1.0117e-02, -9.6660e-03,\n",
       "                       -1.2256e-02, -2.0138e-02, -3.7781e-04, -1.2757e-02,  3.5217e-03,\n",
       "                       -8.5116e-03,  1.2720e-02, -6.0156e-03,  1.3587e-02,  2.1117e-05,\n",
       "                        5.5380e-03, -4.9260e-03, -8.2926e-03, -5.1547e-03,  1.4262e-02,\n",
       "                       -1.4212e-02,  7.6804e-03,  2.4757e-02, -3.4341e-03, -9.9489e-03,\n",
       "                       -8.9424e-03,  5.5344e-03,  7.1507e-03,  1.9242e-03,  2.0704e-02,\n",
       "                       -4.1617e-03,  7.4047e-03,  7.5516e-03,  1.0426e-02,  1.2315e-02,\n",
       "                        3.0823e-03,  4.2623e-04, -1.3219e-02,  5.2682e-03,  3.7778e-02,\n",
       "                       -1.6730e-02,  1.4957e-02, -1.4562e-02,  1.2391e-02, -7.9261e-03,\n",
       "                        1.2477e-02,  9.0792e-04, -1.4537e-02, -1.8149e-02, -5.3774e-03,\n",
       "                       -1.5403e-02,  6.3128e-03, -1.1727e-02, -6.8647e-03,  6.0083e-03,\n",
       "                        1.8477e-02,  2.0192e-02, -9.2305e-03,  7.0919e-03,  2.2057e-02,\n",
       "                       -6.7113e-03, -1.3505e-02,  8.9789e-03,  1.9749e-02,  1.5302e-02,\n",
       "                        2.4075e-02,  1.6046e-02,  1.6460e-02, -1.6145e-02, -6.4479e-03,\n",
       "                        3.8903e-03,  1.0056e-02, -1.5841e-02, -7.8261e-03,  2.5024e-02,\n",
       "                       -5.4379e-03,  1.3485e-03, -1.7881e-02, -1.2660e-02,  6.0665e-03,\n",
       "                       -1.1302e-02,  3.5178e-03, -1.5695e-03,  3.8276e-04,  1.3897e-02,\n",
       "                        9.8079e-03,  3.8652e-02,  1.9591e-02, -3.7426e-03,  1.2848e-02,\n",
       "                        4.8159e-03,  6.5574e-03,  9.9101e-03, -8.3704e-03,  1.2068e-03,\n",
       "                        6.7306e-03,  2.3919e-03, -1.6983e-03,  2.3606e-02, -7.4441e-03,\n",
       "                       -5.0547e-03, -6.4660e-04, -1.4174e-02,  9.9423e-03, -2.0778e-02,\n",
       "                       -1.3347e-02, -1.5162e-02,  2.7890e-04,  2.2614e-02,  1.1950e-02,\n",
       "                        8.4370e-03, -7.8675e-03, -2.4741e-03,  2.3107e-02,  8.6167e-03,\n",
       "                       -9.4731e-04,  2.5227e-02, -3.1065e-03, -8.8786e-03,  1.2006e-02,\n",
       "                       -8.7749e-03, -8.6524e-04, -1.8109e-02, -2.3363e-03,  8.9715e-03,\n",
       "                       -1.1584e-02, -1.9693e-02, -8.9668e-03,  7.3838e-03,  3.7176e-03,\n",
       "                       -5.6924e-04,  4.9535e-03, -1.1998e-03,  3.0073e-02,  1.4760e-02,\n",
       "                       -1.4010e-02, -6.0914e-03,  1.6941e-02, -9.3386e-03, -1.9062e-03,\n",
       "                        7.3017e-03,  1.5378e-02,  4.7521e-03, -1.5889e-02, -7.9155e-03,\n",
       "                        6.6216e-03, -3.8047e-03, -1.3417e-02,  4.8414e-03,  1.4794e-02,\n",
       "                        2.3298e-03, -8.5929e-03, -1.5028e-02,  1.0668e-02,  1.3067e-02,\n",
       "                        4.7384e-03, -7.1461e-03,  8.8339e-03, -1.8308e-02, -1.2043e-02,\n",
       "                        4.7770e-02, -5.2785e-03,  1.6714e-02,  1.3342e-02, -8.2806e-03,\n",
       "                        8.3205e-03,  4.5865e-02, -1.2798e-02, -4.2679e-03,  1.1041e-02,\n",
       "                       -8.8345e-03, -1.9004e-02,  1.2635e-04, -5.3595e-03, -5.9987e-03,\n",
       "                       -7.3650e-03, -4.2987e-03, -1.5224e-02,  1.7508e-02, -1.4238e-02,\n",
       "                       -7.5813e-03,  1.8700e-02, -8.8784e-03, -7.7519e-04,  1.4402e-02,\n",
       "                        1.8980e-02, -1.5587e-02,  1.7203e-02,  3.3524e-02,  1.7862e-04,\n",
       "                       -1.8560e-02, -7.6239e-03,  5.5738e-03,  7.3860e-03,  1.5799e-02,\n",
       "                        1.5105e-03,  1.9414e-02, -7.2793e-03,  8.3211e-03, -1.3338e-02,\n",
       "                        1.1911e-02,  2.7674e-02, -1.7010e-02,  1.4771e-02, -1.0203e-02,\n",
       "                        1.3269e-02, -1.0703e-02, -1.5876e-02,  1.8773e-03, -9.2053e-03,\n",
       "                        6.7219e-04, -2.0303e-02,  1.2970e-02,  1.1267e-02,  1.6278e-03,\n",
       "                        2.4649e-02,  1.9898e-02, -1.0959e-02, -1.0055e-02,  4.5991e-03,\n",
       "                       -1.0806e-02, -1.3282e-02,  2.1918e-02,  4.9925e-03, -5.5837e-03,\n",
       "                        8.5525e-03, -1.9066e-02,  9.4436e-03,  2.4461e-02,  3.2259e-03,\n",
       "                        2.0515e-02,  1.3031e-02,  1.1366e-02, -3.4390e-03, -1.6959e-02,\n",
       "                        1.3229e-02,  2.3582e-02,  3.4440e-02, -1.0545e-02,  1.4167e-02,\n",
       "                        5.9003e-03, -1.4944e-02,  7.0661e-03,  2.3611e-02, -2.0871e-02,\n",
       "                        1.8519e-02,  6.2535e-04, -2.6484e-06, -2.0634e-02, -8.8746e-03,\n",
       "                       -9.7574e-03, -1.8725e-02,  1.3327e-02, -8.8511e-03,  1.4504e-02,\n",
       "                        1.3472e-02, -1.1619e-02,  5.8804e-03, -1.1153e-03,  3.9348e-03,\n",
       "                       -6.4684e-03, -1.2558e-02, -1.6161e-02,  1.5046e-02,  7.7903e-03,\n",
       "                       -1.0254e-02, -1.2995e-02,  1.0355e-03, -2.0079e-03,  3.2011e-02,\n",
       "                       -1.2370e-02, -1.7690e-02,  9.6056e-05,  1.1541e-02, -1.0791e-02,\n",
       "                        1.3051e-02, -4.0558e-03,  8.4538e-03, -8.5837e-03,  4.8622e-03,\n",
       "                        1.1417e-02,  3.0992e-02, -1.0262e-02,  3.4958e-03, -3.8144e-03,\n",
       "                       -2.7044e-03,  1.3064e-02,  3.1332e-03, -1.8888e-02, -1.2238e-02,\n",
       "                        1.8270e-02,  2.0989e-03,  1.5252e-02, -7.0708e-03, -1.0705e-02,\n",
       "                        5.1667e-03,  6.3178e-03, -9.1581e-03,  1.9478e-02,  8.2671e-04,\n",
       "                       -1.8154e-02,  4.4322e-05, -1.9033e-02, -8.2984e-03,  4.1104e-03,\n",
       "                        2.8420e-02,  1.2407e-02,  5.8612e-03, -2.7180e-03,  2.7433e-04,\n",
       "                       -2.5218e-02, -1.3293e-02])),\n",
       "              ('recurrent.weight_ih_l0',\n",
       "               tensor([[-0.0048,  0.0364,  0.0251,  ...,  0.0220, -0.0051,  0.0051],\n",
       "                       [ 0.0110, -0.0230,  0.0269,  ...,  0.0276,  0.0008, -0.0691],\n",
       "                       [ 0.0222,  0.0470, -0.0386,  ...,  0.0214,  0.0097,  0.0911],\n",
       "                       ...,\n",
       "                       [ 0.0478,  0.0248,  0.0359,  ...,  0.0440,  0.0374,  0.0208],\n",
       "                       [ 0.0360, -0.0263,  0.0053,  ...,  0.0300,  0.0318,  0.0518],\n",
       "                       [ 0.0103, -0.0332,  0.0169,  ..., -0.0303, -0.0140,  0.0060]])),\n",
       "              ('recurrent.weight_hh_l0',\n",
       "               tensor([[ 0.0325,  0.0003,  0.0320,  ..., -0.0147, -0.0458,  0.0304],\n",
       "                       [-0.0133, -0.0216, -0.0101,  ..., -0.0208,  0.0341,  0.0341],\n",
       "                       [-0.0010,  0.0448, -0.0351,  ..., -0.0355,  0.0479, -0.0433],\n",
       "                       ...,\n",
       "                       [ 0.0310, -0.0078,  0.0379,  ..., -0.0473,  0.0255, -0.0468],\n",
       "                       [ 0.0026,  0.0198,  0.0153,  ...,  0.0256, -0.0214,  0.0227],\n",
       "                       [ 0.0238,  0.0281, -0.0193,  ...,  0.0269,  0.0283, -0.0143]])),\n",
       "              ('recurrent.bias_ih_l0',\n",
       "               tensor([-0.0237,  0.0120,  0.0395,  ...,  0.0279,  0.0004,  0.0504])),\n",
       "              ('recurrent.bias_hh_l0',\n",
       "               tensor([ 0.0408,  0.0519,  0.0811,  ...,  0.0279, -0.0088,  0.0077])),\n",
       "              ('advantage.0.weight',\n",
       "               tensor([[ 3.4624e-02,  4.6144e-02,  3.9445e-02,  ...,  3.8646e-03,\n",
       "                        -2.1336e-02,  2.2247e-02],\n",
       "                       [ 1.6573e-02, -1.9136e-02, -1.2965e-02,  ...,  3.7238e-02,\n",
       "                        -1.9239e-02, -1.0376e-02],\n",
       "                       [ 2.5932e-02,  1.6632e-03,  1.2193e-02,  ..., -2.3994e-02,\n",
       "                        -3.5862e-02,  9.5356e-05],\n",
       "                       ...,\n",
       "                       [-1.2628e-02,  3.5172e-02,  7.9365e-03,  ...,  2.6319e-02,\n",
       "                         4.2215e-02, -2.2357e-02],\n",
       "                       [-4.5817e-02, -3.2315e-02, -2.4816e-02,  ..., -1.2664e-02,\n",
       "                        -2.6797e-03,  2.5157e-02],\n",
       "                       [-1.3645e-02, -2.3001e-02,  1.9676e-02,  ...,  2.9755e-02,\n",
       "                        -2.7843e-02, -1.8530e-02]])),\n",
       "              ('advantage.0.bias',\n",
       "               tensor([-0.0249,  0.0030, -0.0025,  0.0052, -0.0255, -0.0375, -0.0338, -0.0129,\n",
       "                       -0.0128,  0.0025, -0.0487, -0.0290,  0.0013, -0.0255,  0.0384,  0.0080,\n",
       "                       -0.0390, -0.0398, -0.0036, -0.0439, -0.0298, -0.0149,  0.0135, -0.0179,\n",
       "                       -0.0102, -0.0113, -0.0155,  0.0023,  0.0533, -0.0375,  0.0292,  0.0267,\n",
       "                       -0.0321,  0.0244,  0.0491,  0.0121,  0.0455,  0.0365,  0.0146, -0.0092,\n",
       "                        0.0447,  0.0378, -0.0394,  0.0140, -0.0147,  0.0373,  0.0010, -0.0252,\n",
       "                        0.0140,  0.0368, -0.0260, -0.0063,  0.0358,  0.0175,  0.0075, -0.0287,\n",
       "                       -0.0049, -0.0182, -0.0126, -0.0159,  0.0054, -0.0379, -0.0010, -0.0218,\n",
       "                        0.0330, -0.0073,  0.0003,  0.0270,  0.0280, -0.0021, -0.0116,  0.0173,\n",
       "                       -0.0292,  0.0229, -0.0053,  0.0337, -0.0179,  0.0421, -0.0329,  0.0091,\n",
       "                       -0.0517, -0.0116,  0.0427,  0.0179, -0.0158, -0.0312, -0.0272, -0.0455,\n",
       "                       -0.0182,  0.0264,  0.0472, -0.0518,  0.0288, -0.0031, -0.0427,  0.0253,\n",
       "                        0.0157, -0.0310, -0.0457,  0.0008,  0.0444,  0.0483,  0.0056, -0.0286,\n",
       "                       -0.0106, -0.0172,  0.0464,  0.0147, -0.0064, -0.0236,  0.0299,  0.0395,\n",
       "                        0.0165, -0.0361, -0.0329, -0.0338, -0.0179, -0.0172,  0.0569,  0.0311,\n",
       "                       -0.0428,  0.0096,  0.0009, -0.0093,  0.0034, -0.0279, -0.0256,  0.0207,\n",
       "                       -0.0135,  0.0084, -0.0264,  0.0063, -0.0088,  0.0237, -0.0202, -0.0310,\n",
       "                       -0.0299,  0.0016, -0.0080, -0.0267,  0.0219, -0.0470, -0.0203, -0.0216,\n",
       "                        0.0357, -0.0228, -0.0526, -0.0361, -0.0489, -0.0143,  0.0223,  0.0024,\n",
       "                        0.0206, -0.0323, -0.0183,  0.0133,  0.0083,  0.0259, -0.0198, -0.0495,\n",
       "                        0.0087,  0.0076,  0.0085, -0.0442, -0.0327,  0.0284,  0.0452,  0.0466,\n",
       "                       -0.0524, -0.0089, -0.0253, -0.0392, -0.0400,  0.0224, -0.0251, -0.0133,\n",
       "                       -0.0231,  0.0235, -0.0037,  0.0277, -0.0388, -0.0345,  0.0308,  0.0244,\n",
       "                        0.0142,  0.0358,  0.0204,  0.0150,  0.0061,  0.0418, -0.0141, -0.0227,\n",
       "                        0.0313, -0.0421, -0.0305,  0.0405, -0.0491, -0.0383,  0.0240, -0.0206,\n",
       "                       -0.0298, -0.0147, -0.0207,  0.0306, -0.0038,  0.0165, -0.0047, -0.0023,\n",
       "                        0.0070, -0.0231,  0.0264, -0.0207, -0.0039,  0.0196,  0.0061,  0.0099,\n",
       "                       -0.0016,  0.0042, -0.0361, -0.0325,  0.0435, -0.0071,  0.0032, -0.0243,\n",
       "                        0.0096,  0.0301, -0.0096,  0.0077,  0.0117, -0.0273,  0.0002, -0.0113,\n",
       "                       -0.0403, -0.0160, -0.0182,  0.0096, -0.0019, -0.0032,  0.0104,  0.0138,\n",
       "                       -0.0087,  0.0181,  0.0087, -0.0260, -0.0019, -0.0167, -0.0045, -0.0142,\n",
       "                        0.0398, -0.0206,  0.0002, -0.0308,  0.0301, -0.0379, -0.0564,  0.0119,\n",
       "                       -0.0233,  0.0147, -0.0410, -0.0020, -0.0460, -0.0180, -0.0014, -0.0161,\n",
       "                        0.0055,  0.0061,  0.0255,  0.0165, -0.0007, -0.0279, -0.0311, -0.0637,\n",
       "                        0.0120, -0.0576,  0.0005,  0.0217, -0.0249, -0.0273,  0.0426,  0.0265,\n",
       "                       -0.0409, -0.0351, -0.0003,  0.0186, -0.0120,  0.0494, -0.0382, -0.0179,\n",
       "                       -0.0244,  0.0078, -0.0216, -0.0162, -0.0235,  0.0241,  0.0288, -0.0416,\n",
       "                       -0.0162,  0.0272,  0.0071, -0.0108, -0.0391,  0.0370,  0.0059,  0.0095,\n",
       "                        0.0151, -0.0340, -0.0142,  0.0345, -0.0143, -0.0481, -0.0035,  0.0043,\n",
       "                       -0.0404, -0.0445, -0.0128, -0.0209, -0.0312,  0.0433,  0.0229,  0.0306,\n",
       "                       -0.0262, -0.0267, -0.0174,  0.0170, -0.0114,  0.0429,  0.0390,  0.0272,\n",
       "                       -0.0456, -0.0024,  0.0095, -0.0361,  0.0209, -0.0283,  0.0108, -0.0378,\n",
       "                       -0.0065, -0.0220,  0.0611, -0.0410, -0.0053,  0.0047,  0.0007,  0.0323,\n",
       "                       -0.0205,  0.0470, -0.0028, -0.0252,  0.0128, -0.0379,  0.0358,  0.0365,\n",
       "                        0.0060,  0.0258, -0.0108,  0.0385,  0.0331,  0.0549, -0.0505,  0.0294,\n",
       "                        0.0304,  0.0135,  0.0312, -0.0014, -0.0122,  0.0349,  0.0211, -0.0411,\n",
       "                        0.0351, -0.0122,  0.0272,  0.0090, -0.0125,  0.0257, -0.0073,  0.0491,\n",
       "                        0.0061,  0.0246, -0.0424, -0.0155,  0.0155, -0.0099, -0.0121,  0.0088,\n",
       "                        0.0053,  0.0207, -0.0027, -0.0393, -0.0329, -0.0233,  0.0061,  0.0550,\n",
       "                       -0.0111,  0.0247, -0.0019,  0.0245, -0.0167, -0.0428,  0.0022,  0.0308,\n",
       "                       -0.0152,  0.0124, -0.0250, -0.0515, -0.0432,  0.0302, -0.0227, -0.0193,\n",
       "                        0.0042, -0.0078, -0.0398, -0.0403,  0.0325,  0.0482, -0.0152,  0.0003,\n",
       "                        0.0040,  0.0301,  0.0108, -0.0230,  0.0248, -0.0070, -0.0329,  0.0221,\n",
       "                       -0.0373,  0.0086, -0.0224,  0.0403, -0.0202,  0.0376,  0.0153, -0.0059,\n",
       "                       -0.0140, -0.0037, -0.0135,  0.0076, -0.0152, -0.0368,  0.0048,  0.0036,\n",
       "                        0.0359,  0.0422,  0.0107, -0.0387, -0.0136, -0.0412, -0.0390, -0.0129,\n",
       "                       -0.0013,  0.0136, -0.0440,  0.0235, -0.0145,  0.0403, -0.0250,  0.0004,\n",
       "                       -0.0119, -0.0157,  0.0168, -0.0427,  0.0208, -0.0249,  0.0169,  0.0404,\n",
       "                        0.0026,  0.0230, -0.0098, -0.0259, -0.0450,  0.0258,  0.0024,  0.0467,\n",
       "                       -0.0079, -0.0205, -0.0314,  0.0085,  0.0171,  0.0146,  0.0044, -0.0064,\n",
       "                        0.0341, -0.0010,  0.0083,  0.0295,  0.0454, -0.0136,  0.0200, -0.0190,\n",
       "                       -0.0187,  0.0306, -0.0152, -0.0554, -0.0291,  0.0189,  0.0445,  0.0099,\n",
       "                       -0.0403, -0.0243, -0.0437, -0.0401, -0.0050,  0.0189, -0.0128, -0.0260,\n",
       "                        0.0229, -0.0318,  0.0198,  0.0232, -0.0407, -0.0353,  0.0320,  0.0229])),\n",
       "              ('advantage.2.weight',\n",
       "               tensor([[-0.0082,  0.0483, -0.0342,  ..., -0.0448, -0.0637, -0.0156],\n",
       "                       [ 0.0450,  0.0309,  0.0448,  ..., -0.0510,  0.0345, -0.0681],\n",
       "                       [-0.0368, -0.0332, -0.0270,  ...,  0.0472, -0.0313, -0.0508],\n",
       "                       ...,\n",
       "                       [ 0.0587, -0.0807, -0.0457,  ...,  0.0213,  0.0557,  0.0305],\n",
       "                       [-0.0679,  0.0410,  0.0360,  ...,  0.0494, -0.0543,  0.0444],\n",
       "                       [ 0.0984,  0.0134, -0.0599,  ..., -0.0288,  0.0346,  0.0619]])),\n",
       "              ('advantage.2.bias',\n",
       "               tensor([ 0.0168, -0.0518, -0.0005, -0.0350,  0.0242,  0.0012, -0.0357,  0.0302,\n",
       "                        0.0648])),\n",
       "              ('value.0.weight',\n",
       "               tensor([[-0.0240,  0.0308,  0.0584,  ...,  0.0100, -0.0116, -0.0006],\n",
       "                       [-0.0275,  0.0014,  0.0222,  ...,  0.0673,  0.0069,  0.0441],\n",
       "                       [ 0.0398,  0.0275, -0.0143,  ...,  0.0393,  0.0352, -0.0111],\n",
       "                       ...,\n",
       "                       [ 0.0046, -0.0089, -0.0420,  ...,  0.0369,  0.0393, -0.0305],\n",
       "                       [-0.0006, -0.0050, -0.0162,  ..., -0.0277,  0.0342,  0.0464],\n",
       "                       [-0.0050,  0.0303,  0.0257,  ...,  0.0497,  0.0517,  0.0220]])),\n",
       "              ('value.0.bias',\n",
       "               tensor([ 0.0196, -0.0363,  0.0565,  0.0181,  0.0179, -0.0492,  0.0637,  0.0089,\n",
       "                        0.0142, -0.0224,  0.0532,  0.0506,  0.0124,  0.0495, -0.0385, -0.0384,\n",
       "                        0.0541, -0.0364, -0.0177, -0.0241,  0.0223,  0.0541,  0.0145,  0.0041,\n",
       "                        0.0282,  0.0841, -0.0317, -0.0331, -0.0486, -0.0384, -0.0090,  0.0629,\n",
       "                       -0.0132,  0.0176,  0.0029,  0.0072, -0.0469,  0.0185, -0.0216,  0.0713,\n",
       "                        0.0517,  0.0590, -0.0423,  0.0523, -0.0316,  0.0125,  0.0594,  0.0103,\n",
       "                        0.0762, -0.0590, -0.0129,  0.0173, -0.0290,  0.0637,  0.0263,  0.0315,\n",
       "                       -0.0343, -0.0603, -0.0377,  0.0539, -0.0027,  0.0660,  0.0211,  0.0875,\n",
       "                       -0.0255,  0.0383, -0.0447, -0.0135,  0.0098,  0.0292, -0.0319,  0.0652,\n",
       "                        0.0816,  0.0535,  0.0762,  0.0531,  0.0626, -0.0298, -0.0033,  0.0528,\n",
       "                        0.0074,  0.0260, -0.0176, -0.0431,  0.0478, -0.0170,  0.0303,  0.0132,\n",
       "                        0.0700, -0.0343,  0.0791,  0.0407, -0.0343,  0.0592,  0.0017,  0.0817,\n",
       "                       -0.0528,  0.0003, -0.0004,  0.0053,  0.0243, -0.0029,  0.0919, -0.0412,\n",
       "                        0.0351,  0.0777,  0.0006, -0.0323, -0.0249, -0.0269, -0.0425,  0.0023,\n",
       "                       -0.0211, -0.0200, -0.0053,  0.0245,  0.0653, -0.0355,  0.0327, -0.0157,\n",
       "                        0.0686, -0.0013, -0.0065, -0.0349, -0.0071,  0.0719, -0.0440,  0.0230,\n",
       "                        0.0576,  0.0443, -0.0551,  0.0027,  0.0545,  0.0701, -0.0041,  0.0862,\n",
       "                        0.0669,  0.0609, -0.0556, -0.0376,  0.0020,  0.0165, -0.0197,  0.0166,\n",
       "                        0.0170, -0.0359,  0.0789,  0.0591, -0.0264,  0.0855, -0.0205, -0.0164,\n",
       "                       -0.0072,  0.0114,  0.0134,  0.0117,  0.0391, -0.0383, -0.0015,  0.0170,\n",
       "                        0.0821,  0.0435, -0.0164,  0.0364, -0.0470, -0.0053,  0.0467,  0.0088,\n",
       "                        0.0414, -0.0079, -0.0056,  0.0138,  0.0520,  0.0576,  0.0258,  0.0777,\n",
       "                       -0.0164,  0.0607, -0.0379,  0.0722,  0.0607, -0.0141,  0.0837,  0.0584,\n",
       "                       -0.0522, -0.0273, -0.0241,  0.0610, -0.0065, -0.0111,  0.0096, -0.0242,\n",
       "                        0.0743,  0.0061, -0.0295,  0.0066,  0.0211, -0.0147,  0.0035,  0.0847,\n",
       "                       -0.0020, -0.0411,  0.0320,  0.0833, -0.0514,  0.0125,  0.0797,  0.0142,\n",
       "                        0.0069, -0.0185, -0.0348,  0.0237,  0.0008,  0.0009, -0.0169,  0.0203,\n",
       "                        0.0392, -0.0382, -0.0602,  0.0535,  0.0346,  0.0896, -0.0341,  0.0381,\n",
       "                       -0.0234,  0.0043,  0.0235,  0.0070,  0.0897,  0.0593,  0.0245,  0.0435,\n",
       "                       -0.0476,  0.0368, -0.0102,  0.0648, -0.0400,  0.0100,  0.0294,  0.0731,\n",
       "                       -0.0331, -0.0329, -0.0204, -0.0423,  0.0311, -0.0593, -0.0422,  0.0246,\n",
       "                        0.0519,  0.0016,  0.0892,  0.0573, -0.0364,  0.0120,  0.0322, -0.0258,\n",
       "                        0.0159, -0.0394,  0.0807,  0.0529, -0.0336, -0.0335,  0.0090,  0.0788,\n",
       "                        0.0757, -0.0234, -0.0349, -0.0086,  0.0035, -0.0712,  0.0621, -0.0138,\n",
       "                        0.0743, -0.0139, -0.0005, -0.0499,  0.0463,  0.0206,  0.0471, -0.0610,\n",
       "                       -0.0397,  0.0457,  0.0248,  0.0085,  0.0179, -0.0295,  0.0659,  0.0701,\n",
       "                        0.0459, -0.0213,  0.0671, -0.0308, -0.0044, -0.0449,  0.0202,  0.0759,\n",
       "                       -0.0289, -0.0166,  0.0578, -0.0425,  0.0263,  0.0087,  0.0714,  0.0061,\n",
       "                       -0.0031, -0.0408, -0.0097, -0.0102,  0.0536, -0.0083, -0.0111, -0.0500,\n",
       "                       -0.0087, -0.0211, -0.0440,  0.0061,  0.0451,  0.0188,  0.0409, -0.0182,\n",
       "                        0.0086,  0.0850,  0.0408, -0.0331, -0.0218, -0.0495,  0.0011,  0.0284,\n",
       "                       -0.0020,  0.0255,  0.0250, -0.0229, -0.0098,  0.0461,  0.0018, -0.0247,\n",
       "                        0.0032,  0.0659,  0.0398, -0.0326,  0.0334,  0.0031,  0.0696,  0.0081,\n",
       "                        0.0483,  0.0749,  0.0232,  0.0443,  0.0401, -0.0114,  0.0529,  0.0066,\n",
       "                       -0.0143,  0.0630, -0.0456,  0.0129, -0.0114, -0.0369,  0.0035,  0.0647,\n",
       "                       -0.0030,  0.0774,  0.0752,  0.0822, -0.0482, -0.0038,  0.0303, -0.0167,\n",
       "                        0.0047, -0.0280, -0.0355, -0.0056,  0.0346,  0.0246, -0.0495,  0.0127,\n",
       "                       -0.0239,  0.0272,  0.0847,  0.0586, -0.0539, -0.0048,  0.0314,  0.0199,\n",
       "                       -0.0099, -0.0084, -0.0245,  0.0733, -0.0048,  0.0513,  0.0437,  0.0217,\n",
       "                       -0.0169,  0.0392,  0.0197, -0.0252,  0.0603, -0.0208,  0.0363,  0.0370,\n",
       "                       -0.0303,  0.0095,  0.0640, -0.0225, -0.0259,  0.0179, -0.0288, -0.0268,\n",
       "                       -0.0205,  0.0822, -0.0461,  0.0074,  0.0416,  0.0168,  0.0655,  0.0018,\n",
       "                       -0.0149, -0.0493, -0.0272, -0.0143,  0.0825,  0.0229, -0.0206,  0.0636,\n",
       "                       -0.0184,  0.0751,  0.0165, -0.0294,  0.0725,  0.0761, -0.0301, -0.0390,\n",
       "                        0.0449,  0.0734,  0.0176, -0.0083,  0.0250,  0.0059, -0.0248,  0.0677,\n",
       "                        0.0478,  0.0092,  0.0128,  0.0526, -0.0208, -0.0065,  0.0530,  0.0088,\n",
       "                        0.0702, -0.0185, -0.0272, -0.0025,  0.0367, -0.0235,  0.0285, -0.0490,\n",
       "                       -0.0495, -0.0058,  0.0455,  0.0461, -0.0147,  0.0400, -0.0255, -0.0243,\n",
       "                       -0.0082,  0.0593,  0.0610, -0.0691, -0.0418,  0.0069,  0.0157,  0.0600,\n",
       "                       -0.0092,  0.0792,  0.0049, -0.0413, -0.0020, -0.0442,  0.0254,  0.0171,\n",
       "                        0.0035,  0.0272,  0.0708,  0.0288, -0.0009, -0.0082, -0.0248, -0.0436,\n",
       "                        0.0224,  0.0442,  0.0237,  0.0360,  0.0516, -0.0445, -0.0256,  0.0751,\n",
       "                       -0.0296, -0.0275, -0.0274,  0.0036,  0.0444, -0.0411, -0.0461,  0.0029,\n",
       "                        0.0130, -0.0654, -0.0210, -0.0252,  0.0463,  0.0091, -0.0140, -0.0189])),\n",
       "              ('value.2.weight',\n",
       "               tensor([[ 0.1835,  0.3947,  0.0650,  0.2483, -0.0904, -0.2775,  0.0515,  0.0563,\n",
       "                         0.0642,  0.2507,  0.1205,  0.0619, -0.1012,  0.0876, -0.1227, -0.1861,\n",
       "                         0.1028,  0.1405, -0.0415, -0.0474, -0.0495,  0.0934, -0.1865,  0.0560,\n",
       "                        -0.1356,  0.0728, -0.2535, -0.0918, -0.0884, -0.1730, -0.0278,  0.0390,\n",
       "                         0.2775, -0.0967, -0.0668, -0.1074, -0.0769,  0.0962,  0.0649,  0.0535,\n",
       "                         0.0616,  0.1018, -0.0784,  0.0755, -0.1966,  0.1319,  0.0441,  0.2631,\n",
       "                         0.0763, -0.1279, -0.1064, -0.1783,  0.0417,  0.0760, -0.1129, -0.1560,\n",
       "                        -0.1253, -0.1500, -0.0812,  0.0670,  0.0431,  0.0649,  0.1053,  0.0515,\n",
       "                         0.0605, -0.2302, -0.0741, -0.0209,  0.1601,  0.0425, -0.0433,  0.0885,\n",
       "                         0.0743,  0.0854,  0.0617,  0.0533,  0.0522, -0.1501,  0.1921,  0.0917,\n",
       "                         0.0671, -0.1133,  0.3113, -0.1100,  0.0896,  0.0260,  0.0660, -0.1715,\n",
       "                         0.0797,  0.0529,  0.0685,  0.0978, -0.1663,  0.0932, -0.1322,  0.0909,\n",
       "                        -0.1103,  0.0749, -0.1162, -0.1653, -0.1247, -0.1480,  0.0788, -0.1066,\n",
       "                         0.0706,  0.0439, -0.1920, -0.0512, -0.1369, -0.2613, -0.1467,  0.2340,\n",
       "                         0.2218,  0.2484, -0.1166,  0.0938,  0.0646, -0.0908,  0.1351,  0.2173,\n",
       "                         0.0835,  0.0644,  0.1122, -0.2139, -0.1016,  0.0861,  0.3679, -0.0749,\n",
       "                         0.0264,  0.0626, -0.4795, -0.1014,  0.0306,  0.0708, -0.2481,  0.0660,\n",
       "                         0.0687,  0.0648, -0.1380,  0.1899, -0.1814,  0.1641,  0.2421, -0.1993,\n",
       "                        -0.1509, -0.1836,  0.0783,  0.0604, -0.0767,  0.0724, -0.2058,  0.2174,\n",
       "                         0.2481,  0.1743, -0.1123, -0.2026,  0.0367, -0.0482,  0.1366,  0.1036,\n",
       "                         0.0555,  0.0619, -0.0115,  0.0510,  0.3046,  0.1285,  0.0726, -0.0825,\n",
       "                         0.0601, -0.1550,  0.2235,  0.3508,  0.0914,  0.0570,  0.0905,  0.0744,\n",
       "                        -0.1122,  0.0919, -0.1415,  0.0570,  0.0756, -0.1415,  0.0653,  0.0873,\n",
       "                        -0.1423, -0.1522, -0.0037,  0.0781, -0.2610, -0.1329, -0.0286, -0.1597,\n",
       "                         0.0823, -0.0552, -0.1423, -0.1686, -0.1711,  0.0332, -0.0668,  0.0675,\n",
       "                        -0.1893, -0.1351,  0.1490,  0.0764, -0.1015, -0.1266,  0.0804, -0.1718,\n",
       "                        -0.0401,  0.1541, -0.2332, -0.1045,  0.3231,  0.2278, -0.0905, -0.1280,\n",
       "                         0.0984, -0.0504, -0.1507,  0.1463,  0.0747,  0.0829, -0.1420,  0.0715,\n",
       "                        -0.0252, -0.1351,  0.2042, -0.2290,  0.0809,  0.0771, -0.0390,  0.0559,\n",
       "                        -0.1409,  0.0295, -0.0900,  0.0707, -0.0786, -0.1452,  0.2097,  0.0789,\n",
       "                        -0.0857, -0.2126,  0.0799, -0.0394,  0.2996, -0.1509, -0.1001, -0.0458,\n",
       "                         0.0482,  0.2928,  0.0781,  0.0931, -0.2019, -0.1236,  0.1142, -0.1675,\n",
       "                        -0.1643, -0.1259,  0.0909,  0.2302, -0.0550, -0.1504,  0.2655,  0.0662,\n",
       "                         0.0817, -0.0873, -0.1593, -0.1039,  0.2480, -0.1365,  0.0534,  0.2541,\n",
       "                         0.0734,  0.2646,  0.0821, -0.1715,  0.0403, -0.0681,  0.0623, -0.1291,\n",
       "                        -0.0715,  0.0639, -0.1188, -0.0826,  0.0783, -0.0827,  0.0554,  0.0485,\n",
       "                         0.0795, -0.0778,  0.0775, -0.2594, -0.0916, -0.2362,  0.0677,  0.0782,\n",
       "                         0.0054, -0.0384,  0.0919, -0.1554,  0.0790, -0.0862,  0.0474,  0.1273,\n",
       "                        -0.0856, -0.2386,  0.1041,  0.1856,  0.0955, -0.0971, -0.0775, -0.1853,\n",
       "                        -0.1122,  0.0768,  0.3100, -0.0506,  0.0751,  0.0793,  0.1160, -0.2290,\n",
       "                        -0.1335,  0.0872,  0.0918,  0.2667, -0.1535, -0.1152, -0.1309, -0.1837,\n",
       "                        -0.0660,  0.1078, -0.1014, -0.2060,  0.1190,  0.0533,  0.0134, -0.0893,\n",
       "                         0.0674,  0.0788,  0.1167, -0.0275,  0.0870,  0.2420,  0.0914,  0.2384,\n",
       "                         0.0688,  0.0815, -0.0730,  0.0811,  0.0780, -0.1019,  0.1654,  0.3451,\n",
       "                         0.1669,  0.0624, -0.1033, -0.0917, -0.1512,  0.2729,  0.2270,  0.1150,\n",
       "                        -0.0921,  0.0413,  0.0853,  0.0556, -0.1328, -0.1837,  0.0676,  0.2878,\n",
       "                         0.0929, -0.0325,  0.1648,  0.0307,  0.1266, -0.0562, -0.1497,  0.0809,\n",
       "                         0.1858,  0.0603,  0.0681,  0.0784, -0.1905, -0.1196,  0.0669, -0.2158,\n",
       "                         0.1495, -0.1696, -0.1094,  0.0596, -0.0412,  0.0708,  0.0741, -0.0980,\n",
       "                        -0.0745,  0.2491,  0.0792, -0.4108,  0.0874,  0.3469,  0.0858,  0.0787,\n",
       "                        -0.2346, -0.1653,  0.1234,  0.2161,  0.1474,  0.0697,  0.2538, -0.0649,\n",
       "                        -0.0911,  0.0887, -0.2627, -0.1953,  0.0935, -0.0757,  0.0722, -0.1238,\n",
       "                        -0.1145, -0.0479,  0.0503, -0.1541,  0.0943,  0.1098, -0.1021,  0.0670,\n",
       "                         0.2897,  0.0722, -0.0814, -0.1024,  0.0682,  0.0905, -0.0864, -0.0253,\n",
       "                         0.0956,  0.0851,  0.0727, -0.0761, -0.1193, -0.1229,  0.2597,  0.0975,\n",
       "                         0.0553,  0.0745,  0.1965,  0.0664,  0.2938,  0.0362,  0.0610,  0.0919,\n",
       "                         0.0714, -0.3263,  0.0326, -0.1366,  0.0304,  0.2188, -0.1134, -0.3071,\n",
       "                        -0.1339, -0.1222,  0.0792,  0.2057, -0.1084,  0.0896,  0.2103,  0.2010,\n",
       "                         0.0011,  0.0850,  0.0889, -0.1600, -0.0380, -0.0972,  0.0892,  0.0838,\n",
       "                        -0.1181,  0.0840, -0.0255, -0.1164,  0.0399, -0.1017,  0.0674,  0.0924,\n",
       "                        -0.1699,  0.0774,  0.0875,  0.1034,  0.2906, -0.1116, -0.0958, -0.1811,\n",
       "                        -0.0505,  0.2872,  0.0788,  0.0607,  0.0839, -0.1073, -0.2843,  0.0565,\n",
       "                        -0.0670,  0.2140, -0.2262,  0.0952,  0.1251, -0.2005,  0.3894, -0.0844,\n",
       "                         0.1242, -0.1538, -0.1705, -0.1383,  0.0634,  0.2456, -0.0715,  0.1873]])),\n",
       "              ('value.2.bias', tensor([0.0905]))]),\n",
       " 41000,\n",
       " 3045004,\n",
       " 273.0289812882741)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('models/r2d2/MsPacman-v5/41000.pth', map_location='cpu')\n",
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3264dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2530.0\n"
     ]
    }
   ],
   "source": [
    "env = create_env(game_name, render=True)\n",
    "n_observations = env.observation_space.shape\n",
    "n_actions = env.action_space.n\n",
    "model = Network(n_observations, n_actions)\n",
    "model.load_state_dict(checkpoint[0])\n",
    "obs, _ = env.reset()\n",
    "state = AgentState(torch.from_numpy(obs).unsqueeze(0), n_actions)\n",
    "done = False\n",
    "total_reward = 0\n",
    "while not done:\n",
    "    with torch.no_grad():\n",
    "        q_value, hidden = model(state)\n",
    "    action = torch.argmax(q_value, 1).item()\n",
    "    obs, reward, terminated, truncated, _, = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    total_reward += reward\n",
    "    state.update(obs, action, reward, hidden)\n",
    "env.close()\n",
    "print(total_reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
