{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T09:46:31.194271Z",
     "start_time": "2024-05-14T09:46:28.404470Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import threading\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "import cv2\n",
    "# from tensorboardX import SummaryWriter\n",
    "# from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7809a363e30f2a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_name = 'CartPole-v1'\n",
    "\n",
    "lr = 1e-4  \n",
    "eps = 1e-3  \n",
    "grad_norm = 40  \n",
    "batch_size = 32  \n",
    "learning_starts = 1000  \n",
    "save_interval = 100  \n",
    "target_net_update_interval = 500  \n",
    "gamma = 0.99  \n",
    "prio_exponent = 0.9  \n",
    "importance_sampling_exponent = 0.6  \n",
    "\n",
    "training_steps = 50000  \n",
    "buffer_capacity = 50000  \n",
    "max_episode_steps = 200  \n",
    "actor_update_interval = 100  \n",
    "block_length = 40  \n",
    "\n",
    "num_actors = 8  \n",
    "base_eps = 0.4  \n",
    "alpha = 7  \n",
    "log_interval = 10  \n",
    "\n",
    "# sequence setting\n",
    "burn_in_steps = 0  \n",
    "learning_steps = 20  \n",
    "forward_steps = 5  \n",
    "seq_len = burn_in_steps + learning_steps + forward_steps\n",
    "\n",
    "# network setting\n",
    "hidden_dim = 256  \n",
    "\n",
    "render = False  \n",
    "save_plot = True  \n",
    "test_epsilon = 0.001  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6457872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_env(env_name=game_name, render=False):\n",
    "\n",
    "    env = gym.make(env_name, render_mode='human' if render else None)\n",
    "\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36cbf333688b51ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriorityTree:\n",
    "    def __init__(self, capacity, prio_exponent, is_exponent):\n",
    "        self.num_layers = 1\n",
    "        while capacity > 2**(self.num_layers - 1):\n",
    "            self.num_layers += 1\n",
    "        \n",
    "        self.ptree = np.zeros(2**self.num_layers - 1, dtype=np.float64)\n",
    "        \n",
    "        self.prio_exponent = prio_exponent\n",
    "        self.is_exponent = is_exponent\n",
    "    \n",
    "    def update(self, idxes: np.ndarray, td_error: np.ndarray) -> None:\n",
    "        priorities = td_error ** self.prio_exponent\n",
    "        \n",
    "        idxes = idxes + 2**(self.num_layers - 1) - 1\n",
    "        self.ptree[idxes] = priorities\n",
    "        \n",
    "        for _ in range(self.num_layers - 1):\n",
    "            idxes = (idxes - 1) // 2\n",
    "            idxes = np.unique(idxes)\n",
    "            self.ptree[idxes] = self.ptree[2 * idxes + 1] + self.ptree[2 * idxes + 2]\n",
    "    \n",
    "    def sample(self, num_samples: int) -> tuple[np.ndarray, np.ndarray]:\n",
    "        p_sum = self.ptree[0]\n",
    "        interval = p_sum / num_samples\n",
    "        \n",
    "        prefixsums = np.arange(0, p_sum, interval, dtype=np.float64) + np.random.uniform(0, interval, num_samples)\n",
    "        \n",
    "        idxes = np.zeros(num_samples, dtype=np.int64)\n",
    "        for _ in range(self.num_layers-1):\n",
    "            nodes = self.ptree[2 * idxes + 1]\n",
    "            idxes = np.where(prefixsums < nodes, 2 * idxes + 1, 2 * idxes + 2)\n",
    "            prefixsums = np.where(idxes%2 == 0, prefixsums - self.ptree[idxes-1], prefixsums)\n",
    "        \n",
    "        priorities = self.ptree[idxes]\n",
    "        min_p = np.min(priorities)\n",
    "        is_weigths = np.power(priorities/min_p, -self.is_exponent)\n",
    "        \n",
    "        idxes -= 2**(self.num_layers - 1) - 1\n",
    "        \n",
    "        return idxes, is_weigths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d92553642b4f78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Block:\n",
    "    obs: np.array\n",
    "    last_action: np.array\n",
    "    last_reward: np.array\n",
    "    action: np.array\n",
    "    n_step_reward: np.array\n",
    "    gamma: np.array\n",
    "    num_sequences: int\n",
    "    burn_in_steps: np.array\n",
    "    learning_steps: np.array\n",
    "    forward_steps: np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6533684a57fe978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, sample_queue_list, batch_queue, priority_queue, alpha=prio_exponent, beta=importance_sampling_exponent):\n",
    "        self.buffer_capacity = buffer_capacity\n",
    "        self.sequence_len = learning_steps\n",
    "        self.num_sequences = buffer_capacity // self.sequence_len\n",
    "        self.block_len = block_length\n",
    "        self.num_blocks = self.buffer_capacity // self.block_len\n",
    "        self.seq_pre_block = self.block_len // self.sequence_len\n",
    "        \n",
    "        self.block_ptr = 0\n",
    "        \n",
    "        self.priority_tree = PriorityTree(self.num_sequences, alpha, beta)\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.env_steps = 0\n",
    "        \n",
    "        self.num_episodes = 0\n",
    "        self.episode_reward = 0\n",
    "        \n",
    "        self.training_steps = 0\n",
    "        self.last_training_steps = 0\n",
    "        self.sum_loss = 0\n",
    "        \n",
    "        self.lock = threading.Lock()\n",
    "        \n",
    "        self.size = 0\n",
    "        self.last_size = 0\n",
    "        \n",
    "        self.buffer = [None] * self.num_blocks\n",
    "        \n",
    "        self.sample_queue_list = sample_queue_list\n",
    "        self.batch_queue = batch_queue\n",
    "        self.priority_queue = priority_queue\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def run(self):\n",
    "        background_thread = threading.Thread(target=self.add_data, daemon=True)\n",
    "        background_thread.start()\n",
    "        \n",
    "        background_thread = threading.Thread(target=self.prepare_data, daemon=True)\n",
    "        background_thread.start()\n",
    "        \n",
    "        background_thread = threading.Thread(target=self.update_data, daemon=True)\n",
    "        background_thread.start()\n",
    "\n",
    "        writer_thread = threading.Thread(target=self.write_stats, daemon=True)\n",
    "        writer_thread.start()\n",
    "        \n",
    "        while True:\n",
    "            print(f'Buffer size: {self.size}')\n",
    "            print(f'Buffer update speed: {(self.size - self.last_size) / log_interval}/s')\n",
    "            self.last_size = self.size\n",
    "            print(f'Number of environment steps: {self.env_steps}')\n",
    "            if self.num_episodes != 0:\n",
    "                print(f'Average episode return: {self.episode_reward / self.num_episodes:.4f}')\n",
    "                self.episode_reward = 0\n",
    "                self.num_episodes = 0\n",
    "            print(f'Number of training steps: {self.training_steps}')\n",
    "            print(f'Training speed: {(self.training_steps - self.last_training_steps) / log_interval}/s')\n",
    "            if self.training_steps != self.last_training_steps:\n",
    "                print(f'Loss: {self.sum_loss/(self.training_steps-self.last_training_steps):.4f}')\n",
    "                self.last_training_steps = self.training_steps\n",
    "                self.sum_loss = 0\n",
    "            self.last_env_steps = self.env_steps\n",
    "            print()\n",
    "            \n",
    "            if self.training_steps == training_steps:\n",
    "                break\n",
    "            else:\n",
    "                time.sleep(log_interval)\n",
    "    \n",
    "    def write_stats(self):\n",
    "        os.makedirs(f'logs/t2d2/{game_name}', exist_ok=True)\n",
    "        while True:\n",
    "            with open(f'logs/t2d2/{game_name}/buffer_size.txt', 'a') as f:\n",
    "                f.write(f'{self.size} {self.env_steps}\\n')\n",
    "            \n",
    "            with open(f'logs/t2d2/{game_name}/buffer_update_speed.txt', 'a') as f:\n",
    "                f.write(f'{(self.size - self.last_size) / log_interval} {self.env_steps}\\n')\n",
    "            \n",
    "            with open(f'logs/t2d2/{game_name}/environment_steps.txt', 'a') as f:\n",
    "                f.write(f'{self.env_steps}\\n')\n",
    "\n",
    "            if self.num_episodes != 0:\n",
    "                with open(f'logs/t2d2/{game_name}/episode_return.txt', 'a') as f:\n",
    "                    f.write(f'{self.episode_reward / self.num_episodes} {self.env_steps}\\n')\n",
    "\n",
    "            with open(f'logs/t2d2/{game_name}/training_steps.txt', 'a') as f:\n",
    "                f.write(f'{self.training_steps} {self.env_steps}\\n')\n",
    "\n",
    "            with open(f'logs/t2d2/{game_name}/training_speed.txt', 'a') as f:\n",
    "                f.write(f'{(self.training_steps - self.last_training_steps) / log_interval} {self.env_steps}\\n')\n",
    "\n",
    "            if self.training_steps != self.last_training_steps:\n",
    "                with open(f'logs/t2d2/{game_name}/training_loss.txt', 'a') as f:\n",
    "                    f.write(f'{self.sum_loss/(self.training_steps-self.last_training_steps)} {self.env_steps}\\n')\n",
    "\n",
    "            time.sleep(log_interval)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        while self.size < learning_starts:\n",
    "            time.sleep(1)\n",
    "        \n",
    "        while True:\n",
    "            if not self.batch_queue.full():\n",
    "                data = self.sample_batch()\n",
    "                self.batch_queue.put(data)\n",
    "            else:\n",
    "                time.sleep(0.1)\n",
    "    \n",
    "    def add_data(self):\n",
    "        while True:\n",
    "            for sample_queue in self.sample_queue_list:\n",
    "                if not sample_queue.empty():\n",
    "                    data = sample_queue.get_nowait()\n",
    "                    self.add(*data)\n",
    "    \n",
    "    def update_data(self):\n",
    "        while True:\n",
    "            if not self.priority_queue.empty():\n",
    "                data = self.priority_queue.get_nowait()\n",
    "                self.update_priorities(*data)\n",
    "            else:\n",
    "                time.sleep(0.1)\n",
    "    \n",
    "    def add(self, block: Block, priority: np.array, episode_reward: float):\n",
    "        with self.lock:\n",
    "            idxes = np.arange(self.block_ptr * self.seq_pre_block, (self.block_ptr + 1) * self.seq_pre_block, dtype=np.int64)\n",
    "            \n",
    "            self.priority_tree.update(idxes, priority)\n",
    "            \n",
    "            if self.buffer[self.block_ptr] is not None:\n",
    "                self.size -= np.sum(self.buffer[self.block_ptr].learning_steps).item()\n",
    "            \n",
    "            self.size += np.sum(block.learning_steps).item()\n",
    "            \n",
    "            self.buffer[self.block_ptr] = block\n",
    "            \n",
    "            self.env_steps += np.sum(block.learning_steps, dtype=np.int32)\n",
    "            \n",
    "            self.block_ptr = (self.block_ptr + 1) % self.num_blocks\n",
    "            \n",
    "            if episode_reward:\n",
    "                self.episode_reward += episode_reward\n",
    "                self.num_episodes += 1\n",
    "    \n",
    "    def sample_batch(self):\n",
    "        batch_obs, batch_last_action, batch_last_reward, batch_action, batch_reward, batch_gamma = [], [], [], [], [], []\n",
    "        burn_in_steps, learning_steps, forward_steps = [], [], []\n",
    "\n",
    "        with self.lock:\n",
    "\n",
    "            idxes, is_weights = self.priority_tree.sample(self.batch_size)\n",
    "\n",
    "            block_idxes = idxes // self.seq_pre_block\n",
    "            sequence_idxes = idxes % self.seq_pre_block\n",
    "\n",
    "\n",
    "            for block_idx, sequence_idx  in zip(block_idxes, sequence_idxes):\n",
    "\n",
    "                block = self.buffer[block_idx]\n",
    "\n",
    "                assert sequence_idx < block.num_sequences\n",
    "\n",
    "                burn_in_step = block.burn_in_steps[sequence_idx]\n",
    "                learning_step = block.learning_steps[sequence_idx]\n",
    "                forward_step = block.forward_steps[sequence_idx]\n",
    "                \n",
    "                start_idx = block.burn_in_steps[0] + np.sum(block.learning_steps[:sequence_idx])\n",
    "\n",
    "                obs = block.obs[start_idx-burn_in_step:start_idx+learning_step+forward_step]\n",
    "                last_action = block.last_action[start_idx-burn_in_step:start_idx+learning_step+forward_step]\n",
    "                last_reward = block.last_reward[start_idx-burn_in_step:start_idx+learning_step+forward_step]\n",
    "                obs, last_action, last_reward = torch.from_numpy(obs), torch.from_numpy(last_action), torch.from_numpy(last_reward)\n",
    "                \n",
    "                start_idx = np.sum(block.learning_steps[:sequence_idx])\n",
    "                end_idx = start_idx + block.learning_steps[sequence_idx]\n",
    "                action = block.action[start_idx:end_idx]\n",
    "                reward = block.n_step_reward[start_idx:end_idx]\n",
    "                gamma = block.gamma[start_idx:end_idx]\n",
    "                \n",
    "                batch_obs.append(obs)\n",
    "                batch_last_action.append(last_action)\n",
    "                batch_last_reward.append(last_reward)\n",
    "                batch_action.append(action)\n",
    "                batch_reward.append(reward)\n",
    "                batch_gamma.append(gamma)\n",
    "\n",
    "                burn_in_steps.append(burn_in_step)\n",
    "                learning_steps.append(learning_step)\n",
    "                forward_steps.append(forward_step)\n",
    "\n",
    "            batch_obs = pad_sequence(batch_obs, batch_first=True)\n",
    "            batch_last_action = pad_sequence(batch_last_action, batch_first=True)\n",
    "            batch_last_reward = pad_sequence(batch_last_reward, batch_first=True)\n",
    "\n",
    "            is_weights = np.repeat(is_weights, learning_steps)\n",
    "\n",
    "\n",
    "            data = (\n",
    "                batch_obs,\n",
    "                batch_last_action,\n",
    "                batch_last_reward,\n",
    "\n",
    "                torch.from_numpy(np.concatenate(batch_action)).unsqueeze(1),\n",
    "                torch.from_numpy(np.concatenate(batch_reward)),\n",
    "                torch.from_numpy(np.concatenate(batch_gamma)),\n",
    "\n",
    "                torch.ByteTensor(burn_in_steps),\n",
    "                torch.ByteTensor(learning_steps),\n",
    "                torch.ByteTensor(forward_steps),\n",
    "\n",
    "                idxes,\n",
    "                torch.from_numpy(is_weights.astype(np.float32)),\n",
    "                self.block_ptr,\n",
    "\n",
    "                self.env_steps\n",
    "            )\n",
    "\n",
    "        return data\n",
    "\n",
    "    def update_priorities(self, idxes: np.ndarray, td_errors: np.ndarray, old_ptr: int, loss: float):\n",
    "        \"\"\"Update priorities of sampled transitions\"\"\"\n",
    "        with self.lock:\n",
    "\n",
    "            # discard the idxes that already been replaced by new data in replay buffer during training\n",
    "            if self.block_ptr > old_ptr:\n",
    "                # range from [old_ptr, self.seq_ptr)\n",
    "                mask = (idxes < old_ptr*self.seq_pre_block) | (idxes >= self.block_ptr*self.seq_pre_block)\n",
    "                idxes = idxes[mask]\n",
    "                td_errors = td_errors[mask]\n",
    "            elif self.block_ptr < old_ptr:\n",
    "                # range from [0, self.seq_ptr) & [old_ptr, self,capacity)\n",
    "                mask = (idxes < old_ptr*self.seq_pre_block) & (idxes >= self.block_ptr*self.seq_pre_block)\n",
    "                idxes = idxes[mask]\n",
    "                td_errors = td_errors[mask]\n",
    "\n",
    "            self.priority_tree.update(idxes, td_errors)\n",
    "\n",
    "        self.training_steps += 1\n",
    "        self.sum_loss += loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18211db5539ae96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AgentState:\n",
    "    obs: torch.tensor\n",
    "    action_dim: int\n",
    "    last_action: torch.tensor = field(init=False)\n",
    "    last_reward: torch.tensor = torch.zeros((1, 1), dtype=torch.float32)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.last_action = torch.zeros((1, self.action_dim), dtype=torch.float32)\n",
    "\n",
    "    def update(self, obs, last_action, last_reward):\n",
    "        new_obs = torch.from_numpy(obs).unsqueeze(0)\n",
    "        self.obs = torch.cat([self.obs, new_obs], dim=0)\n",
    "        new_action = torch.tensor([[1 if i == last_action else 0 for i in range(self.action_dim)]],\n",
    "                                        dtype=torch.float32)\n",
    "        self.last_action = torch.cat([self.last_action, new_action], dim=0)\n",
    "        new_reward = torch.tensor([[last_reward]], dtype=torch.float32)\n",
    "        self.last_reward = torch.cat([self.last_reward, new_reward], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa569c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "\n",
    "        if d_model % 2 == 0:\n",
    "            pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        else:\n",
    "            pe[:, 0, 1::2] = torch.cos(position * div_term)[:, :-1]\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: torch.tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aec4addf644e7b99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T09:46:31.204482Z",
     "start_time": "2024-05-14T09:46:31.200932Z"
    }
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, observation_dim, action_dim, hidden_dim=hidden_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.action_dim = action_dim\n",
    "        self.obs_shape = observation_dim\n",
    "        self.max_forward_steps = 5\n",
    "\n",
    "        self.dim_model = observation_dim + action_dim + 1\n",
    "\n",
    "        self.positional_encoding = PositionalEncoding(d_model=self.dim_model)\n",
    "\n",
    "        transformer_layer = nn.TransformerEncoderLayer(d_model=self.dim_model, nhead=1, dim_feedforward=hidden_dim)\n",
    "        self.recurrent = nn.TransformerEncoder(transformer_layer, num_layers=1, enable_nested_tensor=False)\n",
    "\n",
    "        self.advantage = nn.Sequential(\n",
    "            nn.Linear(self.dim_model, self.dim_model),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(self.dim_model, action_dim)\n",
    "        )\n",
    "\n",
    "        self.value = nn.Sequential(\n",
    "            nn.Linear(self.dim_model, self.dim_model),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(self.dim_model, 1)\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def create_square_subsequent_mask(size):\n",
    "        mask = (torch.triu(torch.ones(size, size)) == 0).transpose(0, 1)\n",
    "        return mask.bool()\n",
    "\n",
    "    @staticmethod\n",
    "    def create_padding_mask(seq_lengths, max_len=None):\n",
    "        if max_len is None:\n",
    "            max_len = seq_lengths.max()\n",
    "        batch_size = seq_lengths.size(0)\n",
    "        mask = torch.arange(max_len).expand(batch_size, max_len) >= seq_lengths.unsqueeze(1)\n",
    "        return mask.bool()\n",
    "\n",
    "    def forward(self, state: AgentState):\n",
    "        recurrent_input = torch.cat([state.obs, state.last_action, state.last_reward], dim=1) * math.sqrt(self.dim_model)\n",
    "\n",
    "        recurrent_input = recurrent_input.unsqueeze(1)\n",
    "        \n",
    "        recurrent_input = self.positional_encoding(recurrent_input)\n",
    "\n",
    "        mask = self.create_square_subsequent_mask(state.obs.size(0))\n",
    "        mask = mask.to(recurrent_input.device)\n",
    "\n",
    "        recurrent_output = self.recurrent(recurrent_input, mask=mask)\n",
    "        \n",
    "        hidden = recurrent_output.mean(0)\n",
    "        \n",
    "        adv = self.advantage(hidden)\n",
    "        val = self.value(hidden)\n",
    "        q_value = val + adv - adv.mean(1, keepdim=True)\n",
    "        \n",
    "        return q_value\n",
    "\n",
    "    def calculate_q_(self, obs, last_action, last_reward, burn_in_steps, learning_steps, forward_steps):\n",
    "        # obs shape: (batch_size, seq_len, obs_shape)\n",
    "        max_seq_length = obs.size(1)\n",
    "        seq_len = burn_in_steps + learning_steps + forward_steps\n",
    "\n",
    "        recurrent_input = torch.cat((obs, last_action, last_reward), dim=2) * math.sqrt(self.dim_model)\n",
    "\n",
    "        recurrent_input = recurrent_input.transpose(0, 1) # (seq_len, batch_size, obs_shape)\n",
    "        recurrent_input = self.positional_encoding(recurrent_input)\n",
    "\n",
    "        mask = self.create_square_subsequent_mask(max_seq_length)\n",
    "        mask = mask.to(recurrent_input.device)\n",
    "\n",
    "        padding_mask = self.create_padding_mask(seq_len, max_seq_length)\n",
    "        padding_mask = padding_mask.to(recurrent_input.device)\n",
    "\n",
    "        recurrent_output = self.recurrent(recurrent_input, mask=mask, src_key_padding_mask=padding_mask)\n",
    "        recurrent_output = recurrent_output.transpose(0, 1) # (batch_size, seq_len, dim_model)\n",
    "\n",
    "        seq_start_idx = burn_in_steps + self.max_forward_steps\n",
    "        forward_pad_steps = torch.minimum(self.max_forward_steps - forward_steps, learning_steps)\n",
    "\n",
    "        hidden = []\n",
    "        for hidden_seq, start_idx, end_idx, padding_length in zip(recurrent_output, seq_start_idx, seq_len, forward_pad_steps):\n",
    "            hidden.append(hidden_seq[start_idx:end_idx])\n",
    "            if padding_length > 0:\n",
    "                hidden.append(hidden_seq[end_idx-1:end_idx].repeat(padding_length, 1))\n",
    "\n",
    "        hidden = torch.cat(hidden)\n",
    "\n",
    "        assert hidden.size(0) == torch.sum(learning_steps), f'{hidden.size(0)} != {torch.sum(learning_steps)}'\n",
    "\n",
    "        adv = self.advantage(hidden)\n",
    "        val = self.value(hidden)\n",
    "        q_value = val + adv - adv.mean(1, keepdim=True)\n",
    "\n",
    "        return q_value\n",
    "\n",
    "    def calculate_q(self, obs, last_action, last_reward, burn_in_steps, learning_steps):\n",
    "        # obs shape: (batch_size, seq_len, obs_shape)\n",
    "        max_seq_length = obs.size(1)\n",
    "        recurrent_input = torch.cat((obs, last_action, last_reward), dim=2) * math.sqrt(self.dim_model)\n",
    "\n",
    "        seq_len = burn_in_steps + learning_steps\n",
    "\n",
    "        recurrent_input = recurrent_input.transpose(0, 1) # (seq_len, batch_size, obs_shape)\n",
    "        recurrent_input = self.positional_encoding(recurrent_input)\n",
    "\n",
    "        mask = self.create_square_subsequent_mask(max_seq_length)\n",
    "        mask = mask.to(recurrent_input.device)\n",
    "\n",
    "        padding_mask = self.create_padding_mask(seq_len, max_seq_length)\n",
    "        padding_mask = padding_mask.to(recurrent_input.device)\n",
    "\n",
    "        recurrent_output = self.recurrent(recurrent_input, mask=mask, src_key_padding_mask=padding_mask)\n",
    "        recurrent_output = recurrent_output.transpose(0, 1) # (batch_size, seq_len, dim_model)\n",
    "\n",
    "        hidden = torch.cat([output[burn_in:burn_in+learning] for output, burn_in, learning in zip(recurrent_output, burn_in_steps, learning_steps)], dim=0)\n",
    "\n",
    "        adv = self.advantage(hidden)\n",
    "        val = self.value(hidden)\n",
    "\n",
    "        q_value = val + adv - adv.mean(1, keepdim=True)\n",
    "\n",
    "        return q_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0029246daacd7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mixed_td_errors(td_error, learning_steps):\n",
    "    \n",
    "    start_idx = 0\n",
    "    mixed_td_errors = np.empty(learning_steps.shape, dtype=td_error.dtype)\n",
    "    for i, steps in enumerate(learning_steps):\n",
    "        mixed_td_errors[i] = 0.9*td_error[start_idx:start_idx+steps].max() + 0.1*td_error[start_idx:start_idx+steps].mean()\n",
    "        start_idx += steps\n",
    "    \n",
    "    return mixed_td_errors\n",
    "\n",
    "class Learner:\n",
    "    def __init__(self, batch_queue, priority_queue, model, grad_norm: int = grad_norm,\n",
    "                lr: float = lr, eps:float = eps, game_name: str = game_name,\n",
    "                target_net_update_interval: int = target_net_update_interval, save_interval: int = save_interval):\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.online_net = deepcopy(model)\n",
    "        self.online_net.to(self.device)\n",
    "        self.online_net.train()\n",
    "        self.target_net = deepcopy(self.online_net)\n",
    "        self.target_net.eval()\n",
    "        self.optimizer = torch.optim.Adam(self.online_net.parameters(), lr=lr, eps=eps)\n",
    "        self.loss_fn = nn.MSELoss(reduction='none')\n",
    "        self.grad_norm = grad_norm\n",
    "        self.batch_queue = batch_queue\n",
    "        self.priority_queue = priority_queue\n",
    "        self.num_updates = 0\n",
    "        self.done = False\n",
    "\n",
    "        self.target_net_update_interval = target_net_update_interval\n",
    "        self.save_interval = save_interval\n",
    "\n",
    "        self.batched_data = []\n",
    "\n",
    "        self.shared_model = model\n",
    "\n",
    "        self.game_name = game_name\n",
    "\n",
    "    def store_weights(self):\n",
    "        self.shared_model.load_state_dict(self.online_net.state_dict())\n",
    "\n",
    "    def prepare_data(self):\n",
    "\n",
    "        while True:\n",
    "            if not self.batch_queue.empty() and len(self.batched_data) < 4:\n",
    "                data = self.batch_queue.get_nowait()\n",
    "                self.batched_data.append(data)\n",
    "            else:\n",
    "                time.sleep(0.1)\n",
    "\n",
    "    def run(self):\n",
    "        background_thread = threading.Thread(target=self.prepare_data, daemon=True)\n",
    "        background_thread.start()\n",
    "        time.sleep(2)\n",
    "\n",
    "        start_time = time.time()\n",
    "        while self.num_updates < training_steps:\n",
    "            \n",
    "            while not self.batched_data:\n",
    "                time.sleep(1)\n",
    "            data = self.batched_data.pop(0)\n",
    "\n",
    "            batch_obs, batch_last_action, batch_last_reward, batch_action, batch_n_step_reward, batch_n_step_gamma, burn_in_steps, learning_steps, forward_steps, idxes, is_weights, old_ptr, env_steps = data\n",
    "            batch_obs, batch_last_action, batch_last_reward = batch_obs.to(self.device), batch_last_action.to(self.device), batch_last_reward.to(self.device)\n",
    "            batch_action = batch_action.to(self.device)\n",
    "            batch_n_step_reward, batch_n_step_gamma = batch_n_step_reward.to(self.device), batch_n_step_gamma.to(self.device)\n",
    "            is_weights = is_weights.to(self.device)\n",
    "\n",
    "            batch_obs, batch_last_action = batch_obs.float(), batch_last_action.float()\n",
    "            batch_action = batch_action.long()\n",
    "            burn_in_steps, learning_steps, forward_steps = burn_in_steps, learning_steps, forward_steps\n",
    "\n",
    "            # batch_obs = batch_obs / 255\n",
    "\n",
    "            # double q learning\n",
    "            with torch.no_grad():\n",
    "                batch_action_ = self.online_net.calculate_q_(batch_obs, batch_last_action, batch_last_reward, burn_in_steps, learning_steps, forward_steps).argmax(1).unsqueeze(1)\n",
    "                batch_q_ = self.target_net.calculate_q_(batch_obs, batch_last_action, batch_last_reward, burn_in_steps, learning_steps, forward_steps).gather(1, batch_action_).squeeze(1)\n",
    "            \n",
    "            target_q = self.value_rescale(batch_n_step_reward + batch_n_step_gamma * self.inverse_value_rescale(batch_q_))\n",
    "            # target_q = batch_n_step_reward + batch_n_step_gamma * batch_q_\n",
    "\n",
    "            batch_q = self.online_net.calculate_q(batch_obs, batch_last_action, batch_last_reward, burn_in_steps, learning_steps).gather(1, batch_action).squeeze(1)\n",
    "            \n",
    "            loss = (is_weights * self.loss_fn(batch_q, target_q)).mean()\n",
    "\n",
    "            \n",
    "            td_errors = (target_q-batch_q).detach().clone().squeeze().abs().cpu().float().numpy()\n",
    "\n",
    "            priorities = calculate_mixed_td_errors(td_errors, learning_steps.numpy())\n",
    "\n",
    "            # automatic mixed precision training\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(self.online_net.parameters(), self.grad_norm)\n",
    "            self.optimizer.step()\n",
    "\n",
    "            self.num_updates += 1\n",
    "\n",
    "            self.priority_queue.put((idxes, priorities, old_ptr, loss.item()))\n",
    "\n",
    "            # store new weights in shared memory\n",
    "            if self.num_updates % 4 == 0:\n",
    "                self.store_weights()\n",
    "\n",
    "            # update target net\n",
    "            if self.num_updates % self.target_net_update_interval == 0:\n",
    "                self.target_net.load_state_dict(self.online_net.state_dict())\n",
    "            \n",
    "            # save model \n",
    "            if self.num_updates % self.save_interval == 0:\n",
    "                os.makedirs(f'models/t2d2/{game_name}', exist_ok=True)\n",
    "                torch.save((self.online_net.state_dict(), self.num_updates, env_steps, (time.time()-start_time)/60), os.path.join(f'models/t2d2/{game_name}', '{}.pth'.format(self.num_updates)))\n",
    "\n",
    "    @staticmethod\n",
    "    def value_rescale(value, eps=1e-3):\n",
    "        return value.sign()*((value.abs()+1).sqrt()-1) + eps*value\n",
    "\n",
    "    @staticmethod\n",
    "    def inverse_value_rescale(value, eps=1e-3):\n",
    "        temp = ((1 + 4*eps*(value.abs()+1+eps)).sqrt() - 1) / (2*eps)\n",
    "        return value.sign() * (temp.square() - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e982c17b637a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalBuffer:\n",
    "    def __init__(self, action_dim: int, forward_steps: int = forward_steps,\n",
    "                burn_in_steps = burn_in_steps, learning_steps: int = learning_steps, \n",
    "                gamma: float = gamma, hidden_dim: int = hidden_dim, block_length: int = block_length):\n",
    "        \n",
    "        self.action_dim = action_dim\n",
    "        self.gamma = gamma\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.forward_steps = forward_steps\n",
    "        self.learning_steps = learning_steps\n",
    "        self.burn_in_steps = burn_in_steps\n",
    "        self.block_length = block_length\n",
    "        self.curr_burn_in_steps = 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def reset(self, init_obs: np.ndarray):\n",
    "        self.obs_buffer = [init_obs]\n",
    "        self.last_action_buffer = [np.array([1 if i == 0 else 0 for i in range(self.action_dim)], dtype=bool)]\n",
    "        self.last_reward_buffer = [[0]]\n",
    "        self.action_buffer = []\n",
    "        self.reward_buffer = []\n",
    "        self.qval_buffer = []\n",
    "        self.curr_burn_in_steps = 0\n",
    "        self.size = 0\n",
    "        self.sum_reward = 0\n",
    "        self.done = False\n",
    "\n",
    "    def add(self, action: int, reward: float, next_obs: np.ndarray, q_value: np.ndarray):\n",
    "        self.action_buffer.append(action)\n",
    "        self.reward_buffer.append(reward)\n",
    "        self.obs_buffer.append(next_obs)\n",
    "        self.last_action_buffer.append(np.array([1 if i == action else 0 for i in range(self.action_dim)], dtype=bool))\n",
    "        self.last_reward_buffer.append([reward])\n",
    "        self.qval_buffer.append(q_value)\n",
    "        self.sum_reward += reward\n",
    "        self.size += 1\n",
    "    \n",
    "    def finish(self, last_qval: np.ndarray = None) -> Tuple:\n",
    "        assert self.size <= self.block_length\n",
    "        # assert len(self.last_action_buffer) == self.curr_burn_in_steps + self.size + 1\n",
    "\n",
    "        num_sequences = math.ceil(self.size/self.learning_steps)\n",
    "\n",
    "        max_forward_steps = min(self.size, self.forward_steps)\n",
    "        n_step_gamma = [self.gamma**self.forward_steps] * (self.size-max_forward_steps)\n",
    "\n",
    "        # last_qval is none means episode done \n",
    "        if last_qval is not None:\n",
    "            self.qval_buffer.append(last_qval)\n",
    "            n_step_gamma.extend([self.gamma**i for i in reversed(range(1, max_forward_steps+1))])\n",
    "        else:\n",
    "            self.done = True\n",
    "            self.qval_buffer.append(np.zeros_like(self.qval_buffer[0]))\n",
    "            n_step_gamma.extend([0 for _ in range(max_forward_steps)]) # set gamma to 0 so don't need 'done'\n",
    "\n",
    "        n_step_gamma = np.array(n_step_gamma, dtype=np.float32)\n",
    "\n",
    "        obs = np.stack(self.obs_buffer)\n",
    "        last_action = np.stack(self.last_action_buffer)\n",
    "        last_reward = np.array(self.last_reward_buffer, dtype=np.float32)\n",
    "\n",
    "\n",
    "        actions = np.array(self.action_buffer, dtype=np.uint8)\n",
    "\n",
    "        qval_buffer = np.concatenate(self.qval_buffer)\n",
    "        reward_buffer = self.reward_buffer + [0 for _ in range(self.forward_steps-1)]\n",
    "        n_step_reward = np.convolve(reward_buffer, \n",
    "                                    [self.gamma**(self.forward_steps-1-i) for i in range(self.forward_steps)],\n",
    "                                    'valid').astype(np.float32)\n",
    "\n",
    "        burn_in_steps = np.array([min(i*self.learning_steps+self.curr_burn_in_steps, self.burn_in_steps) for i in range(num_sequences)], dtype=np.uint8)\n",
    "        learning_steps = np.array([min(self.learning_steps, self.size-i*self.learning_steps) for i in range(num_sequences)], dtype=np.uint8)\n",
    "        forward_steps = np.array([min(self.forward_steps, self.size+1-np.sum(learning_steps[:i+1])) for i in range(num_sequences)], dtype=np.uint8)\n",
    "        assert forward_steps[-1] == 1 and burn_in_steps[0] == self.curr_burn_in_steps\n",
    "        # assert last_action.shape[0] == self.curr_burn_in_steps + np.sum(learning_steps) + 1\n",
    "\n",
    "        max_qval = np.max(qval_buffer[max_forward_steps:self.size+1], axis=1)\n",
    "        max_qval = np.pad(max_qval, (0, max_forward_steps-1), 'edge')\n",
    "        target_qval = qval_buffer[np.arange(self.size), actions]\n",
    "\n",
    "        td_errors = np.abs(n_step_reward + n_step_gamma * max_qval - target_qval, dtype=np.float32)\n",
    "        priorities = np.zeros(self.block_length//self.learning_steps, dtype=np.float32)\n",
    "\n",
    "        priorities[:num_sequences] = calculate_mixed_td_errors(td_errors, learning_steps)\n",
    "\n",
    "        # save burn in information for next block\n",
    "        self.obs_buffer = self.obs_buffer[-self.burn_in_steps-1:]\n",
    "        self.last_action_buffer = self.last_action_buffer[-self.burn_in_steps-1:]\n",
    "        self.last_reward_buffer = self.last_reward_buffer[-self.burn_in_steps-1:]\n",
    "        self.action_buffer.clear()\n",
    "        self.reward_buffer.clear()\n",
    "        self.qval_buffer.clear()\n",
    "        self.curr_burn_in_steps = len(self.obs_buffer)-1\n",
    "        self.size = 0\n",
    "        \n",
    "        block = Block(obs, last_action, last_reward, actions, n_step_reward, n_step_gamma, num_sequences, burn_in_steps, learning_steps, forward_steps)\n",
    "        return [block, priorities, self.sum_reward if self.done else None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de71841dc9e844c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor:\n",
    "    def __init__(self, epsilon: float, model, sample_queue,\n",
    "                max_episode_steps: int = max_episode_steps, block_length: int = block_length):\n",
    "\n",
    "        self.env = create_env(game_name)\n",
    "        self.action_dim = self.env.action_space.n\n",
    "        self.model = Network(self.env.observation_space.shape[0], self.action_dim)\n",
    "        self.model.eval()\n",
    "        self.local_buffer = LocalBuffer(self.action_dim)\n",
    "\n",
    "        self.epsilon = epsilon\n",
    "        self.shared_model = model\n",
    "        self.sample_queue = sample_queue\n",
    "        self.max_episode_steps = max_episode_steps\n",
    "        self.block_length = block_length\n",
    "\n",
    "    def run(self):\n",
    "        \n",
    "        actor_steps = 0\n",
    "\n",
    "        while True:\n",
    "\n",
    "            done = False\n",
    "            agent_state = self.reset()\n",
    "            episode_steps = 0\n",
    "\n",
    "            while not done and episode_steps < self.max_episode_steps:\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    q_value = self.model(agent_state)\n",
    "\n",
    "                if random.random() < self.epsilon:\n",
    "                    action = self.env.action_space.sample()\n",
    "                else:\n",
    "                    action = torch.argmax(q_value, 1).item()\n",
    "\n",
    "                # apply action in env\n",
    "                next_obs, reward, terminated, truncated, _ = self.env.step(action)\n",
    "                done = terminated or truncated\n",
    "\n",
    "                agent_state.update(next_obs, action, reward)\n",
    "\n",
    "                episode_steps += 1\n",
    "                actor_steps += 1\n",
    "\n",
    "                self.local_buffer.add(action, reward, next_obs, q_value.numpy())\n",
    "\n",
    "                if done:\n",
    "                    block = self.local_buffer.finish()\n",
    "                    self.sample_queue.put(block)\n",
    "\n",
    "                elif len(self.local_buffer) == self.block_length or episode_steps == self.max_episode_steps:\n",
    "                    with torch.no_grad():\n",
    "                        q_value = self.model(agent_state)\n",
    "\n",
    "                    block = self.local_buffer.finish(q_value.numpy())\n",
    "\n",
    "                    if self.epsilon > 0.01:\n",
    "                        block[2] = None\n",
    "                    self.sample_queue.put(block)\n",
    "\n",
    "                if actor_steps % actor_update_interval == 0:\n",
    "                    self.update_weights()\n",
    "\n",
    "                \n",
    "    def update_weights(self):\n",
    "        self.model.load_state_dict(self.shared_model.state_dict())\n",
    "    \n",
    "    def reset(self):\n",
    "        obs, _ = self.env.reset()\n",
    "        self.local_buffer.reset(obs)\n",
    "\n",
    "        state = AgentState(torch.from_numpy(obs).unsqueeze(0), self.action_dim)\n",
    "\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea899f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epsilon(actor_id: int, base_eps: float = base_eps, alpha: float = alpha, num_actors: int = num_actors):\n",
    "    exponent = 1 + actor_id / (num_actors-1) * alpha\n",
    "    return base_eps**exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56e97fdc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643e8fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(game_name)\n",
    "action_dim = env.action_space.n\n",
    "observation_dim = env.observation_space.shape[0]\n",
    "queue = mp.Queue()\n",
    "actor = Actor(epsilon=get_epsilon(0), model=Network(observation_dim, action_dim), sample_queue=queue)\n",
    "actor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f06c5b41ae86fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffer size: 0\n",
      "Buffer update speed: 14.3/s\n",
      "Number of environment steps: 421\n",
      "Average episode return: 10.6531\n",
      "Number of training steps: 0\n",
      "Training speed: 0.0/s\n",
      "\n",
      "Buffer size: 12125\n",
      "Buffer update speed: 1175.3/s\n",
      "Number of environment steps: 12210\n",
      "Average episode return: 9.8800\n",
      "Number of training steps: 59\n",
      "Training speed: 5.9/s\n",
      "Loss: 1.0653\n",
      "\n",
      "Buffer size: 12331\n",
      "Buffer update speed: 12.2/s\n",
      "Number of environment steps: 25195\n",
      "Average episode return: 9.8687\n",
      "Number of training steps: 112\n",
      "Training speed: 5.3/s\n",
      "Loss: 0.6743\n",
      "\n",
      "Buffer size: 12134\n",
      "Buffer update speed: -20.0/s\n",
      "Number of environment steps: 36844\n",
      "Average episode return: 9.7095\n",
      "Number of training steps: 179\n",
      "Training speed: 6.5/s\n",
      "Loss: 0.4524\n",
      "\n",
      "Buffer size: 12367\n",
      "Buffer update speed: 23.5/s\n",
      "Number of environment steps: 54853\n",
      "Average episode return: 9.8440\n",
      "Number of training steps: 301\n",
      "Training speed: 12.2/s\n",
      "Loss: 0.3084\n",
      "\n",
      "Buffer size: 12348\n",
      "Buffer update speed: -1.9/s\n",
      "Number of environment steps: 66757\n",
      "Average episode return: 9.8632\n",
      "Number of training steps: 351\n",
      "Training speed: 5.0/s\n",
      "Loss: 0.2039\n",
      "\n",
      "Buffer size: 12488\n",
      "Buffer update speed: 13.9/s\n",
      "Number of environment steps: 84249\n",
      "Average episode return: 9.9977\n",
      "Number of training steps: 452\n",
      "Training speed: 10.1/s\n",
      "Loss: 0.1776\n",
      "\n",
      "Buffer size: 12348\n",
      "Buffer update speed: -13.9/s\n",
      "Number of environment steps: 97022\n",
      "Average episode return: 9.8928\n",
      "Number of training steps: 523\n",
      "Training speed: 7.1/s\n",
      "Loss: 0.2257\n",
      "\n",
      "Buffer size: 12282\n",
      "Buffer update speed: -6.6/s\n",
      "Number of environment steps: 110819\n",
      "Average episode return: 9.8491\n",
      "Number of training steps: 626\n",
      "Training speed: 10.2/s\n",
      "Loss: 0.3246\n",
      "\n",
      "Buffer size: 12265\n",
      "Buffer update speed: -2.0/s\n",
      "Number of environment steps: 125260\n",
      "Average episode return: 9.8530\n",
      "Number of training steps: 706\n",
      "Training speed: 8.0/s\n",
      "Loss: 0.3091\n",
      "\n",
      "Buffer size: 12242\n",
      "Buffer update speed: -1.8/s\n",
      "Number of environment steps: 137310\n",
      "Average episode return: 9.7979\n",
      "Number of training steps: 800\n",
      "Training speed: 9.4/s\n",
      "Loss: 0.2410\n",
      "\n",
      "Buffer size: 12310\n",
      "Buffer update speed: 5.9/s\n",
      "Number of environment steps: 149834\n",
      "Average episode return: 9.8466\n",
      "Number of training steps: 918\n",
      "Training speed: 11.6/s\n",
      "Loss: 0.2129\n",
      "\n",
      "Buffer size: 12191\n",
      "Buffer update speed: -10.9/s\n",
      "Number of environment steps: 164746\n",
      "Average episode return: 9.7528\n",
      "Number of training steps: 1059\n",
      "Training speed: 14.1/s\n",
      "Loss: 0.1532\n",
      "\n",
      "Buffer size: 12284\n",
      "Buffer update speed: 8.3/s\n",
      "Number of environment steps: 181332\n",
      "Average episode return: 9.8257\n",
      "Number of training steps: 1164\n",
      "Training speed: 10.5/s\n",
      "Loss: 0.1042\n",
      "\n",
      "Buffer size: 12270\n",
      "Buffer update speed: -1.3/s\n",
      "Number of environment steps: 195465\n",
      "Average episode return: 9.8040\n",
      "Number of training steps: 1269\n",
      "Training speed: 10.5/s\n",
      "Loss: 0.0989\n",
      "\n",
      "Buffer size: 12243\n",
      "Buffer update speed: -2.1/s\n",
      "Number of environment steps: 208900\n",
      "Average episode return: 9.7821\n",
      "Number of training steps: 1357\n",
      "Training speed: 8.8/s\n",
      "Loss: 0.0969\n",
      "\n",
      "Buffer size: 12240\n",
      "Buffer update speed: -1.3/s\n",
      "Number of environment steps: 223710\n",
      "Average episode return: 9.8092\n",
      "Number of training steps: 1414\n",
      "Training speed: 5.7/s\n",
      "Loss: 0.0985\n",
      "\n",
      "Buffer size: 12265\n",
      "Buffer update speed: 2.9/s\n",
      "Number of environment steps: 237111\n",
      "Average episode return: 9.7969\n",
      "Number of training steps: 1484\n",
      "Training speed: 7.0/s\n",
      "Loss: 0.0678\n",
      "\n",
      "Buffer size: 12433\n",
      "Buffer update speed: 16.2/s\n",
      "Number of environment steps: 253899\n",
      "Number of training steps: 1611Average episode return: 9.9738\n",
      "\n",
      "Training speed: 12.7/s\n",
      "Loss: 0.0782\n",
      "\n",
      "Buffer size: 12232\n",
      "Buffer update speed: -20.7/s\n",
      "Number of environment steps: 267925\n",
      "Average episode return: 9.8008\n",
      "Number of training steps: 1682\n",
      "Training speed: 7.1/s\n",
      "Loss: 0.0665\n",
      "\n",
      "Buffer size: 12296\n",
      "Buffer update speed: 7.0/s\n",
      "Number of environment steps: 285124\n",
      "Average episode return: 9.8017\n",
      "Number of training steps: 1757\n",
      "Training speed: 7.5/s\n",
      "Loss: 0.0568\n",
      "\n",
      "Buffer size: 12239\n",
      "Buffer update speed: -5.9/s\n",
      "Number of environment steps: 301471\n",
      "Average episode return: 9.7891\n",
      "Number of training steps: 1833\n",
      "Training speed: 7.6/s\n",
      "Loss: 0.0590\n",
      "\n",
      "Buffer size: 12501\n",
      "Buffer update speed: 24.7/s\n",
      "Number of environment steps: 314237\n",
      "Average episode return: 9.9922\n",
      "Number of training steps: 1879\n",
      "Training speed: 4.6/s\n",
      "Loss: 0.0508\n",
      "\n",
      "Buffer size: 12242\n",
      "Buffer update speed: -24.3/s\n",
      "Number of environment steps: 328726\n",
      "Average episode return: 9.7909\n",
      "Number of training steps: 1956\n",
      "Training speed: 7.6/s\n",
      "Loss: 0.0513\n",
      "\n",
      "Buffer size: 12289\n",
      "Buffer update speed: 5.1/s\n",
      "Number of environment steps: 344960\n",
      "Average episode return: 9.8566\n",
      "Number of training steps: 2045\n",
      "Training speed: 8.9/s\n",
      "Loss: 0.0436\n",
      "\n",
      "Buffer size: 12407\n",
      "\n",
      "Buffer update speed: 11.4/s\n",
      "Number of environment steps: 357983\n",
      "Average episode return: 9.9110Number of training steps: 2083\n",
      "Training speed: 3.8/s\n",
      "Loss: 0.0506\n",
      "\n",
      "Buffer size: 12293\n",
      "Buffer update speed: -10.7/s\n",
      "Number of environment steps: 370222\n",
      "Average episode return: 9.8384\n",
      "Number of training steps: 2118\n",
      "Training speed: 3.5/s\n",
      "Loss: 0.0534\n",
      "\n",
      "Buffer size: 12463\n",
      "Buffer update speed: 15.3/s\n",
      "Number of environment steps: 384426\n",
      "Average episode return: 9.9747\n",
      "Number of training steps: 2187\n",
      "Training speed: 6.9/s\n",
      "Loss: 0.0464\n",
      "\n",
      "Buffer size: 12122\n",
      "Buffer update speed: -33.1/s\n",
      "Number of environment steps: 399033\n",
      "Average episode return: 9.6994\n",
      "Number of training steps: 2275\n",
      "Training speed: 8.8/s\n",
      "Loss: 0.0380\n",
      "\n",
      "Buffer size: 12309\n",
      "Buffer update speed: 18.5/s\n",
      "Number of environment steps: 414692\n",
      "Average episode return: 9.8238\n",
      "Number of training steps: 2343\n",
      "Training speed: 7.0/s\n",
      "Loss: 0.0383\n",
      "\n",
      "Buffer size: 12230\n",
      "Buffer update speed: -7.7/s\n",
      "Number of environment steps: 427898\n",
      "Average episode return: 9.7939\n",
      "Number of training steps: 2424\n",
      "Training speed: 8.0/s\n",
      "Loss: 0.0361\n",
      "\n",
      "Buffer size: 12276\n",
      "Buffer update speed: 4.4/s\n",
      "Number of environment steps: 440209\n",
      "Average episode return: 9.8257\n",
      "Number of training steps: 2513\n",
      "Training speed: 8.8/s\n",
      "Loss: 0.0327\n",
      "\n",
      "Buffer size: 12283\n",
      "Buffer update speed: 0.8/s\n",
      "Number of environment steps: 454066\n",
      "Average episode return: 9.8088\n",
      "Number of training steps: 2592\n",
      "Training speed: 7.9/s\n",
      "Loss: 0.0357\n",
      "\n",
      "Buffer size: 12282\n",
      "Buffer update speed: -1.3/s\n",
      "Number of environment steps: 465777\n",
      "Average episode return: 9.8157\n",
      "Number of training steps: 2648\n",
      "Training speed: 5.6/s\n",
      "Loss: 0.0350\n",
      "\n",
      "Buffer size: 12294\n",
      "Buffer update speed: 2.8/s\n",
      "Number of environment steps: 480688\n",
      "Average episode return: 9.8481\n",
      "Number of training steps: 2701\n",
      "Training speed: 5.3/s\n",
      "Loss: 0.0336\n",
      "\n",
      "Buffer size: 12401\n",
      "Buffer update speed: 9.9/s\n",
      "Number of environment steps: 493373\n",
      "Average episode return: 9.9280\n",
      "Number of training steps: 2801\n",
      "Training speed: 9.8/s\n",
      "Loss: 0.0329\n",
      "\n",
      "Buffer size: 12271\n",
      "Buffer update speed: -13.1/s\n",
      "Number of environment steps: 503298\n",
      "Average episode return: 9.8077\n",
      "Number of training steps: 2860\n",
      "Training speed: 5.9/s\n",
      "Loss: 0.0312\n",
      "\n",
      "Buffer size: 12147\n",
      "Buffer update speed: -12.4/s\n",
      "Number of environment steps: 518005\n",
      "Average episode return: 9.7656\n",
      "Number of training steps: 3015\n",
      "Training speed: 15.5/s\n",
      "Loss: 0.0318\n",
      "\n",
      "Buffer size: 12129\n",
      "Buffer update speed: -1.3/s\n",
      "Number of environment steps: 532371\n",
      "Average episode return: 9.7054\n",
      "Number of training steps: 3093\n",
      "Training speed: 7.8/s\n",
      "Loss: 0.0258\n",
      "\n",
      "Buffer size: 12205\n",
      "Buffer update speed: 7.0/s\n",
      "Number of environment steps: 543720\n",
      "Average episode return: 9.7742\n",
      "Number of training steps: 3169\n",
      "Training speed: 7.6/s\n",
      "Loss: 0.0257\n",
      "\n",
      "Buffer size: 12349\n",
      "Buffer update speed: 14.4/s\n",
      "Number of environment steps: 557817\n",
      "Average episode return: 9.8711\n",
      "Number of training steps: 3246\n",
      "Training speed: 7.7/s\n",
      "Loss: 0.0257\n",
      "\n",
      "Buffer size: 12292\n",
      "Buffer update speed: -5.7/s\n",
      "Number of environment steps: 569102\n",
      "Average episode return: 9.8399\n",
      "Number of training steps: 3310\n",
      "Training speed: 6.4/s\n",
      "Loss: 0.0269\n",
      "\n",
      "Buffer size: 12340\n",
      "Buffer update speed: 4.2/s\n",
      "Number of environment steps: 584336\n",
      "Average episode return: 9.8858\n",
      "Number of training steps: 3412\n",
      "Training speed: 10.2/s\n",
      "Loss: 0.0275\n",
      "\n",
      "Buffer size: 12277\n",
      "Buffer update speed: -5.5/s\n",
      "Number of environment steps: 597519\n",
      "Average episode return: 9.8086\n",
      "Number of training steps: 3505\n",
      "Training speed: 9.3/s\n",
      "Loss: 0.0249\n",
      "\n",
      "Buffer size: 12133\n",
      "Buffer update speed: -14.4/s\n",
      "Number of environment steps: 612459\n",
      "Average episode return: 9.7343\n",
      "Number of training steps: 3587\n",
      "Training speed: 8.2/s\n",
      "Loss: 0.0231\n",
      "\n",
      "Buffer size: 12272\n",
      "Buffer update speed: 16.1/s\n",
      "Number of environment steps: 628508\n",
      "Average episode return: 9.8471\n",
      "Number of training steps: 3683\n",
      "Training speed: 9.6/s\n",
      "Loss: 0.0226\n",
      "\n",
      "Buffer size: 12328\n",
      "Buffer update speed: 2.9/s\n",
      "Number of environment steps: 640961\n",
      "Average episode return: 9.8661\n",
      "Number of training steps: 3729\n",
      "Training speed: 4.6/s\n",
      "Loss: 0.0244\n",
      "\n",
      "Buffer size: 12256\n",
      "Buffer update speed: -7.9/s\n",
      "Number of environment steps: 654030\n",
      "Average episode return: 9.8200\n",
      "Number of training steps: 3798\n",
      "Training speed: 6.9/s\n",
      "Loss: 0.0278\n",
      "\n",
      "Buffer size: 12211\n",
      "Buffer update speed: -4.3/s\n",
      "Number of environment steps: 668563\n",
      "Average episode return: 9.7396\n",
      "Number of training steps: 3892\n",
      "Training speed: 9.4/s\n",
      "Loss: 0.0224\n",
      "\n",
      "Buffer size: 12382\n",
      "Buffer update speed: 16.6/s\n",
      "Number of environment steps: 681824\n",
      "Average episode return: 9.8995\n",
      "Number of training steps: 3966\n",
      "Training speed: 7.4/s\n",
      "Loss: 0.0229\n",
      "\n",
      "Buffer size: 12286\n",
      "Buffer update speed: -8.9/s\n",
      "Number of environment steps: 695827\n",
      "Average episode return: 9.8225\n",
      "Number of training steps: 4036\n",
      "Training speed: 7.0/s\n",
      "Loss: 0.0249\n",
      "\n",
      "Buffer size: 12406\n",
      "Buffer update speed: 12.1/s\n",
      "Number of environment steps: 715678\n",
      "Average episode return: 9.9254\n",
      "Number of training steps: 4101\n",
      "Training speed: 6.5/s\n",
      "Loss: 0.0351\n",
      "\n",
      "Buffer size: 12108\n",
      "Buffer update speed: -30.1/s\n",
      "Number of environment steps: 728944\n",
      "Average episode return: 9.6913\n",
      "Number of training steps: 4162\n",
      "Training speed: 6.1/s\n",
      "Loss: 0.0254\n",
      "\n",
      "Buffer size: 12419\n",
      "Buffer update speed: 31.8/s\n",
      "Number of environment steps: 742052\n",
      "Average episode return: 9.9297\n",
      "Number of training steps: 4232\n",
      "Training speed: 7.0/s\n",
      "Loss: 0.0215\n",
      "\n",
      "Buffer size: 12348\n",
      "Buffer update speed: -7.8/s\n",
      "Number of environment steps: 756218\n",
      "Average episode return: 9.8968\n",
      "Number of training steps: 4298\n",
      "Training speed: 6.6/s\n",
      "Loss: 0.0229\n",
      "\n",
      "Buffer size: 12869\n",
      "Buffer update speed: 52.1/s\n",
      "Number of environment steps: 771659\n",
      "Average episode return: 10.2241\n",
      "Number of training steps: 4363\n",
      "Training speed: 6.5/s\n",
      "Loss: 0.0358\n",
      "\n",
      "Buffer size: 12050\n",
      "Buffer update speed: -81.6/s\n",
      "Number of environment steps: 789918\n",
      "Average episode return: 9.6658\n",
      "Number of training steps: 4416\n",
      "Training speed: 5.3/s\n",
      "Loss: 0.0423\n",
      "\n",
      "Buffer size: 13421\n",
      "Buffer update speed: 137.5/s\n",
      "Number of environment steps: 805381\n",
      "Average episode return: 10.5837\n",
      "Number of training steps: 4481\n",
      "Training speed: 6.5/s\n",
      "Loss: 0.0413\n",
      "\n",
      "Buffer size: 12892\n",
      "Buffer update speed: -53.1/s\n",
      "Number of environment steps: 819590\n",
      "Average episode return: 10.3465\n",
      "Number of training steps: 4535\n",
      "Training speed: 5.3/s\n",
      "Loss: 0.0852\n",
      "\n",
      "Buffer size: 12638\n",
      "Buffer update speed: -24.9/s\n",
      "Number of environment steps: 832111\n",
      "Average episode return: 10.1133\n",
      "Number of training steps: 4589\n",
      "Training speed: 5.4/s\n",
      "Loss: 0.0420\n",
      "\n",
      "Buffer size: 18565\n",
      "Buffer update speed: 592.6/s\n",
      "Number of environment steps: 846794\n",
      "Average episode return: 16.9149\n",
      "Number of training steps: 4660\n",
      "Training speed: 7.1/s\n",
      "Loss: 0.0907\n",
      "\n",
      "Buffer size: 25403\n",
      "Buffer update speed: 681.2/s\n",
      "Number of environment steps: 857754\n",
      "Average episode return: 46.3924\n",
      "Number of training steps: 4712\n",
      "Training speed: 5.2/s\n",
      "Loss: 0.1823\n",
      "\n",
      "Buffer size: 14014\n",
      "Buffer update speed: -1137.4/s\n",
      "Number of environment steps: 873883\n",
      "Average episode return: 11.7571\n",
      "Number of training steps: 4824\n",
      "Training speed: 11.2/s\n",
      "Loss: 0.3625\n",
      "\n",
      "Buffer size: 12826\n",
      "Buffer update speed: -121.3/s\n",
      "Number of environment steps: 889757\n",
      "Average episode return: 10.7588\n",
      "Number of training steps: 4930\n",
      "Training speed: 10.6/s\n",
      "Loss: 0.3726\n",
      "\n",
      "Buffer size: 12194\n",
      "Buffer update speed: -63.2/s\n",
      "Number of environment steps: 905659\n",
      "Average episode return: 9.7543\n",
      "Number of training steps: 4983\n",
      "Training speed: 5.5/s\n",
      "Loss: 0.2291\n",
      "\n",
      "Buffer size: 12339\n",
      "Buffer update speed: 15.5/s\n",
      "Number of environment steps: 921593\n",
      "Average episode return: 9.8922\n",
      "Number of training steps: 5149\n",
      "Training speed: 16.3/s\n",
      "Loss: 0.1075\n",
      "\n",
      "Buffer size: 12413\n",
      "Buffer update speed: 7.3/s\n",
      "Number of environment steps: 936770\n",
      "Average episode return: 9.9484\n",
      "Number of training steps: 5225\n",
      "Training speed: 7.6/s\n",
      "Loss: 0.0890\n",
      "\n",
      "Buffer size: 12293\n",
      "Buffer update speed: -12.0/s\n",
      "Number of environment steps: 949182\n",
      "Average episode return: 9.8337\n",
      "Number of training steps: 5280\n",
      "Training speed: 5.4/s\n",
      "Loss: 0.0833\n",
      "\n",
      "Buffer size: 12277\n",
      "Buffer update speed: -1.6/s\n",
      "Number of environment steps: 965342\n",
      "Average episode return: 9.8342\n",
      "Number of training steps: 5353\n",
      "Training speed: 7.3/s\n",
      "Loss: 0.0740\n",
      "\n",
      "Buffer size: 12247\n",
      "Buffer update speed: -3.2/s\n",
      "Number of environment steps: 978774\n",
      "Average episode return: 9.7978\n",
      "Number of training steps: 5407\n",
      "Training speed: 5.4/s\n",
      "Loss: 0.0749\n",
      "\n",
      "Buffer size: 12476\n",
      "Buffer update speed: 23.1/s\n",
      "Number of environment steps: 995854\n",
      "Average episode return: 9.9708\n",
      "Number of training steps: 5454\n",
      "Training speed: 4.7/s\n",
      "Loss: 0.0679\n",
      "\n",
      "Buffer size: 12267\n",
      "Buffer update speed: -21.0/s\n",
      "Number of environment steps: 1010246\n",
      "Average episode return: 9.8350\n",
      "Number of training steps: 5598\n",
      "Training speed: 14.4/s\n",
      "Loss: 0.0782\n",
      "\n",
      "Buffer size: 12413\n",
      "Buffer update speed: 13.7/s\n",
      "Number of environment steps: 1022560\n",
      "Average episode return: 9.9271\n",
      "Number of training steps: 5668\n",
      "Training speed: 7.0/s\n",
      "Loss: 0.0553\n",
      "\n",
      "Buffer size: 12126\n",
      "Buffer update speed: -28.7/s\n",
      "Number of environment steps: 1037933\n",
      "\n",
      "Average episode return: 9.7540Number of training steps: 5712\n",
      "Training speed: 4.4/s\n",
      "Loss: 0.0479\n",
      "\n",
      "Buffer size: 12229\n",
      "Buffer update speed: 10.1/s\n",
      "Number of environment steps: 1052183\n",
      "Average episode return: 9.7724\n",
      "Number of training steps: 5768\n",
      "Training speed: 5.8/s\n",
      "Loss: 0.0651\n",
      "\n",
      "Buffer size: 12390\n",
      "Buffer update speed: 17.5/s\n",
      "Number of environment steps: 1065586\n",
      "Average episode return: 9.9223\n",
      "Number of training steps: 5829\n",
      "Training speed: 5.9/s\n",
      "Loss: 0.0478\n",
      "\n",
      "Buffer size: 12178\n",
      "Buffer update speed: -21.1/s\n",
      "Number of environment steps: 1080024\n",
      "Average episode return: 9.7427\n",
      "Number of training steps: 5875\n",
      "Training speed: 4.6/s\n",
      "Loss: 0.0505\n",
      "\n",
      "Buffer size: 12542\n",
      "Buffer update speed: 36.6/s\n",
      "Number of environment steps: 1093885\n",
      "Average episode return: 10.0036\n",
      "Number of training steps: 5954\n",
      "Training speed: 7.9/s\n",
      "Loss: 0.0488\n",
      "\n",
      "Buffer size: 12611\n",
      "Buffer update speed: 6.6/s\n",
      "Number of environment steps: 1110511\n",
      "Average episode return: 10.0498\n",
      "Number of training steps: 6042\n",
      "Training speed: 8.7/s\n",
      "Loss: 0.0501\n",
      "\n",
      "Buffer size: 12162\n",
      "Buffer update speed: -44.3/s\n",
      "Number of environment steps: 1130711\n",
      "Average episode return: 9.7780\n",
      "Number of training steps: 6097\n",
      "Training speed: 5.5/s\n",
      "Loss: 0.0537\n",
      "\n",
      "Buffer size: 13053\n",
      "Buffer update speed: 90.0/s\n",
      "Number of environment steps: 1150792\n",
      "Average episode return: 10.2072\n",
      "Number of training steps: 6175\n",
      "Training speed: 7.9/s\n",
      "Loss: 0.0385\n",
      "\n",
      "Buffer size: 20466\n",
      "Buffer update speed: 740.5/s\n",
      "Number of environment steps: 1169477\n",
      "Average episode return: 18.4657\n",
      "Number of training steps: 6251\n",
      "Training speed: 7.6/s\n",
      "Loss: 0.0545\n",
      "\n",
      "Buffer size: 27561\n",
      "Buffer update speed: 707.3/s\n",
      "Number of environment steps: 1184850\n",
      "Average episode return: 22.5468\n",
      "Number of training steps: 6307\n",
      "Training speed: 5.5/s\n",
      "Loss: 0.1083\n",
      "\n",
      "Buffer size: 19011\n",
      "Buffer update speed: -856.7/s\n",
      "Number of environment steps: 1197043\n",
      "Average episode return: 13.6599\n",
      "Number of training steps: 6371\n",
      "Training speed: 6.4/s\n",
      "Loss: 0.1885\n",
      "\n",
      "Buffer size: 15546\n",
      "Buffer update speed: -343.0/s\n",
      "Number of environment steps: 1212491\n",
      "Average episode return: 12.4984\n",
      "Number of training steps: 6458\n",
      "Training speed: 8.7/s\n",
      "Loss: 0.1488\n",
      "\n",
      "Buffer size: 23782\n",
      "Buffer update speed: 823.9/s\n",
      "Number of environment steps: 1225550\n",
      "Average episode return: 35.7781\n",
      "Number of training steps: 6511\n",
      "Training speed: 5.3/s\n",
      "Loss: 0.2392\n",
      "\n",
      "Buffer size: 31506\n",
      "Buffer update speed: 766.9/s\n",
      "Number of environment steps: 1240122\n",
      "Average episode return: 38.3673\n",
      "Number of training steps: 6564\n",
      "Training speed: 5.3/s\n",
      "Loss: 0.2576\n",
      "\n",
      "Buffer size: 31666\n",
      "Buffer update speed: 16.9/s\n",
      "Number of environment steps: 1252540\n",
      "Average episode return: 25.0490\n",
      "Number of training steps: 6634\n",
      "Training speed: 7.0/s\n",
      "Loss: 0.2162\n",
      "\n",
      "Buffer size: 28480\n",
      "Buffer update speed: -319.1/s\n",
      "Number of environment steps: 1266074\n",
      "Average episode return: 21.4038\n",
      "Number of training steps: 6671\n",
      "Training speed: 3.8/s\n",
      "Loss: 0.2630\n",
      "\n",
      "Buffer size: 29474\n",
      "Buffer update speed: 99.4/s\n",
      "Number of environment steps: 1278462\n",
      "Average episode return: 31.6829\n",
      "Number of training steps: 6730\n",
      "Training speed: 5.8/s\n",
      "Loss: 0.3356\n",
      "\n",
      "Buffer size: 32361\n",
      "Buffer update speed: 287.9/s\n",
      "Number of environment steps: 1291063\n",
      "Average episode return: 42.8605\n",
      "Number of training steps: 6797\n",
      "\n",
      "Training speed: 6.7/sLoss: 0.2788\n",
      "\n",
      "Buffer size: 24561\n",
      "Buffer update speed: -775.9/s\n",
      "Number of environment steps: 1303331\n",
      "Average episode return: 16.0683\n",
      "Number of training steps: 6844\n",
      "Training speed: 4.7/s\n",
      "Loss: 0.2263\n",
      "\n",
      "Buffer size: 24190\n",
      "Buffer update speed: -40.1/s\n",
      "Number of environment steps: 1317695\n",
      "Average episode return: 38.5094\n",
      "Number of training steps: 6972\n",
      "Training speed: 12.8/s\n",
      "Loss: 0.1974\n",
      "\n",
      "Buffer size: 31948\n",
      "Buffer update speed: 777.0/sNumber of environment steps: 1332897\n",
      "\n",
      "Average episode return: 34.5624\n",
      "Number of training steps: 7025\n",
      "Training speed: 5.4/s\n",
      "Loss: 0.2329\n",
      "\n",
      "Buffer size: 35352\n",
      "Buffer update speed: 334.0/s\n",
      "Number of environment steps: 1345020\n",
      "Average episode return: 34.3438\n",
      "Number of training steps: 7111\n",
      "Training speed: 8.4/s\n",
      "Loss: 0.2794\n",
      "\n",
      "Buffer size: 35383\n",
      "Buffer update speed: 1.9/s\n",
      "Number of environment steps: 1356469\n",
      "Average episode return: 45.0949\n",
      "Number of training steps: 7164\n",
      "Training speed: 5.3/s\n",
      "Loss: 0.2876\n",
      "\n",
      "Buffer size: 33451\n",
      "Buffer update speed: -195.4/s\n",
      "Number of environment steps: 1369037\n",
      "Average episode return: 34.5944\n",
      "Number of training steps: 7221\n",
      "Training speed: 5.7/s\n",
      "Loss: 0.2472\n",
      "\n",
      "Buffer size: 33118\n",
      "Buffer update speed: -33.3/s\n",
      "Number of environment steps: 1380780\n",
      "Average episode return: 39.2709\n",
      "Number of training steps: 7304\n",
      "Training speed: 8.3/s\n",
      "Loss: 0.2242\n",
      "\n",
      "Buffer size: 34854\n",
      "Buffer update speed: 172.5/s\n",
      "Number of environment steps: 1394549\n",
      "Average episode return: 35.2148\n",
      "Number of training steps: 7350\n",
      "Training speed: 4.6/s\n",
      "Loss: 0.2063\n",
      "\n",
      "Buffer size: 37018\n",
      "Buffer update speed: 217.0/s\n",
      "Number of environment steps: 1409375\n",
      "Average episode return: 35.9148\n",
      "Number of training steps: 7414\n",
      "Training speed: 6.6/s\n",
      "Loss: 0.2221\n",
      "\n",
      "Buffer size: 36411\n",
      "Buffer update speed: -63.7/s\n",
      "Number of environment steps: 1425625\n",
      "Average episode return: 41.1888\n",
      "Number of training steps: 7486\n",
      "Training speed: 7.0/s\n",
      "Loss: 0.2159\n",
      "\n",
      "Buffer size: 25959\n",
      "Buffer update speed: -1049.2/s\n",
      "Number of environment steps: 1440573\n",
      "Average episode return: 19.9039\n",
      "Number of training steps: 7597\n",
      "Training speed: 11.1/s\n",
      "Loss: 0.2775\n",
      "\n",
      "Buffer size: 17245\n",
      "Buffer update speed: -860.3/s\n",
      "Number of environment steps: 1452406\n",
      "Average episode return: 16.6164\n",
      "Number of training steps: 7636\n",
      "Training speed: 3.9/s\n",
      "Loss: 0.3618\n",
      "\n",
      "Buffer size: 24860\n",
      "Buffer update speed: 761.5/s\n",
      "Number of environment steps: 1466245\n",
      "Average episode return: 42.7130\n",
      "Number of training steps: 7730\n",
      "Training speed: 9.4/s\n",
      "Loss: 0.3478\n",
      "\n",
      "Buffer size: 32406\n",
      "Buffer update speed: 752.8/s\n",
      "Number of environment steps: 1481536\n",
      "Average episode return: 45.5753\n",
      "Number of training steps: 7793\n",
      "Training speed: 6.3/s\n",
      "Loss: 0.3080\n",
      "\n",
      "Buffer size: 29144\n",
      "Buffer update speed: -325.5/s\n",
      "Number of environment steps: 1498546\n",
      "Average episode return: 26.5469\n",
      "Number of training steps: 7911\n",
      "Training speed: 11.8/s\n",
      "Loss: 0.2712\n",
      "\n",
      "Buffer size: 28720\n",
      "Buffer update speed: -42.8/s\n",
      "Number of environment steps: 1511586\n",
      "Average episode return: 38.7066\n",
      "Number of training steps: 7984\n",
      "Training speed: 7.3/s\n",
      "Loss: 0.3434\n",
      "\n",
      "Buffer size: 30896\n",
      "Buffer update speed: 217.5/s\n",
      "Number of environment steps: 1522166\n",
      "Average episode return: 44.6610\n",
      "Number of training steps: 8070\n",
      "Training speed: 8.6/s\n",
      "Loss: 0.4258\n",
      "\n",
      "Buffer size: 31641\n",
      "Buffer update speed: 74.5/s\n",
      "Number of environment steps: 1537387\n",
      "Average episode return: 45.1662\n",
      "Number of training steps: 8159\n",
      "Training speed: 9.2/s\n",
      "Loss: 0.3645\n",
      "\n",
      "Buffer size: 31981\n",
      "Buffer update speed: 33.7/s\n",
      "Number of environment steps: 1550958\n",
      "Average episode return: 41.8646\n",
      "Number of training steps: 8219\n",
      "Training speed: 5.7/s\n",
      "Loss: 0.2877\n",
      "\n",
      "Buffer size: 32486\n",
      "Buffer update speed: 50.8/s\n",
      "Number of environment steps: 1563879\n",
      "Average episode return: 40.2704\n",
      "Number of training steps: 8272\n",
      "Training speed: 5.3/s\n",
      "Loss: 0.2634\n",
      "\n",
      "Buffer size: 32869\n",
      "Buffer update speed: 40.5/s\n",
      "Number of environment steps: 1578933\n",
      "Average episode return: 40.9837\n",
      "Number of training steps: 8351\n",
      "Training speed: 7.7/s\n",
      "Loss: 0.2863\n",
      "\n",
      "Buffer size: 33636\n",
      "Buffer update speed: 73.1/s\n",
      "Number of environment steps: 1592052\n",
      "Average episode return: 40.8563\n",
      "Number of training steps: 8402\n",
      "Training speed: 5.1/s\n",
      "Loss: 0.2800\n",
      "\n",
      "Buffer size: 33349\n",
      "Buffer update speed: -33.0/s\n",
      "Number of environment steps: 1606511\n",
      "Average episode return: 41.0737\n",
      "Number of training steps: 8468\n",
      "Training speed: 6.7/s\n",
      "Loss: 0.2410\n",
      "\n",
      "Buffer size: 32265\n",
      "Buffer update speed: -104.1/s\n",
      "Number of environment steps: 1617047\n",
      "Average episode return: 40.5251\n",
      "Number of training steps: 8524\n",
      "Training speed: 5.5/s\n",
      "Loss: 0.2747\n",
      "\n",
      "Buffer size: 19025\n",
      "Buffer update speed: -1324.2/s\n",
      "Number of environment steps: 1630064Average episode return: 13.4461\n",
      "\n",
      "Number of training steps: 8588\n",
      "Training speed: 6.4/s\n",
      "Loss: 0.3818\n",
      "\n",
      "Buffer size: 20902\n",
      "Buffer update speed: 194.1/s\n",
      "Number of environment steps: 1644195\n",
      "Average episode return: 32.6311\n",
      "Number of training steps: 8647\n",
      "Training speed: 5.8/s\n",
      "Loss: 0.5477\n",
      "\n",
      "Buffer size: 28275\n",
      "Buffer update speed: 735.4/s\n",
      "Number of environment steps: 1656750\n",
      "Average episode return: 41.2244\n",
      "Number of training steps: 8721\n",
      "Training speed: 7.2/s\n",
      "Loss: 0.4723\n",
      "\n",
      "Buffer size: 30614\n",
      "Buffer update speed: 226.5/s\n",
      "Number of environment steps: 1669331\n",
      "Average episode return: 30.8277\n",
      "Number of training steps: 8781\n",
      "Training speed: 5.8/s\n",
      "Loss: 0.3951\n",
      "\n",
      "Buffer size: 25598\n",
      "Buffer update speed: -500.0/s\n",
      "Number of environment steps: 1683032\n",
      "Average episode return: 22.7679\n",
      "Number of training steps: 8865\n",
      "Training speed: 8.4/s\n",
      "Loss: 0.4612\n",
      "\n",
      "Buffer size: 26182\n",
      "Buffer update speed: 65.9/s\n",
      "Number of environment steps: 1696645\n",
      "Average episode return: 28.3604\n",
      "Number of training steps: 8964\n",
      "Training speed: 9.9/s\n",
      "Loss: 0.5970\n",
      "\n",
      "Buffer size: 27883\n",
      "Buffer update speed: 165.4/s\n",
      "Number of environment steps: 1709090\n",
      "Average episode return: 29.7488\n",
      "Number of training steps: 9053\n",
      "Training speed: 8.9/s\n",
      "Loss: 0.6490\n",
      "\n",
      "Buffer size: 30582\n",
      "Buffer update speed: 269.3/s\n",
      "Number of environment steps: 1720616\n",
      "Average episode return: 36.7111\n",
      "Number of training steps: 9120\n",
      "Training speed: 6.8/s\n",
      "Loss: 0.5811\n",
      "\n",
      "Buffer size: 32965\n",
      "Buffer update speed: 239.4/s\n",
      "Number of environment steps: 1732674\n",
      "Average episode return: 40.9283\n",
      "Number of training steps: 9215\n",
      "Training speed: 9.4/s\n",
      "Loss: 0.5889\n",
      "\n",
      "Buffer size: 33233\n",
      "Buffer update speed: 22.7/s\n",
      "Number of environment steps: 1749287\n",
      "Average episode return: 42.1527\n",
      "Number of training steps: 9311\n",
      "Training speed: 9.6/s\n",
      "Loss: 0.4733\n",
      "\n",
      "Buffer size: 32799\n",
      "Buffer update speed: -42.0/s\n",
      "Number of environment steps: 1762842\n",
      "Average episode return: 39.8251\n",
      "Number of training steps: 9356\n",
      "Training speed: 4.5/s\n",
      "Loss: 0.3924\n",
      "\n",
      "Buffer size: 34009\n",
      "Buffer update speed: 121.0/s\n",
      "Number of environment steps: 1776793\n",
      "Average episode return: 39.5486\n",
      "Number of training steps: 9437\n",
      "Training speed: 7.9/s\n",
      "Loss: 0.3506\n",
      "\n",
      "Buffer size: 34464\n",
      "Buffer update speed: 45.5/s\n",
      "Number of environment steps: 1791297\n",
      "Average episode return: 38.8841\n",
      "Number of training steps: 9517\n",
      "Training speed: 8.0/s\n",
      "\n",
      "Loss: 0.3030\n",
      "Buffer size: 19476\n",
      "Buffer update speed: -1500.9/s\n",
      "Number of environment steps: 1810571\n",
      "Average episode return: 16.9219\n",
      "Number of training steps: 9623\n",
      "Training speed: 10.6/s\n",
      "Loss: 0.4622\n",
      "\n",
      "Buffer size: 26757\n",
      "Buffer update speed: 730.3/s\n",
      "Number of environment steps: 1827186\n",
      "Average episode return: 39.2790\n",
      "Number of training steps: 9722\n",
      "Training speed: 9.9/s\n",
      "Loss: 0.6663\n",
      "\n",
      "Buffer size: 30780\n",
      "Buffer update speed: 398.3/s\n",
      "Number of environment steps: 1840985\n",
      "Average episode return: 29.4399\n",
      "Number of training steps: 9813\n",
      "Training speed: 9.1/s\n",
      "Loss: 0.5307\n",
      "\n",
      "Buffer size: 28053\n",
      "Buffer update speed: -274.0/s\n",
      "Number of environment steps: 1853345\n",
      "Average episode return: 26.2579\n",
      "Number of training steps: 9876\n",
      "Training speed: 6.3/s\n",
      "Loss: 0.5887\n",
      "\n",
      "Buffer size: 28710\n",
      "Buffer update speed: 70.4/s\n",
      "Number of environment steps: 1868050\n",
      "Average episode return: 36.9471\n",
      "Number of training steps: 9925\n",
      "Training speed: 4.9/s\n",
      "Loss: 0.6212\n",
      "\n",
      "Buffer size: 30925\n",
      "Buffer update speed: 219.2/s\n",
      "Number of environment steps: 1882463\n",
      "Average episode return: 32.3888\n",
      "Number of training steps: 9981\n",
      "Training speed: 5.6/s\n",
      "Loss: 0.5875\n",
      "\n",
      "Buffer size: 30028\n",
      "Buffer update speed: -90.2/s\n",
      "Number of environment steps: 1895401\n",
      "Average episode return: 33.5933\n",
      "Number of training steps: 10049Training speed: 6.8/s\n",
      "\n",
      "Loss: 0.5571\n",
      "\n",
      "Buffer size: 31279\n",
      "Buffer update speed: 125.9/s\n",
      "Number of environment steps: 1911973\n",
      "Average episode return: 49.0833\n",
      "Number of training steps: 10103\n",
      "Training speed: 5.4/s\n",
      "Loss: 0.5754\n",
      "\n",
      "Buffer size: 33108\n",
      "Buffer update speed: 182.9/s\n",
      "Number of environment steps: 1923995\n",
      "Average episode return: 47.5929\n",
      "Number of training steps: 10187\n",
      "Training speed: 8.4/s\n",
      "Loss: 0.4684\n",
      "\n",
      "Buffer size: 32176\n",
      "Buffer update speed: -96.0/s\n",
      "Number of environment steps: 1937733\n",
      "Average episode return: 35.9029\n",
      "Number of training steps: 10235\n",
      "Training speed: 4.8/s\n",
      "Loss: 0.3738\n",
      "\n",
      "Buffer size: 31384\n",
      "Buffer update speed: -79.2/s\n",
      "Number of environment steps: 1951471\n",
      "Average episode return: 40.4737\n",
      "Number of training steps: 10323\n",
      "Training speed: 8.9/s\n",
      "Loss: 0.4343\n",
      "\n",
      "Buffer size: 31948\n",
      "Buffer update speed: 51.9/s\n",
      "Number of environment steps: 1961857\n",
      "Average episode return: 47.4700\n",
      "Number of training steps: 10379\n",
      "Training speed: 5.5/s\n",
      "Loss: 0.4854\n",
      "\n",
      "Buffer size: 32197\n",
      "Buffer update speed: 24.9/s\n",
      "Number of environment steps: 1974696\n",
      "Average episode return: 43.0943\n",
      "Number of training steps: 10471\n",
      "Training speed: 9.2/s\n",
      "Loss: 0.4247\n",
      "\n",
      "Buffer size: 31111\n",
      "Buffer update speed: -108.6/s\n",
      "Number of environment steps: 1986338\n",
      "Average episode return: 33.5504\n",
      "Number of training steps: 10558\n",
      "Training speed: 8.7/s\n",
      "Loss: 0.4657\n",
      "\n",
      "Buffer size: 30070\n",
      "Buffer update speed: -103.7/s\n",
      "Number of environment steps: 1999108\n",
      "Average episode return: 32.6967\n",
      "Number of training steps: 10604\n",
      "Training speed: 4.6/s\n",
      "Loss: 0.5389\n",
      "\n",
      "Buffer size: 30139\n",
      "Buffer update speed: 8.3/s\n",
      "Number of environment steps: 2012013\n",
      "Average episode return: 44.7924\n",
      "Number of training steps: 10678\n",
      "Training speed: 7.4/s\n",
      "Loss: 0.6167\n",
      "\n",
      "Buffer size: 31744\n",
      "Buffer update speed: 161.5/s\n",
      "Number of environment steps: 2025593\n",
      "Average episode return: 42.7215\n",
      "Number of training steps: 10740\n",
      "Training speed: 6.0/s\n",
      "Loss: 0.5373\n",
      "\n",
      "Buffer size: 31495\n",
      "Buffer update speed: -29.1/s\n",
      "Number of environment steps: 2036795\n",
      "Average episode return: 35.3375\n",
      "Number of training steps: 10833\n",
      "Training speed: 9.2/s\n",
      "Loss: 0.4952\n",
      "\n",
      "Buffer size: 31661\n",
      "Buffer update speed: 13.2/s\n",
      "Number of environment steps: 2049189\n",
      "Average episode return: 42.0625\n",
      "Number of training steps: 10928\n",
      "Training speed: 9.5/s\n",
      "Loss: 0.5609\n",
      "\n",
      "Buffer size: 32295\n",
      "Buffer update speed: 62.6/s\n",
      "Number of environment steps: 2063177\n",
      "Average episode return: 45.1897\n",
      "Number of training steps: 11027\n",
      "Training speed: 9.9/s\n",
      "Loss: 0.5402\n",
      "\n",
      "Buffer size: 32710\n",
      "Buffer update speed: 46.7/s\n",
      "Number of environment steps: 2077074\n",
      "Average episode return: 45.2222\n",
      "Number of training steps: 11120\n",
      "Training speed: 9.3/s\n",
      "Loss: 0.5421\n",
      "\n",
      "Buffer size: 34032\n",
      "Buffer update speed: 131.1/s\n",
      "Number of environment steps: 2093570\n",
      "Average episode return: 53.4411\n",
      "Number of training steps: 11216\n",
      "Training speed: 9.5/s\n",
      "Loss: 0.4665\n",
      "\n",
      "Buffer size: 34057\n",
      "Buffer update speed: 2.5/s\n",
      "Number of environment steps: 2107060\n",
      "Average episode return: 45.5537\n",
      "Number of training steps: 11293\n",
      "Training speed: 7.7/s\n",
      "Loss: 0.4456\n",
      "\n",
      "Buffer size: 32573\n",
      "Buffer update speed: -146.8/s\n",
      "Number of environment steps: 2120907\n",
      "Average episode return: 38.9068\n",
      "Number of training steps: 11377\n",
      "Training speed: 8.4/s\n",
      "Loss: 0.4842\n",
      "\n",
      "Buffer size: 31058\n",
      "Buffer update speed: -154.3/s\n",
      "Number of environment steps: 2133375\n",
      "Average episode return: 36.4561\n",
      "Number of training steps: 11415\n",
      "Training speed: 3.8/s\n",
      "Loss: 0.5093\n",
      "\n",
      "Buffer size: 31479\n",
      "Buffer update speed: 44.6/s\n",
      "Number of environment steps: 2146338\n",
      "Average episode return: 47.8922\n",
      "Number of training steps: 11484\n",
      "Training speed: 6.9/s\n",
      "Loss: 0.5197\n",
      "\n",
      "Buffer size: 31898\n",
      "Buffer update speed: 33.4/s\n",
      "Number of environment steps: 2158288\n",
      "Average episode return: 44.7388\n",
      "Number of training steps: 11532\n",
      "Training speed: 4.8/s\n",
      "Loss: 0.5532\n",
      "\n",
      "Buffer size: 32414\n",
      "Buffer update speed: 53.7/s\n",
      "Number of environment steps: 2171823\n",
      "Average episode return: 41.6361\n",
      "Number of training steps: 11630\n",
      "Training speed: 9.9/s\n",
      "Loss: 0.5125\n",
      "\n",
      "Buffer size: 31881\n",
      "Buffer update speed: -52.0/s\n",
      "Number of environment steps: 2186499\n",
      "Average episode return: 41.8171\n",
      "Number of training steps: 11706\n",
      "Training speed: 7.4/s\n",
      "Loss: 0.5375\n",
      "\n",
      "Buffer size: 31559\n",
      "Buffer update speed: -29.1/s\n",
      "Number of environment steps: 2198779\n",
      "Average episode return: 42.9395\n",
      "Number of training steps: 11798\n",
      "Training speed: 9.2/s\n",
      "Loss: 0.5164\n",
      "\n",
      "Buffer size: 32312\n",
      "Buffer update speed: 72.2/s\n",
      "Number of environment steps: 2212600\n",
      "Average episode return: 45.1331\n",
      "Number of training steps: 11844\n",
      "Training speed: 4.6/s\n",
      "Loss: 0.5081\n",
      "\n",
      "Buffer size: 34698\n",
      "Buffer update speed: 235.2/s\n",
      "Number of environment steps: 2231866\n",
      "Average episode return: 57.5247\n",
      "Number of training steps: 11955\n",
      "Training speed: 11.1/s\n",
      "Loss: 0.5353\n",
      "\n",
      "Buffer size: 36432\n",
      "Buffer update speed: 176.8/s\n",
      "Number of environment steps: 2244375\n",
      "Average episode return: 65.7742\n",
      "Number of training steps: 12004\n",
      "Training speed: 4.9/s\n",
      "Loss: 0.4904\n",
      "\n",
      "Buffer size: 36792\n",
      "Buffer update speed: 36.0/s\n",
      "Number of environment steps: 2254944\n",
      "Average episode return: 57.3743\n",
      "Number of training steps: 12056\n",
      "Training speed: 5.2/s\n",
      "Loss: 0.4894\n",
      "\n",
      "Buffer size: 34672\n",
      "Buffer update speed: -212.6/s\n",
      "Number of environment steps: 2269075\n",
      "Average episode return: 44.9071\n",
      "Number of training steps: 12119\n",
      "Training speed: 6.3/sLoss: 0.4754\n",
      "\n",
      "\n",
      "Buffer size: 30522\n",
      "Buffer update speed: -412.6/s\n",
      "Number of environment steps: 2283323\n",
      "Average episode return: 31.1261\n",
      "Number of training steps: 12204\n",
      "Training speed: 8.4/s\n",
      "Loss: 0.4729\n",
      "\n",
      "Buffer size: 29618\n",
      "Buffer update speed: -93.6/s\n",
      "Number of environment steps: 2297470\n",
      "Average episode return: 38.0349\n",
      "Number of training steps: 12269\n",
      "Training speed: 6.5/s\n",
      "Loss: 0.6838\n",
      "\n",
      "Buffer size: 30989\n",
      "Buffer update speed: 138.5/s\n",
      "Number of environment steps: 2308513\n",
      "Average episode return: 51.2864\n",
      "Number of training steps: 12332\n",
      "Training speed: 6.3/s\n",
      "Loss: 0.7216\n",
      "\n",
      "Buffer size: 33662\n",
      "Buffer update speed: 267.4/s\n",
      "Number of environment steps: 2323569\n",
      "Average episode return: 50.6538\n",
      "Number of training steps: 12410\n",
      "Training speed: 7.8/s\n",
      "Loss: 0.6069\n",
      "\n",
      "Buffer size: 33739\n",
      "Buffer update speed: 5.5/s\n",
      "Number of environment steps: 2334698\n",
      "Average episode return: 42.6298\n",
      "Number of training steps: 12468\n",
      "Training speed: 5.7/s\n",
      "Loss: 0.5239\n",
      "\n",
      "Buffer size: 32510\n",
      "Buffer update speed: -125.4/s\n",
      "Number of environment steps: 2346911\n",
      "Average episode return: 43.7742\n",
      "Number of training steps: 12523\n",
      "Training speed: 5.5/s\n",
      "Loss: 0.4941\n",
      "\n",
      "Buffer size: 30980\n",
      "Buffer update speed: -150.3/s\n",
      "Number of environment steps: 2360330\n",
      "Average episode return: 31.8833\n",
      "Number of training steps: 12600\n",
      "Training speed: 7.7/s\n",
      "Loss: 0.5858\n",
      "\n",
      "Buffer size: 30428\n",
      "Buffer update speed: -54.9/sNumber of environment steps: 2375561\n",
      "\n",
      "Average episode return: 36.8637\n",
      "Number of training steps: 12641\n",
      "Training speed: 4.0/s\n",
      "Loss: 0.6614\n",
      "\n",
      "Buffer size: 31481\n",
      "Buffer update speed: 108.0/s\n",
      "Number of environment steps: 2386239\n",
      "Average episode return: 45.4573\n",
      "Number of training steps: 12738\n",
      "Training speed: 9.7/s\n",
      "Loss: 0.7427\n",
      "\n",
      "Buffer size: 32080\n",
      "Buffer update speed: 63.0/s\n",
      "Number of environment steps: 2398834\n",
      "Average episode return: 41.1803\n",
      "Number of training steps: 12784\n",
      "Training speed: 4.5/s\n",
      "Loss: 0.6372\n",
      "\n",
      "Buffer size: 31585\n",
      "Buffer update speed: -49.5/s\n",
      "Number of environment steps: 2413328\n",
      "Average episode return: 37.7199\n",
      "Number of training steps: 12880\n",
      "Training speed: 9.6/s\n",
      "Loss: 0.6130\n",
      "\n",
      "Buffer size: 31164\n",
      "Buffer update speed: -40.9/s\n",
      "Number of environment steps: 2425989\n",
      "Average episode return: 38.9665\n",
      "Number of training steps: 12980\n",
      "Training speed: 10.0/s\n",
      "Loss: 0.6713\n",
      "\n",
      "Buffer size: 32252\n",
      "Buffer update speed: 107.9/s\n",
      "Number of environment steps: 2438886\n",
      "Average episode return: 47.3094\n",
      "Number of training steps: 13044\n",
      "Training speed: 6.4/s\n",
      "Loss: 0.6949\n",
      "\n",
      "Buffer size: 32937\n",
      "Buffer update speed: 68.6/s\n",
      "Number of environment steps: 2453618\n",
      "Average episode return: 47.8058\n",
      "Number of training steps: 13109\n",
      "Training speed: 6.7/s\n",
      "Loss: 0.5681\n",
      "\n",
      "Buffer size: 32717\n",
      "Buffer update speed: -26.1/s\n",
      "Number of environment steps: 2467687\n",
      "Average episode return: 42.8207\n",
      "Number of training steps: 13180\n",
      "Training speed: 6.9/s\n",
      "Loss: 0.5602\n",
      "\n",
      "Buffer size: 32074\n",
      "Buffer update speed: -63.8/s\n",
      "Number of environment steps: 2480928\n",
      "Average episode return: 44.0236\n",
      "Number of training steps: 13233\n",
      "Training speed: 5.3/s\n",
      "Loss: 0.5576\n",
      "\n",
      "Buffer size: 32251\n",
      "Buffer update speed: 18.8/s\n",
      "Number of environment steps: 2496307\n",
      "Average episode return: 44.5014\n",
      "Number of training steps: 13286\n",
      "Training speed: 5.3/s\n",
      "Loss: 0.5276\n",
      "\n",
      "Buffer size: 32499\n",
      "Buffer update speed: 27.0/s\n",
      "Number of environment steps: 2509239\n",
      "Average episode return: 47.6066\n",
      "Number of training steps: 13388\n",
      "Training speed: 10.2/s\n",
      "Loss: 0.5102\n",
      "\n",
      "Buffer size: 32085\n",
      "Buffer update speed: -43.4/s\n",
      "Number of environment steps: 2523692\n",
      "Average episode return: 41.7884\n",
      "Number of training steps: 13453\n",
      "Training speed: 6.5/s\n",
      "Loss: 0.5133\n",
      "\n",
      "Buffer size: 31638\n",
      "Buffer update speed: -39.0/s\n",
      "Number of environment steps: 2534845\n",
      "Average episode return: 40.2635\n",
      "Number of training steps: 13513\n",
      "Training speed: 6.0/s\n",
      "Loss: 0.5120\n",
      "\n",
      "Buffer size: 31304\n",
      "Buffer update speed: -34.8/s\n",
      "Number of environment steps: 2545698\n",
      "Average episode return: 37.1581\n",
      "Number of training steps: 13569\n",
      "Training speed: 5.6/s\n",
      "Loss: 0.5874\n",
      "\n",
      "Buffer size: 31609\n",
      "Buffer update speed: 28.6/s\n",
      "Number of environment steps: 2556315\n",
      "Average episode return: 43.7375\n",
      "Number of training steps: 13636\n",
      "Training speed: 6.6/s\n",
      "Loss: 0.6008\n",
      "\n",
      "Buffer size: 32042\n",
      "Buffer update speed: 45.6/s\n",
      "Number of environment steps: 2569144\n",
      "Average episode return: 42.9933\n",
      "Number of training steps: 13737\n",
      "Training speed: 10.1/s\n",
      "Loss: 0.6665\n",
      "\n",
      "Buffer size: 31941\n",
      "Buffer update speed: -8.8/s\n",
      "Number of environment steps: 2582449\n",
      "Number of training steps: 13831Average episode return: 38.4986\n",
      "\n",
      "Training speed: 9.2/s\n",
      "Loss: 0.6625\n",
      "\n",
      "Buffer size: 31319\n",
      "Buffer update speed: -69.9/s\n",
      "Number of environment steps: 2598033\n",
      "Average episode return: 34.8103\n",
      "Number of training steps: 13923\n",
      "Training speed: 9.2/s\n",
      "Loss: 0.7354\n",
      "\n",
      "Buffer size: 30900\n",
      "Buffer update speed: -35.8/s\n",
      "Number of environment steps: 2609996\n",
      "Average episode return: 34.8119\n",
      "Number of training steps: 13969\n",
      "Training speed: 4.6/s\n",
      "Loss: 0.8144\n",
      "\n",
      "Buffer size: 31690\n",
      "Buffer update speed: 77.7/s\n",
      "Number of environment steps: 2621601\n",
      "Average episode return: 39.1111\n",
      "Number of training steps: 14039\n",
      "Training speed: 7.0/s\n",
      "Loss: 0.7920\n",
      "\n",
      "Buffer size: 33663\n",
      "Buffer update speed: 195.9/s\n",
      "Number of environment steps: 2634503\n",
      "Average episode return: 56.1659\n",
      "Number of training steps: 14098\n",
      "Training speed: 5.8/s\n",
      "Loss: 0.7181\n",
      "\n",
      "Buffer size: 35441\n",
      "Buffer update speed: 178.5/s\n",
      "Number of environment steps: 2650800\n",
      "Average episode return: 50.2677\n",
      "Number of training steps: 14246\n",
      "Training speed: 15.1/s\n",
      "Loss: 0.6543\n",
      "\n",
      "Buffer size: 34000\n",
      "Buffer update speed: -145.9/s\n",
      "Number of environment steps: 2666928\n",
      "Average episode return: 41.6744\n",
      "Number of training steps: 14302\n",
      "Training speed: 5.3/s\n",
      "Loss: 0.5844\n",
      "\n",
      "Buffer size: 31363\n",
      "Buffer update speed: -265.2/s\n",
      "Number of environment steps: 2685169\n",
      "Average episode return: 35.6901\n",
      "Number of training steps: 14360\n",
      "Training speed: 5.8/s\n",
      "Loss: 0.5719\n",
      "\n",
      "Buffer size: 31585\n",
      "Buffer update speed: 24.9/s\n",
      "Number of environment steps: 2697694\n",
      "Average episode return: 41.9559\n",
      "Number of training steps: 14436\n",
      "Training speed: 7.6/s\n",
      "Loss: 0.6559\n",
      "\n",
      "Buffer size: 32274\n",
      "Buffer update speed: 71.3/s\n",
      "Number of environment steps: 2710948\n",
      "Average episode return: 46.7643\n",
      "Number of training steps: 14500\n",
      "Training speed: 6.4/s\n",
      "Loss: 0.6431\n",
      "\n",
      "Buffer size: 32565\n",
      "Buffer update speed: 30.2/s\n",
      "Number of environment steps: 2724221\n",
      "Average episode return: 40.5866\n",
      "Number of training steps: 14581\n",
      "Training speed: 8.1/s\n",
      "Loss: 0.6044\n",
      "\n",
      "Buffer size: 32170\n",
      "Buffer update speed: -40.7/s\n",
      "Number of environment steps: 2739443\n",
      "Average episode return: 36.2153\n",
      "Number of training steps: 14686\n",
      "Training speed: 10.5/s\n",
      "Loss: 0.6962\n",
      "\n",
      "Buffer size: 31551\n",
      "Buffer update speed: -59.8/s\n",
      "Number of environment steps: 2753986\n",
      "Average episode return: 34.3632\n",
      "Number of training steps: 14775\n",
      "Training speed: 8.9/s\n",
      "Loss: 0.7890\n",
      "\n",
      "Buffer size: 31606\n",
      "Buffer update speed: 5.6/s\n",
      "Number of environment steps: 2763976\n",
      "Average episode return: 39.3254\n",
      "Number of training steps: 14833\n",
      "Training speed: 5.8/s\n",
      "Loss: 0.8236\n",
      "\n",
      "Buffer size: 31699\n",
      "Buffer update speed: 8.7/s\n",
      "Number of environment steps: 2778533\n",
      "Average episode return: 39.9754\n",
      "Number of training steps: 14920\n",
      "Training speed: 8.7/s\n",
      "Loss: 0.7293\n",
      "\n",
      "Buffer size: 32105\n",
      "Buffer update speed: 41.1/s\n",
      "Number of environment steps: 2797681\n",
      "Average episode return: 39.8174\n",
      "Number of training steps: 15013\n",
      "Training speed: 9.3/s\n",
      "Loss: 0.6692\n",
      "\n",
      "Buffer size: 31785\n",
      "Buffer update speed: -31.5/s\n",
      "Number of environment steps: 2814057\n",
      "Average episode return: 39.9951\n",
      "Number of training steps: 15108\n",
      "Training speed: 9.2/s\n",
      "Loss: 0.6606\n",
      "\n",
      "Buffer size: 31908\n",
      "Buffer update speed: 10.2/s\n",
      "Number of environment steps: 2824148\n",
      "Average episode return: 42.7759\n",
      "Number of training steps: 15154\n",
      "Training speed: 4.6/s\n",
      "Loss: 0.6573\n",
      "\n",
      "Buffer size: 32666\n",
      "Buffer update speed: 79.3/s\n",
      "Number of environment steps: 2834922\n",
      "Average episode return: 46.3574\n",
      "Number of training steps: 15232\n",
      "Training speed: 7.8/s\n",
      "Loss: 0.6589\n",
      "\n",
      "Buffer size: 32931\n",
      "Buffer update speed: 26.0/s\n",
      "Number of environment steps: 2847752\n",
      "Average episode return: 42.5467\n",
      "Number of training steps: 15381\n",
      "Training speed: 14.9/s\n",
      "Loss: 0.6358\n",
      "\n",
      "Buffer size: 32957\n",
      "Buffer update speed: -0.2/s\n",
      "Number of environment steps: 2859954\n",
      "Average episode return: 45.0842\n",
      "Number of training steps: 15467\n",
      "Training speed: 8.6/s\n",
      "Loss: 0.6200\n",
      "\n",
      "Buffer size: 33018\n",
      "Buffer update speed: 3.1/s\n",
      "Number of environment steps: 2872497\n",
      "Average episode return: 44.3523\n",
      "Number of training steps: 15554\n",
      "Training speed: 8.7/s\n",
      "Loss: 0.6777\n",
      "\n",
      "Buffer size: 32657\n",
      "Buffer update speed: -31.9/s\n",
      "Number of environment steps: 2888070\n",
      "Average episode return: 39.9335\n",
      "Number of training steps: 15642\n",
      "Training speed: 8.8/s\n",
      "Loss: 0.6824\n",
      "\n",
      "Buffer size: 32147\n",
      "Buffer update speed: -51.0/s\n",
      "Number of environment steps: 2901820\n",
      "Average episode return: 39.3948\n",
      "Number of training steps: 15728\n",
      "Training speed: 8.6/s\n",
      "Loss: 0.6945\n",
      "\n",
      "Buffer size: 32437\n",
      "Buffer update speed: 29.0/s\n",
      "Number of environment steps: 2915400\n",
      "Average episode return: 42.9653\n",
      "Number of training steps: 15817\n",
      "Training speed: 8.9/s\n",
      "Loss: 0.7270\n",
      "\n",
      "Buffer size: 32446\n",
      "Buffer update speed: 5.8/s\n",
      "Number of environment steps: 2929980\n",
      "Average episode return: 43.1454\n",
      "Number of training steps: 15897\n",
      "Training speed: 8.0/s\n",
      "Loss: 0.6784\n",
      "\n",
      "Buffer size: 32519\n",
      "Buffer update speed: -0.6/s\n",
      "Number of environment steps: 2947610\n",
      "Average episode return: 41.3785\n",
      "Number of training steps: 15987\n",
      "Training speed: 8.8/s\n",
      "Loss: 0.6478\n",
      "\n",
      "Buffer size: 32066\n",
      "Buffer update speed: -38.8/s\n",
      "Number of environment steps: 2966910\n",
      "Average episode return: 38.6694\n",
      "Number of training steps: 16074\n",
      "Training speed: 8.7/s\n",
      "Loss: 0.6818\n",
      "\n",
      "Buffer size: 32638\n",
      "Buffer update speed: 50.8/s\n",
      "Number of environment steps: 2980615\n",
      "Average episode return: 47.8920\n",
      "Number of training steps: 16139\n",
      "Training speed: 6.5/s\n",
      "Loss: 0.7240\n",
      "\n",
      "Buffer size: 32427\n",
      "Buffer update speed: -20.4/s\n",
      "Number of environment steps: 2996947\n",
      "Average episode return: 43.1230\n",
      "Number of training steps: 16205\n",
      "Training speed: 6.6/s\n",
      "Loss: 0.6215\n",
      "\n",
      "Buffer size: 31694\n",
      "Buffer update speed: -76.9/s\n",
      "Number of environment steps: 3010539\n",
      "Average episode return: 36.9503\n",
      "Number of training steps: 16275\n",
      "Training speed: 7.0/s\n",
      "Loss: 0.6010\n",
      "\n",
      "Buffer size: 31737\n",
      "Buffer update speed: 7.8/s\n",
      "Number of environment steps: 3024722\n",
      "Average episode return: 40.2578\n",
      "Number of training steps: 16316\n",
      "Training speed: 4.1/s\n",
      "Loss: 0.6359\n",
      "\n",
      "Buffer size: 32162\n",
      "Buffer update speed: 46.7/s\n",
      "Number of environment steps: 3039138\n",
      "Average episode return: 38.6954\n",
      "Number of training steps: 16410\n",
      "Training speed: 9.4/s\n",
      "Loss: 0.7248\n",
      "\n",
      "Buffer size: 32410\n",
      "Buffer update speed: 17.5/s\n",
      "Number of environment steps: 3053274\n",
      "Average episode return: 42.5753\n",
      "Number of training steps: 16502\n",
      "Training speed: 9.2/s\n",
      "Loss: 0.7200\n",
      "\n",
      "Buffer size: 32046\n",
      "Buffer update speed: -33.3/s\n",
      "Number of environment steps: 3065155\n",
      "Average episode return: 37.9617\n",
      "Number of training steps: 16607\n",
      "Training speed: 10.3/s\n",
      "Loss: 0.7280\n",
      "\n",
      "Buffer size: 31845\n",
      "Buffer update speed: -22.9/s\n",
      "Number of environment steps: 3076969\n",
      "Average episode return: 38.8595\n",
      "Number of training steps: 16657\n",
      "Training speed: 5.0/s\n",
      "Loss: 0.7709\n",
      "\n",
      "Buffer size: 32143\n",
      "Buffer update speed: 28.3/s\n",
      "Number of environment steps: 3089306\n",
      "Average episode return: 41.3289\n",
      "Number of training steps: 16696\n",
      "Training speed: 3.9/s\n",
      "Loss: 0.6249\n",
      "\n",
      "Buffer size: 32184\n",
      "Buffer update speed: 5.9/s\n",
      "Number of environment steps: 3099702\n",
      "Average episode return: 38.2271\n",
      "Number of training steps: 16736\n",
      "Training speed: 4.0/s\n",
      "Loss: 0.6286\n",
      "\n",
      "Buffer size: 31971\n",
      "Buffer update speed: -24.4/s\n",
      "Number of environment steps: 3112440\n",
      "Average episode return: 37.0556\n",
      "Number of training steps: 16826\n",
      "Training speed: 9.0/s\n",
      "Loss: 0.6681\n",
      "\n",
      "Buffer size: 32077\n",
      "Buffer update speed: 13.6/s\n",
      "Number of environment steps: 3126738\n",
      "Average episode return: 40.5881\n",
      "Number of training steps: 16890\n",
      "\n",
      "Training speed: 6.4/s\n",
      "Loss: 0.7185\n",
      "Buffer size: 32720\n",
      "Buffer update speed: 65.0/s\n",
      "Number of environment steps: 3141716\n",
      "Average episode return: 42.5042\n",
      "Number of training steps: 16957\n",
      "Training speed: 6.7/s\n",
      "Loss: 0.6630\n",
      "\n",
      "Buffer size: 32604\n",
      "Buffer update speed: -4.6/s\n",
      "Number of environment steps: 3152895\n",
      "Average episode return: 37.1538\n",
      "Number of training steps: 17010\n",
      "Training speed: 5.1/s\n",
      "Loss: 0.6231\n",
      "\n",
      "Buffer size: 31651\n",
      "Buffer update speed: -103.1/s\n",
      "Number of environment steps: 3162347\n",
      "Average episode return: 30.2581\n",
      "Number of training steps: 17057\n",
      "Training speed: 4.7/s\n",
      "Loss: 0.6443\n",
      "\n",
      "Buffer size: 30919\n",
      "Buffer update speed: -72.6/s\n",
      "Number of environment steps: 3174838\n",
      "Average episode return: 31.6439\n",
      "Number of training steps: 17129\n",
      "Training speed: 7.2/s\n",
      "Loss: 0.8032\n",
      "\n",
      "Buffer size: 30512\n",
      "Buffer update speed: -41.3/s\n",
      "Number of environment steps: 3188864\n",
      "Average episode return: 32.1517\n",
      "Number of training steps: 17231\n",
      "Training speed: 10.2/s\n",
      "Loss: 0.9051\n",
      "\n",
      "Buffer size: 30706\n",
      "Buffer update speed: 21.9/s\n",
      "Number of environment steps: 3205262\n",
      "Average episode return: 32.7305\n",
      "Number of training steps: 17314\n",
      "Training speed: 8.3/s\n",
      "Loss: 0.9333\n",
      "\n",
      "Buffer size: 31770\n",
      "Buffer update speed: 107.5/s\n",
      "Number of environment steps: 3221077\n",
      "Average episode return: 35.9432\n",
      "Number of training steps: 17397\n",
      "Training speed: 8.3/s\n",
      "Loss: 0.9053\n",
      "\n",
      "Buffer size: 32783\n",
      "Buffer update speed: 98.8/s\n",
      "Number of environment steps: 3234325\n",
      "Average episode return: 40.6738\n",
      "Number of training steps: 17452\n",
      "Training speed: 5.4/s\n",
      "Loss: 0.8438\n",
      "\n",
      "Buffer size: 32540\n",
      "Buffer update speed: -24.3/s\n",
      "Number of environment steps: 3246850\n",
      "Average episode return: 33.4652\n",
      "Number of training steps: 17508\n",
      "Training speed: 5.6/s\n",
      "Loss: 0.7856\n",
      "\n",
      "Buffer size: 32507\n",
      "Buffer update speed: -3.3/s\n",
      "Number of environment steps: 3260557\n",
      "Average episode return: 42.1304\n",
      "Number of training steps: 17548\n",
      "Training speed: 4.0/s\n",
      "Loss: 0.7595\n",
      "\n",
      "Buffer size: 32943\n",
      "Buffer update speed: 43.6/s\n",
      "Number of environment steps: 3273373\n",
      "Average episode return: 46.7601\n",
      "Number of training steps: 17638\n",
      "Training speed: 9.0/s\n",
      "Loss: 0.7371\n",
      "\n",
      "Buffer size: 32889\n",
      "Buffer update speed: -1.7/s\n",
      "Number of environment steps: 3287670\n",
      "Average episode return: 40.6353\n",
      "Number of training steps: 17760\n",
      "Training speed: 12.2/s\n",
      "Loss: 0.7404\n",
      "\n",
      "Buffer size: 32620\n",
      "Buffer update speed: -38.0/s\n",
      "Number of environment steps: 3299847\n",
      "Average episode return: 38.5394\n",
      "Number of training steps: 17811\n",
      "Training speed: 4.9/s\n",
      "Loss: 0.6605\n",
      "\n",
      "Buffer size: 32408\n",
      "Buffer update speed: -16.5/s\n",
      "Number of environment steps: 3309028\n",
      "Average episode return: 40.0925\n",
      "Number of training steps: 17856\n",
      "Training speed: 4.9/s\n",
      "Loss: 0.6923\n",
      "\n",
      "Buffer size: 32628\n",
      "Buffer update speed: 24.4/s\n",
      "Number of environment steps: 3324308\n",
      "Average episode return: 40.3720\n",
      "Number of training steps: 17954\n",
      "Training speed: 9.3/s\n",
      "Loss: 0.6981\n",
      "\n",
      "Buffer size: 32807\n",
      "Buffer update speed: 15.9/s\n",
      "Number of environment steps: 3338033\n",
      "Average episode return: 39.3768\n",
      "Number of training steps: 18005\n",
      "Training speed: 5.1/s\n",
      "Loss: 0.7143\n",
      "\n",
      "Buffer size: 32686\n",
      "Buffer update speed: -11.3/s\n",
      "Number of environment steps: 3350477\n",
      "Average episode return: 36.3567\n",
      "Number of training steps: 18074\n",
      "Training speed: 6.9/s\n",
      "Loss: 0.6812\n",
      "\n",
      "Buffer size: 32672\n",
      "Buffer update speed: -5.6/s\n",
      "Number of environment steps: 3365168\n",
      "Average episode return: 38.3620\n",
      "Number of training steps: 18135\n",
      "Training speed: 6.1/s\n",
      "Loss: 0.7264\n",
      "\n",
      "Buffer size: 32689\n",
      "Buffer update speed: 2.4/s\n",
      "Number of environment steps: 3379709\n",
      "Average episode return: 38.6064\n",
      "Number of training steps: 18194\n",
      "Training speed: 5.9/s\n",
      "Loss: 0.7362\n",
      "\n",
      "Buffer size: 32333\n",
      "Buffer update speed: -31.7/s\n",
      "Number of environment steps: 3390844\n",
      "Average episode return: 39.9242\n",
      "Number of training steps: 18242\n",
      "Training speed: 4.8/s\n",
      "Loss: 0.6890\n",
      "\n",
      "Buffer size: 32365\n",
      "Buffer update speed: 1.6/s\n",
      "Number of environment steps: 3402468\n",
      "Average episode return: 39.7945\n",
      "Number of training steps: 18299\n",
      "Training speed: 5.7/s\n",
      "Loss: 0.6711\n",
      "\n",
      "Buffer size: 32296\n",
      "Buffer update speed: -5.7/s\n",
      "Number of environment steps: 3417597\n",
      "Average episode return: 38.6209\n",
      "Number of training steps: 18410\n",
      "Training speed: 11.1/s\n",
      "Loss: 0.6777\n",
      "\n",
      "Buffer size: 32356\n",
      "Buffer update speed: 5.3/s\n",
      "Number of environment steps: 3429141\n",
      "Average episode return: 38.3522\n",
      "Number of training steps: 18465\n",
      "Training speed: 5.5/s\n",
      "Loss: 0.7159\n",
      "\n",
      "Buffer size: 32313\n",
      "Buffer update speed: -5.3/s\n",
      "Number of environment steps: 3445272\n",
      "Average episode return: 38.4033\n",
      "Number of training steps: 18566\n",
      "Training speed: 10.1/s\n",
      "Loss: 0.7217\n",
      "\n",
      "Buffer size: 32454\n",
      "Buffer update speed: 16.8/s\n",
      "Number of environment steps: 3456826\n",
      "Average episode return: 41.8623\n",
      "Number of training steps: 18644\n",
      "Training speed: 7.8/s\n",
      "Loss: 0.6946\n",
      "\n",
      "Buffer size: 32322\n",
      "Buffer update speed: -8.2/s\n",
      "Number of environment steps: 3468540\n",
      "Average episode return: 40.5017\n",
      "Number of training steps: 18705\n",
      "Training speed: 6.1/s\n",
      "Loss: 0.6288\n",
      "\n",
      "Buffer size: 32373\n",
      "Buffer update speed: 1.4/s\n",
      "Number of environment steps: 3481062\n",
      "Average episode return: 41.1130\n",
      "Number of training steps: 18776\n",
      "Training speed: 7.1/s\n",
      "Loss: 0.6177\n",
      "\n",
      "Buffer size: 32106\n",
      "Buffer update speed: -24.5/s\n",
      "Number of environment steps: 3497799\n",
      "Average episode return: 39.1565\n",
      "Number of training steps: 18831\n",
      "Training speed: 5.5/s\n",
      "Loss: 0.6339\n",
      "\n",
      "Buffer size: 32027\n",
      "Buffer update speed: -10.1/s\n",
      "Number of environment steps: 3509473\n",
      "Average episode return: 38.4013\n",
      "Number of training steps: 18918\n",
      "Training speed: 8.7/s\n",
      "Loss: 0.6268\n",
      "\n",
      "Buffer size: 31940\n",
      "Buffer update speed: -10.9/s\n",
      "Number of environment steps: 3521693\n",
      "Average episode return: 40.2204\n",
      "Number of training steps: 18976\n",
      "Training speed: 5.8/s\n",
      "Loss: 0.6885\n",
      "\n",
      "Buffer size: 32302\n",
      "Buffer update speed: 36.2/s\n",
      "Number of environment steps: 3534187\n",
      "Average episode return: 41.9327\n",
      "Number of training steps: 19047\n",
      "Training speed: 7.1/s\n",
      "Loss: 0.6908\n",
      "\n",
      "Buffer size: 32297\n",
      "Buffer update speed: -6.1/s\n",
      "Number of environment steps: 3547993\n",
      "Average episode return: 38.9129\n",
      "Number of training steps: 19100\n",
      "Training speed: 5.5/s\n",
      "Loss: 0.6075\n",
      "\n",
      "Buffer size: 31824\n",
      "Buffer update speed: -50.4/s\n",
      "Number of environment steps: 3563017\n",
      "Average episode return: 36.6781\n",
      "Number of training steps: 19180\n",
      "Training speed: 7.8/s\n",
      "Loss: 0.6400\n",
      "\n",
      "Buffer size: 31748\n",
      "Buffer update speed: -3.5/s\n",
      "Number of environment steps: 3578521\n",
      "Average episode return: 39.9589\n",
      "Number of training steps: 19258\n",
      "Training speed: 7.8/s\n",
      "Loss: 0.6517\n",
      "\n",
      "Buffer size: 31468\n",
      "Buffer update speed: -28.2/s\n",
      "Number of environment steps: 3592343\n",
      "Average episode return: 40.5875\n",
      "Number of training steps: 19336\n",
      "Training speed: 7.8/s\n",
      "Loss: 0.6261\n",
      "\n",
      "Buffer size: 31295\n",
      "Buffer update speed: -17.1/s\n",
      "Number of environment steps: 3606246\n",
      "Average episode return: 39.8080\n",
      "Number of training steps: 19451\n",
      "Training speed: 11.5/s\n",
      "Loss: 0.6423\n",
      "\n",
      "Buffer size: 31653\n",
      "Buffer update speed: 39.8/s\n",
      "Number of environment steps: 3617496\n",
      "Average episode return: 35.1562\n",
      "Number of training steps: 19522\n",
      "Training speed: 7.1/s\n",
      "Loss: 0.6591\n",
      "\n",
      "Buffer size: 32434\n",
      "Buffer update speed: 76.6/s\n",
      "Number of environment steps: 3633916\n",
      "Average episode return: 35.6277\n",
      "Number of training steps: 19594\n",
      "Training speed: 7.2/s\n",
      "Loss: 0.6437\n",
      "\n",
      "Buffer size: 32183\n",
      "Buffer update speed: -27.4/s\n",
      "Number of environment steps: 3646587\n",
      "Average episode return: 32.5733\n",
      "Number of training steps: 19656\n",
      "Training speed: 6.2/s\n",
      "Loss: 0.6913\n",
      "\n",
      "Buffer size: 32197\n",
      "Buffer update speed: -3.9/s\n",
      "Number of environment steps: 3659639\n",
      "Average episode return: 38.8024\n",
      "Number of training steps: 19738\n",
      "Training speed: 8.2/s\n",
      "Loss: 0.7338\n",
      "\n",
      "Buffer size: 31769\n",
      "Buffer update speed: -38.3/s\n",
      "Number of environment steps: 3674902\n",
      "Average episode return: 35.4019\n",
      "Number of training steps: 19802\n",
      "Training speed: 6.4/s\n",
      "Loss: 0.6899\n",
      "\n",
      "Buffer size: 31458\n",
      "Buffer update speed: -36.4/s\n",
      "Number of environment steps: 3688262\n",
      "Average episode return: 32.6813\n",
      "Number of training steps: 19891\n",
      "Training speed: 8.9/s\n",
      "Loss: 0.6464\n",
      "\n",
      "Buffer size: 30814\n",
      "Buffer update speed: -62.5/s\n",
      "Number of environment steps: 3700408\n",
      "Average episode return: 35.4985\n",
      "Number of training steps: 19979\n",
      "Training speed: 8.8/s\n",
      "Loss: 0.7154\n",
      "\n",
      "Buffer size: 31158\n",
      "Buffer update speed: 34.4/s\n",
      "Number of environment steps: 3714888Average episode return: 41.6916\n",
      "\n",
      "Number of training steps: 20035\n",
      "Training speed: 5.6/s\n",
      "Loss: 0.7303\n",
      "\n",
      "Buffer size: 31635\n",
      "Buffer update speed: 52.4/s\n",
      "Number of environment steps: 3729016\n",
      "Average episode return: 41.1140\n",
      "Number of training steps: 20075\n",
      "Training speed: 4.0/s\n",
      "Loss: 0.6376\n",
      "\n",
      "Buffer size: 31868\n",
      "Buffer update speed: 23.7/s\n",
      "Number of environment steps: 3739169\n",
      "Average episode return: 38.3004\n",
      "Number of training steps: 20127\n",
      "Training speed: 5.2/s\n",
      "Loss: 0.5589\n",
      "\n",
      "Buffer size: 31714\n",
      "Buffer update speed: -19.5/s\n",
      "Number of environment steps: 3754972\n",
      "Average episode return: 38.4272\n",
      "Number of training steps: 20214\n",
      "Training speed: 8.7/s\n",
      "Loss: 0.6171\n",
      "\n",
      "Buffer size: 31190\n",
      "Buffer update speed: -49.7/s\n",
      "Number of environment steps: 3769396\n",
      "Average episode return: 36.6598\n",
      "Number of training steps: 20288\n",
      "Training speed: 7.4/s\n",
      "Loss: 0.6507\n",
      "\n",
      "Buffer size: 31098\n",
      "Buffer update speed: -5.8/s\n",
      "Number of environment steps: 3782250\n",
      "Average episode return: 36.5269\n",
      "Number of training steps: 20328\n",
      "Training speed: 4.0/s\n",
      "Loss: 0.6447\n",
      "\n",
      "Buffer size: 31302\n",
      "Buffer update speed: 18.2/s\n",
      "Number of environment steps: 3796020\n",
      "Average episode return: 40.0293\n",
      "Number of training steps: 20398\n",
      "Training speed: 7.0/s\n",
      "Loss: 0.6408\n",
      "\n",
      "Buffer size: 31834\n",
      "Buffer update speed: 51.7/s\n",
      "Number of environment steps: 3807109\n",
      "Average episode return: 39.1809\n",
      "Number of training steps: 20509\n",
      "Training speed: 11.0/s\n",
      "Loss: 0.6238\n",
      "\n",
      "Buffer size: 32530\n",
      "Buffer update speed: 74.4/s\n",
      "Number of environment steps: 3819119\n",
      "Average episode return: 34.4857\n",
      "Number of training steps: 20627\n",
      "Training speed: 11.8/s\n",
      "Loss: 0.6540\n",
      "\n",
      "Buffer size: 31977\n",
      "Buffer update speed: -60.1/s\n",
      "Number of environment steps: 3832453\n",
      "Average episode return: 30.8469\n",
      "Number of training steps: 20727\n",
      "Training speed: 10.0/s\n",
      "Loss: 0.7701\n",
      "\n",
      "Buffer size: 32278\n",
      "Buffer update speed: 29.6/s\n",
      "Number of environment steps: 3845628\n",
      "Average episode return: 34.9037\n",
      "Number of training steps: 20778\n",
      "Training speed: 5.1/s\n",
      "Loss: 0.8416\n",
      "\n",
      "Buffer size: 32332\n",
      "Buffer update speed: 5.2/s\n",
      "Number of environment steps: 3857737\n",
      "Average episode return: 37.3815\n",
      "Number of training steps: 20869\n",
      "Training speed: 9.1/s\n",
      "Loss: 0.8154\n",
      "\n",
      "Buffer size: 32226\n",
      "Buffer update speed: -16.1/s\n",
      "\n",
      "Number of environment steps: 3870923Average episode return: 39.6506\n",
      "Number of training steps: 20947\n",
      "Training speed: 7.8/s\n",
      "Loss: 0.7210\n",
      "\n",
      "Buffer size: 32212\n",
      "Buffer update speed: 1.8/s\n",
      "Number of environment steps: 3884074\n",
      "Average episode return: 32.9472\n",
      "Number of training steps: 21002\n",
      "Training speed: 5.5/s\n",
      "Loss: 0.6848\n",
      "\n",
      "Buffer size: 32467\n",
      "Buffer update speed: 28.5/s\n",
      "Number of environment steps: 3899010\n",
      "Average episode return: 33.9226\n",
      "Number of training steps: 21076\n",
      "Training speed: 7.4/s\n",
      "Loss: 0.7225\n",
      "\n",
      "Buffer size: 32243\n",
      "Buffer update speed: -29.0/s\n",
      "Number of environment steps: 3913648\n",
      "Average episode return: 37.8805\n",
      "Number of training steps: 21146\n",
      "Training speed: 7.0/s\n",
      "Loss: 0.7893\n",
      "\n",
      "Buffer size: 31796\n",
      "Buffer update speed: -48.1/s\n",
      "Number of environment steps: 3932993\n",
      "Average episode return: 38.4052\n",
      "Number of training steps: 21210\n",
      "Training speed: 6.4/s\n",
      "Loss: 0.6511\n",
      "\n",
      "Buffer size: 32423\n",
      "Buffer update speed: 62.1/s\n",
      "Number of environment steps: 3945471\n",
      "Average episode return: 38.0399\n",
      "Number of training steps: 21285\n",
      "Training speed: 7.5/s\n",
      "Loss: 0.6993\n",
      "\n",
      "Buffer size: 33164\n",
      "Buffer update speed: 78.8/s\n",
      "Number of environment steps: 3957184\n",
      "Average episode return: 36.5077\n",
      "Number of training steps: 21388\n",
      "Training speed: 10.3/s\n",
      "Loss: 0.7687\n",
      "\n",
      "Buffer size: 33605Buffer update speed: 42.9/s\n",
      "\n",
      "Number of environment steps: 3969510\n",
      "Average episode return: 37.3384\n",
      "Number of training steps: 21473\n",
      "Training speed: 8.5/s\n",
      "Loss: 0.7699\n",
      "\n",
      "Buffer size: 34144\n",
      "Buffer update speed: 56.9/s\n",
      "Number of environment steps: 3981073\n",
      "Average episode return: 43.9802\n",
      "Number of training steps: 21562\n",
      "Training speed: 8.9/s\n",
      "Loss: 0.7638\n",
      "\n",
      "Buffer size: 35574\n",
      "Buffer update speed: 143.0/s\n",
      "Number of environment steps: 3991828\n",
      "Average episode return: 64.9074\n",
      "Number of training steps: 21632\n",
      "Training speed: 7.0/s\n",
      "Loss: 0.7657\n",
      "\n",
      "Buffer size: 36646\n",
      "Buffer update speed: 109.3/s\n",
      "Number of environment steps: 4002472\n",
      "Average episode return: 61.4186\n",
      "Number of training steps: 21697\n",
      "Training speed: 6.5/s\n",
      "Loss: 0.7366\n",
      "\n",
      "Buffer size: 36759\n",
      "Buffer update speed: 10.2/s\n",
      "Number of environment steps: 4016011\n",
      "Average episode return: 47.2305\n",
      "Number of training steps: 21760\n",
      "Training speed: 6.3/s\n",
      "Loss: 0.7018\n",
      "\n",
      "Buffer size: 34560\n",
      "Buffer update speed: -223.3/s\n",
      "Number of environment steps: 4028864\n",
      "Average episode return: 42.4040\n",
      "Number of training steps: 21845\n",
      "Training speed: 8.5/s\n",
      "Loss: 0.7079\n",
      "\n",
      "Buffer size: 33025\n",
      "Buffer update speed: -148.3/s\n",
      "Number of environment steps: 4045264\n",
      "Average episode return: 40.1966\n",
      "Number of training steps: 21903\n",
      "Training speed: 5.8/s\n",
      "Loss: 0.6934\n",
      "\n",
      "Buffer size: 32600\n",
      "Buffer update speed: -42.5/s\n",
      "Number of environment steps: 4060360\n",
      "Average episode return: 45.1337\n",
      "Number of training steps: 21989\n",
      "Training speed: 8.6/s\n",
      "Loss: 0.7221\n",
      "\n",
      "Buffer size: 32919\n",
      "Buffer update speed: 31.9/s\n",
      "Number of environment steps: 4071290\n",
      "Average episode return: 45.1833\n",
      "Number of training steps: 22054\n",
      "Training speed: 6.4/s\n",
      "Loss: 0.6592\n",
      "\n",
      "Buffer size: 32884\n",
      "Buffer update speed: -3.5/s\n",
      "Number of environment steps: 4086069\n",
      "Average episode return: 38.5958\n",
      "Number of training steps: 22125\n",
      "Training speed: 7.0/s\n",
      "Loss: 0.6784\n",
      "\n",
      "Buffer size: 32488\n",
      "Buffer update speed: -37.4/s\n",
      "Number of environment steps: 4099527\n",
      "Average episode return: 39.2878\n",
      "Number of training steps: 22202\n",
      "Training speed: 7.7/s\n",
      "Loss: 0.6889\n",
      "\n",
      "Buffer size: 32668\n",
      "Buffer update speed: 16.9/s\n",
      "Number of environment steps: 4112534\n",
      "Average episode return: 43.6143\n",
      "Number of training steps: 22292\n",
      "Training speed: 9.0/s\n",
      "Loss: 0.7486\n",
      "\n",
      "Buffer size: 32697\n",
      "Buffer update speed: 2.8/s\n",
      "Number of environment steps: 4127526\n",
      "Average episode return: 40.9210\n",
      "Number of training steps: 22354\n",
      "Training speed: 6.2/s\n",
      "Loss: 0.6842\n",
      "\n",
      "Buffer size: 32412\n",
      "Buffer update speed: -27.5/s\n",
      "Number of environment steps: 4142538\n",
      "\n",
      "Average episode return: 40.4636Number of training steps: 22468\n",
      "Training speed: 11.4/s\n",
      "Loss: 0.6471\n",
      "\n",
      "Buffer size: 32500\n",
      "Buffer update speed: 5.6/s\n",
      "Number of environment steps: 4154832\n",
      "Average episode return: 40.8467\n",
      "Number of training steps: 22523\n",
      "Training speed: 5.5/s\n",
      "Loss: 0.6584\n",
      "\n",
      "Buffer size: 32410\n",
      "Buffer update speed: -10.0/s\n",
      "Number of environment steps: 4165833\n",
      "Average episode return: 41.3258\n",
      "Number of training steps: 22612\n",
      "Training speed: 8.9/s\n",
      "Loss: 0.6915\n",
      "\n",
      "Buffer size: 32401\n",
      "Buffer update speed: 3.3/s\n",
      "Number of environment steps: 4180101\n",
      "Average episode return: 36.9716\n",
      "Number of training steps: 22722\n",
      "Training speed: 11.0/s\n",
      "Loss: 0.7159\n",
      "\n",
      "Buffer size: 32529\n",
      "Buffer update speed: 10.7/s\n",
      "Number of environment steps: 4196684\n",
      "Average episode return: 41.0496\n",
      "Number of training steps: 22806\n",
      "Training speed: 8.4/s\n",
      "Loss: 0.7596\n",
      "\n",
      "Buffer size: 32484\n",
      "Buffer update speed: -2.4/s\n",
      "Number of environment steps: 4212924\n",
      "Average episode return: 39.2233\n",
      "Number of training steps: 22913\n",
      "Training speed: 10.7/s\n",
      "Loss: 0.7316\n",
      "\n",
      "Buffer size: 32923\n",
      "Buffer update speed: 43.7/s\n",
      "Number of environment steps: 4226765\n",
      "Average episode return: 41.1935\n",
      "Number of training steps: 22986\n",
      "Training speed: 7.3/s\n",
      "Loss: 0.7206\n",
      "\n",
      "Buffer size: 33141\n",
      "Buffer update speed: 21.8/s\n",
      "Number of environment steps: 4239726\n",
      "Average episode return: 39.0420\n",
      "Number of training steps: 23091\n",
      "Training speed: 10.5/s\n",
      "Loss: 0.7109\n",
      "\n",
      "Buffer size: 32974\n",
      "Buffer update speed: -16.7/s\n",
      "Number of environment steps: 4251218\n",
      "Average episode return: 39.9132\n",
      "Number of training steps: 23170\n",
      "Training speed: 7.8/s\n",
      "Loss: 0.7458\n",
      "\n",
      "Buffer size: 33034\n",
      "Buffer update speed: 7.8/s\n",
      "Number of environment steps: 4263483\n",
      "Average episode return: 41.4257\n",
      "Number of training steps: 23238\n",
      "Training speed: 6.7/s\n",
      "Loss: 0.6887\n",
      "\n",
      "Buffer size: 33179\n",
      "Buffer update speed: 13.6/s\n",
      "Number of environment steps: 4278742\n",
      "Average episode return: 44.4360\n",
      "Number of training steps: 23308\n",
      "Training speed: 7.0/s\n",
      "Loss: 0.7074\n",
      "\n",
      "Buffer size: 33045\n",
      "Buffer update speed: -8.0/s\n",
      "Number of environment steps: 4292236\n",
      "Average episode return: 38.5690\n",
      "Number of training steps: 23373\n",
      "Training speed: 6.5/s\n",
      "Loss: 0.6588\n",
      "\n",
      "Buffer size: 32959\n",
      "Buffer update speed: -12.3/s\n",
      "Number of environment steps: 4304895\n",
      "Average episode return: 39.1920\n",
      "Number of training steps: 23445\n",
      "Training speed: 7.2/s\n",
      "Loss: 0.6998\n",
      "\n",
      "Buffer size: 33060\n",
      "Buffer update speed: 13.8/s\n",
      "Number of environment steps: 4317510\n",
      "Average episode return: 42.6361\n",
      "Number of training steps: 23492\n",
      "Training speed: 4.7/s\n",
      "Loss: 0.7057\n",
      "\n",
      "Buffer size: 33525\n",
      "Buffer update speed: 48.3/s\n",
      "Number of environment steps: 4327078\n",
      "Average episode return: 46.7059\n",
      "Number of training steps: 23542\n",
      "Training speed: 4.7/s\n",
      "Loss: 0.7312\n",
      "\n",
      "Buffer size: 34321\n",
      "Buffer update speed: 76.9/s\n",
      "Number of environment steps: 4339547\n",
      "Average episode return: 49.7935\n",
      "Number of training steps: 23607\n",
      "Training speed: 6.5/s\n",
      "Loss: 0.6713\n",
      "\n",
      "Buffer size: 34024\n",
      "Buffer update speed: -24.3/s\n",
      "Number of environment steps: 4352274\n",
      "Average episode return: 41.2984\n",
      "Number of training steps: 23695\n",
      "Training speed: 8.8/s\n",
      "Loss: 0.6614\n",
      "\n",
      "Buffer size: 32849\n",
      "Buffer update speed: -123.3/s\n",
      "Number of environment steps: 4365743\n",
      "Average episode return: 40.3242\n",
      "Number of training steps: 23770\n",
      "Training speed: 7.5/s\n",
      "Loss: 0.7179\n",
      "\n",
      "Buffer size: 32861\n",
      "Buffer update speed: 8.2/s\n",
      "Number of environment steps: 4379262\n",
      "Average episode return: 46.1076\n",
      "Number of training steps: 23833\n",
      "Training speed: 6.3/s\n",
      "Loss: 0.6804\n",
      "\n",
      "Buffer size: 33655\n",
      "Buffer update speed: 77.3/s\n",
      "Number of environment steps: 4392440\n",
      "Average episode return: 47.8339\n",
      "Number of training steps: 23916\n",
      "Training speed: 8.3/s\n",
      "\n",
      "Loss: 0.6320\n",
      "Buffer size: 33803\n",
      "Buffer update speed: 16.3/s\n",
      "Number of environment steps: 4405004\n",
      "Average episode return: 41.2237\n",
      "Number of training steps: 24003\n",
      "Training speed: 8.7/s\n",
      "Loss: 0.6352\n",
      "\n",
      "Buffer size: 33366\n",
      "Buffer update speed: -42.0/s\n",
      "Number of environment steps: 4419062\n",
      "Average episode return: 37.5914\n",
      "Number of training steps: 24046\n",
      "Training speed: 4.3/s\n",
      "Loss: 0.6655\n",
      "\n",
      "Buffer size: 32934\n",
      "Buffer update speed: -46.3/s\n",
      "Number of environment steps: 4432957\n",
      "Average episode return: 39.9284\n",
      "Number of training steps: 24125\n",
      "Training speed: 7.9/s\n",
      "Loss: 0.7239\n",
      "\n",
      "Buffer size: 32820\n",
      "Buffer update speed: -19.1/s\n",
      "Number of environment steps: 4446521\n",
      "Average episode return: 40.9698\n",
      "Number of training steps: 24212\n",
      "Training speed: 8.7/s\n",
      "Loss: 0.7335\n",
      "\n",
      "Buffer size: 32482\n",
      "Buffer update speed: -28.2/s\n",
      "Number of environment steps: 4458959\n",
      "Average episode return: 41.4600\n",
      "Number of training steps: 24263\n",
      "Training speed: 5.1/s\n",
      "Loss: 0.6849\n",
      "\n",
      "Buffer size: 32730\n",
      "Buffer update speed: 25.9/s\n",
      "Number of environment steps: 4471161\n",
      "Average episode return: 42.5245\n",
      "Number of training steps: 24347\n",
      "Training speed: 8.3/s\n",
      "Loss: 0.6839\n",
      "\n",
      "Buffer size: 32386\n",
      "Buffer update speed: -30.4/s\n",
      "Number of environment steps: 4484985\n",
      "Average episode return: 39.0508\n",
      "Number of training steps: 24413\n",
      "Training speed: 6.6/s\n",
      "Loss: 0.6870\n",
      "\n",
      "Buffer size: 32272\n",
      "Buffer update speed: -11.4/s\n",
      "Number of environment steps: 4500779\n",
      "Average episode return: 39.2832\n",
      "Number of training steps: 24490\n",
      "Training speed: 7.7/s\n",
      "Loss: 0.6803\n",
      "\n",
      "Buffer size: 32867\n",
      "Buffer update speed: 59.5/s\n",
      "Number of environment steps: 4514835\n",
      "Average episode return: 43.3051\n",
      "Number of training steps: 24575\n",
      "Training speed: 8.5/s\n",
      "Loss: 0.7052\n",
      "\n",
      "Buffer size: 32820\n",
      "Buffer update speed: -3.5/s\n",
      "Number of environment steps: 4533413\n",
      "Average episode return: 41.2664\n",
      "Number of training steps: 24647\n",
      "Training speed: 7.1/s\n",
      "Loss: 0.6876\n",
      "\n",
      "Buffer size: 32583\n",
      "Buffer update speed: -23.7/s\n",
      "Number of environment steps: 4546000\n",
      "Average episode return: 41.4092\n",
      "Number of training steps: 24721\n",
      "Training speed: 7.4/s\n",
      "Loss: 0.6318\n",
      "\n",
      "Buffer size: 32756\n",
      "Buffer update speed: 21.0/s\n",
      "Number of environment steps: 4559202\n",
      "Average episode return: 39.2328\n",
      "Number of training steps: 24776\n",
      "Training speed: 5.3/s\n",
      "Loss: 0.6607\n",
      "\n",
      "Buffer size: 33102\n",
      "Buffer update speed: 34.6/s\n",
      "Number of environment steps: 4571529\n",
      "Average episode return: 40.1536\n",
      "Number of training steps: 24838\n",
      "Training speed: 6.2/s\n",
      "Loss: 0.6751\n",
      "\n",
      "Buffer size: 33058\n",
      "Buffer update speed: -4.4/s\n",
      "Number of environment steps: 4582158\n",
      "Average episode return: 41.0736\n",
      "Number of training steps: 24919\n",
      "Training speed: 8.2/s\n",
      "Loss: 0.7157\n",
      "\n",
      "Buffer size: 32629\n",
      "Buffer update speed: -42.9/s\n",
      "Number of environment steps: 4597896\n",
      "Average episode return: 39.0347\n",
      "Number of training steps: 25021\n",
      "Training speed: 10.1/s\n",
      "Loss: 0.6998\n",
      "\n",
      "Buffer size: 32717\n",
      "Buffer update speed: 8.8/s\n",
      "Number of environment steps: 4613376\n",
      "Average episode return: 38.7855Number of training steps: 25077\n",
      "\n",
      "Training speed: 5.6/s\n",
      "Loss: 0.7168\n",
      "\n",
      "Buffer size: 33245\n",
      "Buffer update speed: 54.9/s\n",
      "Number of environment steps: 4625138\n",
      "Average episode return: 39.2274\n",
      "Number of training steps: 25128\n",
      "Training speed: 5.1/s\n",
      "Loss: 0.7068\n",
      "\n",
      "Buffer size: 33419\n",
      "Buffer update speed: 15.3/s\n",
      "Number of environment steps: 4639756\n",
      "Average episode return: 39.6081\n",
      "Number of training steps: 25180\n",
      "Training speed: 5.4/s\n",
      "Loss: 0.6701\n",
      "\n",
      "Buffer size: 33071\n",
      "Buffer update speed: -32.3/s\n",
      "Number of environment steps: 4654250\n",
      "Average episode return: 39.0707\n",
      "Number of training steps: 25304\n",
      "Training speed: 12.2/s\n",
      "Loss: 0.7166\n",
      "\n",
      "Buffer size: 33262\n",
      "Buffer update speed: 18.2/s\n",
      "Number of environment steps: 4665941\n",
      "Average episode return: 41.6107\n",
      "Number of training steps: 25361\n",
      "Training speed: 5.7/s\n",
      "Loss: 0.6776\n",
      "\n",
      "Buffer size: 33334\n",
      "Buffer update speed: 9.0/s\n",
      "Number of environment steps: 4678837\n",
      "Average episode return: 40.0494\n",
      "Number of training steps: 25436\n",
      "Training speed: 7.5/s\n",
      "Loss: 0.7014\n",
      "\n",
      "Buffer size: 33200\n",
      "Buffer update speed: -8.5/s\n",
      "Number of environment steps: 4691198\n",
      "Average episode return: 37.4576\n",
      "Number of training steps: 25522\n",
      "Training speed: 8.5/s\n",
      "Loss: 0.7382\n",
      "\n",
      "Buffer size: 33274\n",
      "Buffer update speed: 5.8/s\n",
      "Number of environment steps: 4703623\n",
      "Average episode return: 38.2198\n",
      "Number of training steps: 25583\n",
      "Training speed: 6.3/s\n",
      "Loss: 0.7352\n",
      "\n",
      "Buffer size: 33387\n",
      "Buffer update speed: 14.3/s\n",
      "Number of environment steps: 4716039\n",
      "Average episode return: 42.5205\n",
      "Number of training steps: 25656\n",
      "Training speed: 7.1/s\n",
      "Loss: 0.7284\n",
      "\n",
      "Buffer size: 33729\n",
      "Buffer update speed: 31.9/s\n",
      "Number of environment steps: 4727890\n",
      "Average episode return: 41.1493\n",
      "Number of training steps: 25727\n",
      "Training speed: 7.1/s\n",
      "Loss: 0.7607\n",
      "\n",
      "Buffer size: 33922\n",
      "Buffer update speed: 20.3/s\n",
      "Number of environment steps: 4742554\n",
      "Average episode return: 40.7396\n",
      "Number of training steps: 25797\n",
      "Training speed: 6.9/s\n",
      "Loss: 0.7339\n",
      "\n",
      "Buffer size: 33925\n",
      "Buffer update speed: -3.6/s\n",
      "Number of environment steps: 4754918\n",
      "Average episode return: 43.7199\n",
      "Number of training steps: 25894\n",
      "Training speed: 9.7/s\n",
      "Loss: 0.7389\n",
      "\n",
      "Buffer size: 34212\n",
      "Buffer update speed: 28.3/s\n",
      "Number of environment steps: 4764664\n",
      "Average episode return: 47.2404\n",
      "Number of training steps: 25935\n",
      "Training speed: 4.2/s\n",
      "Loss: 0.7584\n",
      "\n",
      "Buffer size: 34562\n",
      "Buffer update speed: 32.9/s\n",
      "Number of environment steps: 4774591\n",
      "Average episode return: 47.0571\n",
      "Number of training steps: 26007\n",
      "Training speed: 7.1/s\n",
      "Loss: 0.6869\n",
      "\n",
      "Buffer size: 34427\n",
      "Buffer update speed: -13.5/s\n",
      "Number of environment steps: 4785992\n",
      "Average episode return: 45.7430\n",
      "Number of training steps: 26075\n",
      "Training speed: 6.8/s\n",
      "Loss: 0.7184\n",
      "\n",
      "Buffer size: 34215\n",
      "Buffer update speed: -21.0/s\n",
      "Number of environment steps: 4797566\n",
      "Average episode return: 43.0861\n",
      "Number of training steps: 26145\n",
      "Training speed: 7.0/s\n",
      "Loss: 0.6721\n",
      "\n",
      "Buffer size: 33673\n",
      "Buffer update speed: -53.3/s\n",
      "Number of environment steps: 4812127\n",
      "Average episode return: 41.8526\n",
      "Number of training steps: 26224\n",
      "Training speed: 7.9/s\n",
      "Loss: 0.6575\n",
      "\n",
      "Buffer size: 33744\n",
      "Buffer update speed: 3.7/s\n",
      "Number of environment steps: 4825984\n",
      "Average episode return: 46.7755\n",
      "Number of training steps: 26320\n",
      "Training speed: 9.6/s\n",
      "Loss: 0.6998\n",
      "\n",
      "Buffer size: 33992\n",
      "Buffer update speed: 24.8/s\n",
      "Number of environment steps: 4840357\n",
      "Average episode return: 47.2433\n",
      "Number of training steps: 26385\n",
      "Training speed: 6.5/s\n",
      "Loss: 0.7321\n",
      "\n",
      "Buffer size: 33943\n",
      "Buffer update speed: -4.9/s\n",
      "Number of environment steps: 4852987\n",
      "Average episode return: 42.2333\n",
      "Number of training steps: 26436\n",
      "Training speed: 5.1/s\n",
      "Loss: 0.6753\n",
      "\n",
      "Buffer size: 33755\n",
      "Buffer update speed: -11.4/s\n",
      "Number of environment steps: 4868998\n",
      "Average episode return: 40.5369\n",
      "Number of training steps: 26520\n",
      "Training speed: 8.4/s\n",
      "Loss: 0.7368\n",
      "\n",
      "Buffer size: 33758\n",
      "Buffer update speed: -3.2/s\n",
      "Number of environment steps: 4882938\n",
      "Average episode return: 45.2589\n",
      "Number of training steps: 26607\n",
      "Training speed: 8.7/s\n",
      "Loss: 0.7159\n",
      "\n",
      "Buffer size: 33634\n",
      "Buffer update speed: -17.5/s\n",
      "Number of environment steps: 4896997\n",
      "Average episode return: 42.3606\n",
      "Number of training steps: 26723\n",
      "Training speed: 11.6/s\n",
      "Loss: 0.7627\n",
      "\n",
      "Buffer size: 33400\n",
      "Buffer update speed: -21.6/s\n",
      "Number of environment steps: 4909285\n",
      "Average episode return: 41.2007\n",
      "Number of training steps: 26791\n",
      "Training speed: 6.8/s\n",
      "Loss: 0.6971\n",
      "\n",
      "Buffer size: 32902\n",
      "Buffer update speed: -47.1/s\n",
      "Number of environment steps: 4922174\n",
      "Average episode return: 42.3113\n",
      "Number of training steps: 26908\n",
      "Training speed: 11.7/s\n",
      "Loss: 0.7265\n",
      "\n",
      "Buffer size: 33157\n",
      "Buffer update speed: 29.6/s\n",
      "Number of environment steps: 4935700\n",
      "Average episode return: 44.6403\n",
      "Number of training steps: 26978\n",
      "Training speed: 7.1/s\n",
      "Loss: 0.7165\n",
      "\n",
      "Buffer size: 33220\n",
      "Buffer update speed: 6.6/s\n",
      "Average episode return: 43.4152Number of environment steps: 4947729\n",
      "\n",
      "Number of training steps: 27049\n",
      "Training speed: 7.0/s\n",
      "Loss: 0.6394\n",
      "\n",
      "Buffer size: 33622\n",
      "Buffer update speed: 38.4/s\n",
      "Number of environment steps: 4960823\n",
      "Average episode return: 39.8628\n",
      "Number of training steps: 27115\n",
      "Training speed: 6.5/s\n",
      "Loss: 0.6667\n",
      "\n",
      "Buffer size: 33796\n",
      "Buffer update speed: 20.1/s\n",
      "Number of environment steps: 4975376\n",
      "Average episode return: 39.7073\n",
      "Number of training steps: 27182\n",
      "Training speed: 6.7/s\n",
      "Loss: 0.6563\n",
      "\n",
      "Buffer size: 33834\n",
      "Buffer update speed: 4.9/s\n",
      "Number of environment steps: 4992339\n",
      "Average episode return: 38.6437\n",
      "Number of training steps: 27236\n",
      "Training speed: 5.4/s\n",
      "Loss: 0.6669\n",
      "\n",
      "Buffer size: 33890\n",
      "Buffer update speed: 5.7/s\n",
      "Number of environment steps: 5003174\n",
      "Average episode return: 40.3985\n",
      "Number of training steps: 27334\n",
      "Training speed: 9.8/s\n",
      "Loss: 0.7022\n",
      "\n",
      "Buffer size: 33521\n",
      "\n",
      "Buffer update speed: -38.1/sNumber of environment steps: 5015534\n",
      "Average episode return: 41.2424\n",
      "Number of training steps: 27389\n",
      "Training speed: 5.3/s\n",
      "Loss: 0.6980\n",
      "\n",
      "Buffer size: 33488\n",
      "Buffer update speed: -3.3/s\n",
      "Number of environment steps: 5029930\n",
      "Average episode return: 41.0597\n",
      "Number of training steps: 27450\n",
      "Training speed: 6.1/s\n",
      "Loss: 0.6852\n",
      "\n",
      "Buffer size: 33510\n",
      "Buffer update speed: 12.2/s\n",
      "Number of environment steps: 5047587\n",
      "Average episode return: 40.0706\n",
      "Number of training steps: 27564\n",
      "Training speed: 11.4/s\n",
      "Loss: 0.7275\n",
      "\n",
      "Buffer size: 33460\n",
      "Buffer update speed: -10.3/s\n",
      "Number of environment steps: 5062378\n",
      "Average episode return: 42.6110\n",
      "Number of training steps: 27668\n",
      "Training speed: 10.4/s\n",
      "Loss: 0.7033\n",
      "\n",
      "Buffer size: 33798\n",
      "Buffer update speed: 31.3/s\n",
      "Number of environment steps: 5074485\n",
      "Average episode return: 46.0189\n",
      "Number of training steps: 27746\n",
      "Training speed: 7.9/s\n",
      "Loss: 0.7157\n",
      "\n",
      "Buffer size: 33879\n",
      "Buffer update speed: 7.3/s\n",
      "Number of environment steps: 5087854\n",
      "Average episode return: 44.3043\n",
      "Number of training steps: 27804\n",
      "Training speed: 5.7/s\n",
      "Loss: 0.6610\n",
      "\n",
      "Buffer size: 33857\n",
      "Buffer update speed: -2.2/s\n",
      "Number of environment steps: 5100094\n",
      "Average episode return: 41.4276\n",
      "Number of training steps: 27875\n",
      "Training speed: 6.9/s\n",
      "Loss: 0.6699\n",
      "\n",
      "Buffer size: 33509\n",
      "Buffer update speed: -34.8/s\n",
      "Number of environment steps: 5114789\n",
      "Average episode return: 46.1041\n",
      "Number of training steps: 27957\n",
      "Training speed: 8.0/s\n",
      "Loss: 0.6315\n",
      "\n",
      "Buffer size: 33957\n",
      "Buffer update speed: 44.3/s\n",
      "Number of environment steps: 5128782\n",
      "Average episode return: 46.7113\n",
      "Number of training steps: 28067\n",
      "Training speed: 11.0/s\n",
      "Loss: 0.6756\n",
      "\n",
      "Buffer size: 33639\n",
      "Buffer update speed: -35.2/s\n",
      "Number of environment steps: 5143995\n",
      "Average episode return: 40.8070\n",
      "Number of training steps: 28159\n",
      "Training speed: 9.2/s\n",
      "Loss: 0.6960\n",
      "\n",
      "Buffer size: 33444\n",
      "Buffer update speed: -16.6/s\n",
      "Number of environment steps: 5154814\n",
      "Average episode return: 41.2433\n",
      "Number of training steps: 28205\n",
      "Training speed: 4.6/s\n",
      "Loss: 0.6646\n",
      "\n",
      "Buffer size: 33290\n",
      "Buffer update speed: -12.9/s\n",
      "Number of environment steps: 5167249\n",
      "Average episode return: 41.8953\n",
      "Number of training steps: 28295\n",
      "Training speed: 9.0/s\n",
      "Loss: 0.6894\n",
      "\n",
      "Buffer size: 33236\n",
      "Buffer update speed: -7.4/s\n",
      "Number of environment steps: 5183744\n",
      "Average episode return: 41.4668\n",
      "Number of training steps: 28384\n",
      "Training speed: 8.8/s\n",
      "Loss: 0.6937\n",
      "\n",
      "Buffer size: 32983\n",
      "Buffer update speed: -26.1/s\n",
      "Number of environment steps: 5194804\n",
      "Average episode return: 39.5643\n",
      "Number of training steps: 28456\n",
      "Training speed: 7.1/s\n",
      "Loss: 0.6366\n",
      "\n",
      "Buffer size: 32949\n",
      "Buffer update speed: -0.9/s\n",
      "Number of environment steps: 5209763\n",
      "Average episode return: 41.8045\n",
      "Number of training steps: 28525\n",
      "Training speed: 6.9/s\n",
      "Loss: 0.6570\n",
      "\n",
      "Buffer size: 33073\n",
      "Buffer update speed: 7.7/s\n",
      "Number of environment steps: 5221904\n",
      "Average episode return: 41.6207\n",
      "Number of training steps: 28572\n",
      "Training speed: 4.7/s\n",
      "Loss: 0.6566\n",
      "\n",
      "Buffer size: 33261\n",
      "Buffer update speed: 19.4/s\n",
      "Number of environment steps: 5236105\n",
      "Average episode return: 44.4406\n",
      "Number of training steps: 28668\n",
      "Training speed: 9.6/s\n",
      "Loss: 0.6384\n",
      "\n",
      "Buffer size: 33189\n",
      "Buffer update speed: -8.3/s\n",
      "Number of environment steps: 5247807\n",
      "Average episode return: 43.6302\n",
      "Number of training steps: 28721\n",
      "Training speed: 5.3/s\n",
      "Loss: 0.6057\n",
      "\n",
      "Buffer size: 32844\n",
      "Buffer update speed: -37.2/s\n",
      "Number of environment steps: 5263863\n",
      "Average episode return: 42.6807\n",
      "Number of training steps: 28813\n",
      "Training speed: 9.2/s\n",
      "Loss: 0.6142\n",
      "\n",
      "Buffer size: 32911\n",
      "Buffer update speed: 10.2/s\n",
      "Number of environment steps: 5280940\n",
      "Average episode return: 41.5990\n",
      "Number of training steps: 28891\n",
      "Training speed: 7.8/s\n",
      "Loss: 0.6197\n",
      "\n",
      "Buffer size: 33082\n",
      "Buffer update speed: 16.3/s\n",
      "Number of environment steps: 5294891\n",
      "Average episode return: 42.9877\n",
      "Number of training steps: 28964\n",
      "Training speed: 7.3/s\n",
      "Loss: 0.6713\n",
      "\n",
      "Buffer size: 33089\n",
      "Buffer update speed: -2.9/s\n",
      "Number of environment steps: 5307369\n",
      "Average episode return: 43.0172\n",
      "Number of training steps: 29013\n",
      "Training speed: 4.9/s\n",
      "Loss: 0.6670\n",
      "\n",
      "Buffer size: 32773\n",
      "Buffer update speed: -28.0/s\n",
      "Number of environment steps: 5318640\n",
      "Average episode return: 39.1324\n",
      "Number of training steps: 29075\n",
      "Training speed: 6.3/s\n",
      "Loss: 0.6247\n",
      "\n",
      "Buffer size: 32824\n",
      "Buffer update speed: 5.2/s\n",
      "Number of environment steps: 5331449\n",
      "Average episode return: 40.2812\n",
      "Number of training steps: 29118\n",
      "Training speed: 4.2/s\n",
      "Loss: 0.6638\n",
      "\n",
      "Buffer size: 33027\n",
      "Buffer update speed: 20.6/s\n",
      "Number of environment steps: 5342293\n",
      "Average episode return: 40.3609\n",
      "Number of training steps: 29180\n",
      "Training speed: 6.2/s\n",
      "Loss: 0.6679\n",
      "\n",
      "Buffer size: 33098\n",
      "Buffer update speed: 3.5/s\n",
      "Number of environment steps: 5354270\n",
      "Average episode return: 41.8403\n",
      "Number of training steps: 29289\n",
      "Training speed: 10.9/s\n",
      "Loss: 0.6920\n",
      "\n",
      "Buffer size: 32730\n",
      "Buffer update speed: -33.2/s\n",
      "Number of environment steps: 5368051\n",
      "Average episode return: 39.7420\n",
      "Number of training steps: 29360\n",
      "Training speed: 7.1/s\n",
      "Loss: 0.6922\n",
      "\n",
      "Buffer size: 32447\n",
      "Buffer update speed: -26.8/s\n",
      "Number of environment steps: 5380492\n",
      "Average episode return: 40.6471\n",
      "Number of training steps: 29437\n",
      "Training speed: 7.7/s\n",
      "Loss: 0.7069\n",
      "\n",
      "Buffer size: 32734\n",
      "Buffer update speed: 27.1/s\n",
      "Number of environment steps: 5395191\n",
      "Average episode return: 42.9883\n",
      "Number of training steps: 29518\n",
      "Training speed: 8.1/s\n",
      "Loss: 0.6689\n",
      "\n",
      "Buffer size: 32988\n",
      "Buffer update speed: 22.3/s\n",
      "Number of environment steps: 5408268\n",
      "Average episode return: 41.5191\n",
      "Number of training steps: 29565\n",
      "Training speed: 4.7/s\n",
      "Loss: 0.6562\n",
      "\n",
      "Buffer size: 32942\n",
      "Buffer update speed: -11.6/sNumber of environment steps: 5419531\n",
      "\n",
      "Average episode return: 40.2234\n",
      "Number of training steps: 29615\n",
      "Training speed: 5.0/s\n",
      "\n",
      "Loss: 0.6481\n",
      "Buffer size: 32896\n",
      "Buffer update speed: 4.7/s\n",
      "Number of environment steps: 5433857\n",
      "Average episode return: 42.1971\n",
      "Number of training steps: 29659\n",
      "Training speed: 4.5/s\n",
      "Loss: 0.5966\n",
      "\n",
      "Buffer size: 32637\n",
      "Buffer update speed: -26.3/s\n",
      "Number of environment steps: 5448312\n",
      "Average episode return: 41.5965\n",
      "Number of training steps: 29704\n",
      "Training speed: 4.4/s\n",
      "Loss: 0.5758\n",
      "\n",
      "Buffer size: 32464\n",
      "Buffer update speed: -17.9/s\n",
      "Number of environment steps: 5461167\n",
      "Average episode return: 42.9060\n",
      "Number of training steps: 29759\n",
      "Training speed: 5.5/s\n",
      "Loss: 0.5764\n",
      "\n",
      "Buffer size: 32807\n",
      "Buffer update speed: 33.5/s\n",
      "Number of environment steps: 5476493\n",
      "Average episode return: 40.9705\n",
      "Number of training steps: 29830\n",
      "Training speed: 7.1/s\n",
      "Loss: 0.5803\n",
      "\n",
      "Buffer size: 32857\n",
      "Buffer update speed: 1.1/s\n",
      "Number of environment steps: 5490679\n",
      "Average episode return: 39.8343\n",
      "Number of training steps: 29901\n",
      "Training speed: 7.1/s\n",
      "Loss: 0.5951\n",
      "\n",
      "Buffer size: 32803\n",
      "Buffer update speed: -6.3/s\n",
      "Number of environment steps: 5506100\n",
      "Average episode return: 40.2598\n",
      "Number of training steps: 29963\n",
      "Training speed: 6.2/s\n",
      "Loss: 0.6753\n",
      "\n",
      "Buffer size: 33093\n",
      "Buffer update speed: 32.4/s\n",
      "Number of environment steps: 5519327\n",
      "Average episode return: 41.0683\n",
      "Number of training steps: 30049\n",
      "Training speed: 8.6/s\n",
      "Loss: 0.6709\n",
      "\n",
      "Buffer size: 33045\n",
      "Buffer update speed: -0.1/s\n",
      "Number of environment steps: 5532504\n",
      "Average episode return: 40.9252\n",
      "\n",
      "Number of training steps: 30116\n",
      "Training speed: 6.7/s\n",
      "Loss: 0.6836\n",
      "Buffer size: 33361\n",
      "Buffer update speed: 28.0/s\n",
      "Number of environment steps: 5544873\n",
      "Average episode return: 43.0976\n",
      "Number of training steps: 30176\n",
      "Training speed: 6.0/s\n",
      "Loss: 0.6325\n",
      "\n",
      "Buffer size: 33234\n",
      "Buffer update speed: -7.4/s\n",
      "Number of environment steps: 5556658\n",
      "Average episode return: 40.2218\n",
      "Number of training steps: 30226\n",
      "Training speed: 5.0/s\n",
      "Loss: 0.5814\n",
      "\n",
      "Buffer size: 33036\n",
      "Buffer update speed: -24.6/s\n",
      "Number of environment steps: 5570553\n",
      "Average episode return: 40.4669\n",
      "Number of training steps: 30273\n",
      "Training speed: 4.7/s\n",
      "\n",
      "Loss: 0.6252\n",
      "Buffer size: 33345\n",
      "Buffer update speed: 31.0/s\n",
      "Number of environment steps: 5582879\n",
      "Average episode return: 39.6699\n",
      "Number of training steps: 30353\n",
      "Training speed: 8.1/s\n",
      "Loss: 0.5872\n",
      "\n",
      "Buffer size: 33505\n",
      "Buffer update speed: 8.7/s\n",
      "Number of environment steps: 5594933\n",
      "Average episode return: 43.0394\n",
      "Number of training steps: 30410\n",
      "Training speed: 5.6/s\n",
      "Loss: 0.6269\n",
      "\n",
      "Buffer size: 33575\n",
      "Buffer update speed: 10.3/s\n",
      "Number of environment steps: 5606290\n",
      "Average episode return: 38.8938\n",
      "Number of training steps: 30499\n",
      "Training speed: 8.9/s\n",
      "Loss: 0.6315\n",
      "\n",
      "Buffer size: 33668\n",
      "Buffer update speed: 9.7/s\n",
      "Number of environment steps: 5620415\n",
      "Average episode return: 40.2210\n",
      "Number of training steps: 30557\n",
      "Training speed: 5.9/s\n",
      "Loss: 0.6704\n",
      "\n",
      "Buffer size: 33756\n",
      "Buffer update speed: 15.9/s\n",
      "Number of environment steps: 5634642\n",
      "Average episode return: 41.7139\n",
      "Number of training steps: 30644\n",
      "Training speed: 8.6/s\n",
      "Loss: 0.6615\n",
      "\n",
      "Buffer size: 33445\n",
      "Buffer update speed: -30.6/s\n",
      "Number of environment steps: 5652975\n",
      "Average episode return: 44.4185\n",
      "Number of training steps: 30723\n",
      "Training speed: 7.9/s\n",
      "Loss: 0.6089\n",
      "\n",
      "Buffer size: 33149\n",
      "Buffer update speed: -30.1/s\n",
      "Number of environment steps: 5665534\n",
      "Average episode return: 41.1316\n",
      "Number of training steps: 30783\n",
      "Training speed: 6.0/s\n",
      "Loss: 0.5852\n",
      "\n",
      "Buffer size: 32855\n",
      "Buffer update speed: -27.7/s\n",
      "Number of environment steps: 5678245\n",
      "Average episode return: 38.9448\n",
      "Number of training steps: 30843\n",
      "Training speed: 6.0/s\n",
      "Loss: 0.5702\n",
      "\n",
      "Buffer size: 32864\n",
      "Buffer update speed: 0.9/s\n",
      "Number of environment steps: 5692715\n",
      "Average episode return: 38.3717\n",
      "Number of training steps: 30943\n",
      "Training speed: 10.0/s\n",
      "Loss: 0.7043\n",
      "\n",
      "Buffer size: 32882\n",
      "Buffer update speed: 2.8/s\n",
      "Number of environment steps: 5707185\n",
      "Average episode return: 38.6863\n",
      "Number of training steps: 31025\n",
      "Training speed: 8.2/s\n",
      "Loss: 0.7933\n",
      "\n",
      "Buffer size: 32730\n",
      "Buffer update speed: -10.8/s\n",
      "Number of environment steps: 5721960\n",
      "Average episode return: 40.5718\n",
      "Number of training steps: 31076\n",
      "Training speed: 5.1/s\n",
      "Loss: 0.7060\n",
      "\n",
      "Buffer size: 32663\n",
      "Buffer update speed: -12.3/s\n",
      "Number of environment steps: 5736417\n",
      "Average episode return: 41.9046\n",
      "Number of training steps: 31193\n",
      "Training speed: 11.7/s\n",
      "Loss: 0.6015\n",
      "\n",
      "Buffer size: 32890\n",
      "Buffer update speed: 24.3/s\n",
      "Number of environment steps: 5752434\n",
      "Average episode return: 43.6785\n",
      "Number of training steps: 31321\n",
      "Training speed: 12.8/s\n",
      "Loss: 0.5841\n",
      "\n",
      "Buffer size: 33091\n",
      "Buffer update speed: 19.2/s\n",
      "Number of environment steps: 5766961\n",
      "Average episode return: 39.3542\n",
      "Number of training steps: 31412\n",
      "Training speed: 9.1/s\n",
      "Loss: 0.6589\n",
      "\n",
      "Buffer size: 33232\n",
      "Buffer update speed: 14.2/s\n",
      "Number of environment steps: 5780750\n",
      "Average episode return: 41.9878\n",
      "Number of training steps: 31497\n",
      "Training speed: 8.5/s\n",
      "Loss: 0.6408\n",
      "\n",
      "Buffer size: 33555\n",
      "Buffer update speed: 31.0/s\n",
      "Number of environment steps: 5794799\n",
      "Average episode return: 42.4970\n",
      "Number of training steps: 31566\n",
      "Training speed: 6.9/s\n",
      "Loss: 0.6488\n",
      "\n",
      "Buffer size: 32893\n",
      "Buffer update speed: -63.1/s\n",
      "Number of environment steps: 5808227\n",
      "Average episode return: 41.7072\n",
      "Number of training steps: 31625\n",
      "Training speed: 5.9/s\n",
      "Loss: 0.5854\n",
      "\n",
      "Buffer size: 32744\n",
      "Buffer update speed: -18.3/s\n",
      "Number of environment steps: 5819888\n",
      "Average episode return: 41.6464\n",
      "Number of training steps: 31727\n",
      "Training speed: 10.2/s\n",
      "Loss: 0.5993\n",
      "\n",
      "Buffer size: 32561\n",
      "Buffer update speed: -12.5/s\n",
      "Number of environment steps: 5832961\n",
      "Average episode return: 40.9905\n",
      "Number of training steps: 31821\n",
      "Training speed: 9.4/s\n",
      "Loss: 0.6044\n",
      "\n",
      "Buffer size: 32602\n",
      "Buffer update speed: 1.7/s\n",
      "Number of environment steps: 5848769\n",
      "Average episode return: 43.1035\n",
      "Number of training steps: 31908\n",
      "Training speed: 8.7/s\n",
      "Loss: 0.6165\n",
      "\n",
      "Buffer size: 32887\n",
      "Buffer update speed: 24.9/s\n",
      "Number of environment steps: 5861485\n",
      "Average episode return: 40.8961\n",
      "Number of training steps: 31982\n",
      "Training speed: 7.6/s\n",
      "Loss: 0.5793\n",
      "\n",
      "Buffer size: 32855\n",
      "Buffer update speed: -1.0/s\n",
      "Number of environment steps: 5873452\n",
      "Average episode return: 40.2910\n",
      "Number of training steps: 32024\n",
      "Training speed: 4.0/s\n",
      "Loss: 0.5987\n",
      "\n",
      "Buffer size: 32611\n",
      "Buffer update speed: -21.1/s\n",
      "Number of environment steps: 5884149\n",
      "Average episode return: 37.9326\n",
      "Number of training steps: 32075\n",
      "Training speed: 5.1/s\n",
      "Loss: 0.6073\n",
      "\n",
      "Buffer size: 32925\n",
      "Buffer update speed: 29.4/s\n",
      "Number of environment steps: 5898052\n",
      "Average episode return: 36.9761\n",
      "Number of training steps: 32158\n",
      "Training speed: 8.3/s\n",
      "Loss: 0.6536\n",
      "\n",
      "Buffer size: 32883\n",
      "Buffer update speed: 0.9/s\n",
      "Number of environment steps: 5911234\n",
      "Average episode return: 36.4155\n",
      "Number of training steps: 32214\n",
      "Training speed: 5.6/s\n",
      "Loss: 0.6928\n",
      "\n",
      "Buffer size: 33002\n",
      "Buffer update speed: 5.5/s\n",
      "Number of environment steps: 5925143\n",
      "Average episode return: 37.3016\n",
      "Number of training steps: 32286\n",
      "Training speed: 7.2/s\n",
      "Loss: 0.6815\n",
      "\n",
      "Buffer size: 32455\n",
      "Buffer update speed: -54.7/s\n",
      "Number of environment steps: 5939791\n",
      "Average episode return: 36.7028\n",
      "Number of training steps: 32341\n",
      "Training speed: 5.1/s\n",
      "Loss: 0.6945\n",
      "\n",
      "Buffer size: 32194\n",
      "Buffer update speed: -26.1/s\n",
      "Number of environment steps: 5954959\n",
      "Average episode return: 35.4906\n",
      "Number of training steps: 32400\n",
      "Training speed: 5.9/s\n",
      "Loss: 0.7091\n",
      "\n",
      "Buffer size: 31994\n",
      "Buffer update speed: -24.3/s\n",
      "Number of environment steps: 5970290\n",
      "Average episode return: 34.8914\n",
      "Number of training steps: 32511\n",
      "Training speed: 11.2/s\n",
      "Loss: 0.7252\n",
      "\n",
      "Buffer size: 31855\n",
      "Buffer update speed: -11.4/s\n",
      "Number of environment steps: 5984783\n",
      "Average episode return: 33.5381\n",
      "Number of training steps: 32569\n",
      "Training speed: 5.7/s\n",
      "Loss: 0.7505\n",
      "\n",
      "Buffer size: 32083\n",
      "Buffer update speed: 20.3/s\n",
      "Number of environment steps: 5997311\n",
      "Average episode return: 36.4302\n",
      "Number of training steps: 32629\n",
      "Training speed: 5.9/s\n",
      "Loss: 0.7053\n",
      "\n",
      "Buffer size: 32077\n",
      "Buffer update speed: 10.1/s\n",
      "Number of environment steps: 6009155\n",
      "Average episode return: 37.6497\n",
      "Number of training steps: 32666\n",
      "Training speed: 3.7/s\n",
      "Loss: 0.6612\n",
      "\n",
      "Buffer size: 31999\n",
      "Buffer update speed: -12.2/s\n",
      "Number of environment steps: 6022514\n",
      "Average episode return: 36.1530\n",
      "Number of training steps: 32770\n",
      "Training speed: 10.3/sLoss: 0.6651\n",
      "\n",
      "\n",
      "Buffer size: 31972\n",
      "Buffer update speed: -2.7/s\n",
      "Number of environment steps: 6038529\n",
      "Average episode return: 39.7717\n",
      "Number of training steps: 32854\n",
      "Training speed: 8.4/s\n",
      "Loss: 0.6178\n",
      "\n",
      "Buffer size: 31831\n",
      "Buffer update speed: -14.7/s\n",
      "Number of environment steps: 6051149\n",
      "Average episode return: 40.8161\n",
      "Number of training steps: 32934\n",
      "Training speed: 7.7/s\n",
      "Loss: 0.6019\n",
      "\n",
      "Buffer size: 31607\n",
      "Buffer update speed: -22.4/s\n",
      "Number of environment steps: 6065892\n",
      "Average episode return: 38.9125\n",
      "Number of training steps: 32995\n",
      "Training speed: 6.1/s\n",
      "Loss: 0.5774\n",
      "\n",
      "Buffer size: 31626\n",
      "Buffer update speed: 1.9/s\n",
      "Number of environment steps: 6081631\n",
      "Average episode return: 37.1108\n",
      "Number of training steps: 33102\n",
      "Training speed: 10.4/s\n",
      "Loss: 0.6503\n",
      "\n",
      "Buffer size: 31585\n",
      "Buffer update speed: -5.5/s\n",
      "Number of environment steps: 6096169\n",
      "Average episode return: 35.0096\n",
      "Number of training steps: 33160\n",
      "Training speed: 5.8/s\n",
      "Loss: 0.7010\n",
      "\n",
      "Buffer size: 31494\n",
      "Buffer update speed: -4.6/s\n",
      "Number of environment steps: 6109957\n",
      "Average episode return: 32.2254\n",
      "Number of training steps: 33226\n",
      "Training speed: 6.5/s\n",
      "Loss: 0.7652\n",
      "\n",
      "Buffer size: 32099\n",
      "Buffer update speed: 61.9/s\n",
      "Number of environment steps: 6124324\n",
      "Average episode return: 34.6642\n",
      "Number of training steps: 33297\n",
      "Training speed: 7.1/s\n",
      "Loss: 0.7491\n",
      "\n",
      "Buffer size: 32816\n",
      "Buffer update speed: 64.4/s\n",
      "Number of environment steps: 6140383\n",
      "Average episode return: 35.6269\n",
      "Number of training steps: 33402\n",
      "Training speed: 10.5/s\n",
      "Loss: 0.7452\n",
      "\n",
      "Buffer size: 33049\n",
      "Buffer update speed: 18.8/s\n",
      "Number of environment steps: 6154665\n",
      "Average episode return: 36.7333\n",
      "Number of training steps: 33461\n",
      "Training speed: 5.9/s\n",
      "Loss: 0.7395\n",
      "\n",
      "Buffer size: 32804\n",
      "Buffer update speed: -19.2/s\n",
      "Number of environment steps: 6168175\n",
      "Average episode return: 37.1154\n",
      "Number of training steps: 33530\n",
      "Training speed: 6.9/s\n",
      "Loss: 0.6823\n",
      "\n",
      "Buffer size: 33133\n",
      "Buffer update speed: 35.8/s\n",
      "Number of environment steps: 6179692\n",
      "Average episode return: 41.4228\n",
      "Number of training steps: 33586\n",
      "Training speed: 5.6/s\n",
      "Loss: 0.7358\n",
      "\n",
      "Buffer size: 33406\n",
      "Buffer update speed: 26.9/s\n",
      "Number of environment steps: 6193048\n",
      "Average episode return: 41.7267\n",
      "Number of training steps: 33657\n",
      "Training speed: 7.2/s\n",
      "Loss: 0.6346\n",
      "\n",
      "Buffer size: 33629\n",
      "Buffer update speed: 19.6/s\n",
      "Number of environment steps: 6205652\n",
      "Average episode return: 38.3617\n",
      "Number of training steps: 33702\n",
      "Training speed: 4.4/s\n",
      "Loss: 0.6385\n",
      "\n",
      "Buffer size: 33512\n",
      "Buffer update speed: -11.7/s\n",
      "Number of environment steps: 6216645\n",
      "Average episode return: 38.1010\n",
      "Number of training steps: 33762\n",
      "Training speed: 6.0/s\n",
      "Loss: 0.6077\n",
      "\n",
      "Buffer size: 33440\n",
      "Buffer update speed: -6.9/s\n",
      "Number of environment steps: 6229021\n",
      "Average episode return: 38.5455\n",
      "Number of training steps: 33851\n",
      "Training speed: 8.7/s\n",
      "Loss: 0.7205\n",
      "\n",
      "Buffer size: 33338\n",
      "Buffer update speed: -6.6/s\n",
      "Number of environment steps: 6242730\n",
      "Average episode return: 41.8963\n",
      "Number of training steps: 33919\n",
      "Training speed: 6.8/s\n",
      "Loss: 0.6825\n",
      "\n",
      "Buffer size: 33550\n",
      "Buffer update speed: 18.6/s\n",
      "Number of environment steps: 6256171\n",
      "Average episode return: 40.5331\n",
      "Number of training steps: 33983\n",
      "Training speed: 6.4/s\n",
      "Loss: 0.6536\n",
      "\n",
      "Buffer size: 33331\n",
      "Buffer update speed: -21.5/s\n",
      "Number of environment steps: 6268440\n",
      "Average episode return: 38.8833\n",
      "Number of training steps: 34064\n",
      "Training speed: 8.1/s\n",
      "Loss: 0.6330\n",
      "\n",
      "Buffer size: 33167\n",
      "Buffer update speed: -16.4/s\n",
      "Number of environment steps: 6283085\n",
      "Average episode return: 42.1304\n",
      "Number of training steps: 34144\n",
      "Training speed: 8.0/s\n",
      "Loss: 0.6749\n",
      "\n",
      "Buffer size: 33552\n",
      "Buffer update speed: 36.0/s\n",
      "Number of environment steps: 6296381\n",
      "Average episode return: 40.8985\n",
      "Number of training steps: 34219\n",
      "Training speed: 7.5/s\n",
      "Loss: 0.6480\n",
      "\n",
      "Buffer size: 33373\n",
      "Buffer update speed: -19.2/s\n",
      "Number of environment steps: 6309239\n",
      "Average episode return: 41.6299Training speed: 5.7/s\n",
      "Number of training steps: 34276\n",
      "\n",
      "Loss: 0.6837\n",
      "\n",
      "Buffer size: 33265\n",
      "Buffer update speed: -6.4/s\n",
      "Number of environment steps: 6321575\n",
      "Average episode return: 43.2535\n",
      "Number of training steps: 34360\n",
      "Training speed: 8.4/s\n",
      "Loss: 0.6240\n",
      "\n",
      "Buffer size: 32813\n",
      "Buffer update speed: -46.1/s\n",
      "Number of environment steps: 6336801\n",
      "Average episode return: 43.1525\n",
      "Number of training steps: 34490\n",
      "Training speed: 13.0/s\n",
      "Loss: 0.6784\n",
      "\n",
      "Buffer size: 32964\n",
      "Buffer update speed: 15.1/s\n",
      "Number of environment steps: 6349259\n",
      "Average episode return: 42.5828\n",
      "Number of training steps: 34595\n",
      "Training speed: 10.5/s\n",
      "Loss: 0.6775\n",
      "\n",
      "Buffer size: 32796\n",
      "Buffer update speed: -16.8/s\n",
      "Number of environment steps: 6361898\n",
      "Average episode return: 39.9969\n",
      "Number of training steps: 34661\n",
      "Training speed: 6.6/s\n",
      "Loss: 0.6937\n",
      "\n",
      "Buffer size: 32356\n",
      "Buffer update speed: -44.0/s\n",
      "Number of environment steps: 6377735\n",
      "Average episode return: 38.1570\n",
      "Number of training steps: 34704\n",
      "Training speed: 4.3/s\n",
      "Loss: 0.7039\n",
      "\n",
      "Buffer size: 32209\n",
      "Buffer update speed: -14.7/s\n",
      "Number of environment steps: 6388940\n",
      "Average episode return: 39.0451\n",
      "Number of training steps: 34751\n",
      "Training speed: 4.9/s\n",
      "Loss: 0.7515\n",
      "\n",
      "Buffer size: 32280\n",
      "Buffer update speed: 2.5/s\n",
      "Number of environment steps: 6401105\n",
      "Average episode return: 37.6480\n",
      "Number of training steps: 34811\n",
      "Training speed: 5.8/s\n",
      "Loss: 0.7537\n",
      "\n",
      "Buffer size: 32952\n",
      "Buffer update speed: 71.8/s\n",
      "Number of environment steps: 6415242\n",
      "Average episode return: 37.6048\n",
      "Number of training steps: 34881\n",
      "Training speed: 7.0/s\n",
      "Loss: 0.7327\n",
      "\n",
      "Buffer size: 32667\n",
      "Buffer update speed: -21.9/s\n",
      "Number of environment steps: 6430138\n",
      "Average episode return: 38.1902\n",
      "Number of training steps: 34945\n",
      "Training speed: 6.5/s\n",
      "Loss: 0.7306\n",
      "\n",
      "Buffer size: 31937\n",
      "Buffer update speed: -75.7/s\n",
      "Number of environment steps: 6443360\n",
      "Average episode return: 37.7123\n",
      "Number of training steps: 35048\n",
      "Training speed: 10.2/s\n",
      "Loss: 0.7094\n",
      "\n",
      "Buffer size: 31060\n",
      "Buffer update speed: -89.0/s\n",
      "Number of environment steps: 6457028\n",
      "Average episode return: 38.4342\n",
      "Number of training steps: 35122\n",
      "Training speed: 7.4/s\n",
      "Loss: 0.6784\n",
      "\n",
      "Buffer size: 31154\n",
      "Buffer update speed: 5.4/s\n",
      "Number of environment steps: 6473056\n",
      "Average episode return: 36.1318\n",
      "Number of training steps: 35192\n",
      "Training speed: 7.0/s\n",
      "Loss: 0.6561\n",
      "\n",
      "Buffer size: 32034\n",
      "\n",
      "Buffer update speed: 88.1/sNumber of environment steps: 6491085\n",
      "Average episode return: 33.2356\n",
      "Number of training steps: 35289\n",
      "Training speed: 9.5/s\n",
      "Loss: 0.6852\n",
      "\n",
      "Buffer size: 32134\n",
      "Buffer update speed: 12.0/s\n",
      "Number of environment steps: 6504096\n",
      "Average episode return: 34.8027\n",
      "Number of training steps: 35345\n",
      "Training speed: 5.3/s\n",
      "Loss: 0.6996\n",
      "\n",
      "Buffer size: 32069\n",
      "Buffer update speed: -6.5/s\n",
      "Number of environment steps: 6517158\n",
      "Average episode return: 36.6723\n",
      "Number of training steps: 35392\n",
      "Training speed: 4.7/s\n",
      "Loss: 0.7460\n",
      "\n",
      "Buffer size: 31364\n",
      "Buffer update speed: -59.1/s\n",
      "Number of environment steps: 6531700\n",
      "Average episode return: 36.4550\n",
      "Number of training steps: 35447\n",
      "Training speed: 5.5/s\n",
      "Loss: 0.6150\n",
      "\n",
      "Buffer size: 31094\n",
      "Buffer update speed: -24.8/s\n",
      "Number of environment steps: 6545325\n",
      "Average episode return: 36.8142\n",
      "Number of training steps: 35505\n",
      "Training speed: 5.8/s\n",
      "Loss: 0.6140\n",
      "\n",
      "Buffer size: 31460\n",
      "Buffer update speed: 35.0/s\n",
      "Number of environment steps: 6557333\n",
      "Average episode return: 34.4069\n",
      "Number of training steps: 35566\n",
      "Training speed: 6.1/s\n",
      "Loss: 0.6720\n",
      "\n",
      "Buffer size: 31068\n",
      "Buffer update speed: -41.5/s\n",
      "Number of environment steps: 6572307\n",
      "Average episode return: 29.8135\n",
      "Number of training steps: 35617\n",
      "Training speed: 5.1/s\n",
      "Loss: 0.6974\n",
      "\n",
      "Buffer size: 30277\n",
      "Buffer update speed: -79.1/s\n",
      "Number of environment steps: 6587391\n",
      "Average episode return: 28.3887\n",
      "Number of training steps: 35712\n",
      "Training speed: 9.7/s\n",
      "Loss: 0.8829\n",
      "\n",
      "Buffer size: 31296\n",
      "Buffer update speed: 101.3/s\n",
      "Number of environment steps: 6603311\n",
      "Average episode return: 30.6763\n",
      "Number of training steps: 35792\n",
      "Training speed: 7.8/s\n",
      "Loss: 0.9296\n",
      "\n",
      "Buffer size: 32674\n",
      "Buffer update speed: 142.2/s\n",
      "Number of environment steps: 6618121\n",
      "Average episode return: 33.9679\n",
      "Number of training steps: 35840\n",
      "Training speed: 4.6/s\n",
      "Loss: 0.7926\n",
      "\n",
      "Buffer size: 32585\n",
      "Buffer update speed: -7.9/s\n",
      "Number of environment steps: 6631791\n",
      "Average episode return: 35.8110\n",
      "Number of training steps: 35946\n",
      "Training speed: 10.6/s\n",
      "Loss: 0.7216\n",
      "\n",
      "Buffer size: 31898\n",
      "Buffer update speed: -71.0/s\n",
      "Number of environment steps: 6647856\n",
      "Average episode return: 39.2445\n",
      "Number of training steps: 36019\n",
      "Training speed: 7.0/s\n",
      "Loss: 0.6827\n",
      "\n",
      "Buffer size: 31863\n",
      "Buffer update speed: -3.6/s\n",
      "Number of environment steps: 6661455\n",
      "Average episode return: 40.3145\n",
      "Number of training steps: 36111\n",
      "Training speed: 9.2/s\n",
      "Loss: 0.7024\n",
      "\n",
      "Buffer size: 32107\n",
      "Buffer update speed: 22.6/s\n",
      "Number of environment steps: 6679984\n",
      "Average episode return: 39.6731\n",
      "Number of training steps: 36205\n",
      "Training speed: 9.1/s\n",
      "Loss: 0.6612\n",
      "\n",
      "Buffer size: 31828\n",
      "Buffer update speed: -29.3/s\n",
      "Number of environment steps: 6694615\n",
      "Average episode return: 39.5445\n",
      "Number of training steps: 36250\n",
      "Training speed: 4.4/s\n",
      "Loss: 0.6421\n",
      "\n",
      "Buffer size: 31847\n",
      "Average episode return: 40.9650Buffer update speed: 5.0/s\n",
      "Number of environment steps: 6708746\n",
      "\n",
      "Number of training steps: 36333\n",
      "Training speed: 8.5/s\n",
      "Loss: 0.6639\n",
      "\n",
      "Buffer size: 32380\n",
      "Buffer update speed: 48.7/s\n",
      "Number of environment steps: 6722471\n",
      "Average episode return: 39.5578\n",
      "Number of training steps: 36405\n",
      "Training speed: 7.0/s\n",
      "Loss: 0.6592\n",
      "\n",
      "Buffer size: 32459\n",
      "Buffer update speed: 13.4/s\n",
      "Number of environment steps: 6734677\n",
      "Average episode return: 40.6890\n",
      "Number of training steps: 36478\n",
      "Training speed: 7.3/s\n",
      "Loss: 0.6438\n",
      "\n",
      "Buffer size: 32871Number of training steps: 36565\n",
      "Buffer update speed: 41.2/s\n",
      "Number of environment steps: 6746717\n",
      "Average episode return: 40.9459\n",
      "\n",
      "Training speed: 8.6/s\n",
      "Loss: 0.6836\n",
      "\n",
      "Buffer size: 32883\n",
      "Buffer update speed: 2.1/s\n",
      "Number of environment steps: 6761673\n",
      "Average episode return: 37.1970\n",
      "Number of training steps: 36614\n",
      "Training speed: 4.7/s\n",
      "Loss: 0.6601\n",
      "\n",
      "Buffer size: 33484\n",
      "Buffer update speed: 60.2/s\n",
      "Number of environment steps: 6775278\n",
      "Average episode return: 36.4867\n",
      "Number of training steps: 36685\n",
      "Training speed: 7.1/s\n",
      "Loss: 0.7873\n",
      "\n",
      "Buffer size: 33399\n",
      "Buffer update speed: -9.1/s\n",
      "Number of environment steps: 6788744\n",
      "Average episode return: 36.8485\n",
      "Number of training steps: 36752\n",
      "Training speed: 6.8/s\n",
      "Loss: 0.8993\n",
      "\n",
      "Buffer size: 33518\n",
      "Buffer update speed: 11.0/s\n",
      "Number of environment steps: 6803954\n",
      "Average episode return: 38.6005\n",
      "Number of training steps: 36816\n",
      "Training speed: 6.2/s\n",
      "Loss: 0.8010\n",
      "\n",
      "Buffer size: 33204\n",
      "Buffer update speed: -32.0/s\n",
      "Number of environment steps: 6818320\n",
      "Average episode return: 39.6953\n",
      "Number of training steps: 36913\n",
      "Training speed: 9.6/s\n",
      "Loss: 0.7272\n",
      "\n",
      "Buffer size: 32908\n",
      "Buffer update speed: -29.3/s\n",
      "Number of environment steps: 6833342\n",
      "Average episode return: 42.5577\n",
      "Number of training steps: 36984\n",
      "Training speed: 7.1/s\n",
      "Loss: 0.7210\n",
      "\n",
      "Buffer size: 32693\n",
      "Buffer update speed: -20.1/s\n",
      "Number of environment steps: 6845327\n",
      "Average episode return: 40.0034\n",
      "Number of training steps: 37044\n",
      "Training speed: 6.0/s\n",
      "Loss: 0.6901\n",
      "\n",
      "Buffer size: 32257\n",
      "Buffer update speed: -47.4/s\n",
      "Number of environment steps: 6858260\n",
      "Average episode return: 42.4047\n",
      "Number of training steps: 37114\n",
      "Training speed: 7.0/s\n",
      "Loss: 0.6846\n",
      "\n",
      "Buffer size: 31973\n",
      "Buffer update speed: -24.6/s\n",
      "Number of environment steps: 6872272\n",
      "Average episode return: 43.2147\n",
      "Number of training steps: 37201\n",
      "Training speed: 8.7/s\n",
      "Loss: 0.6440\n",
      "\n",
      "Buffer size: 32243\n",
      "Buffer update speed: 27.0/s\n",
      "Number of environment steps: 6887590\n",
      "Average episode return: 41.3198\n",
      "Number of training steps: 37293\n",
      "Training speed: 9.2/s\n",
      "Loss: 0.6515\n",
      "\n",
      "Buffer size: 32569\n",
      "Buffer update speed: 25.6/s\n",
      "Number of environment steps: 6900885\n",
      "Average episode return: 39.6856\n",
      "Number of training steps: 37396\n",
      "Training speed: 10.2/s\n",
      "Loss: 0.7304\n",
      "\n",
      "Buffer size: 32813\n",
      "Buffer update speed: 31.0/s\n",
      "Number of environment steps: 6913840\n",
      "Average episode return: 38.4421\n",
      "Number of training steps: 37447\n",
      "Training speed: 5.1/s\n",
      "Loss: 0.6904\n",
      "\n",
      "Buffer size: 32967\n",
      "Buffer update speed: 14.5/s\n",
      "Number of environment steps: 6928742\n",
      "Average episode return: 39.2089\n",
      "Number of training steps: 37519\n",
      "Training speed: 7.2/s\n",
      "Loss: 0.7314\n",
      "\n",
      "Buffer size: 32695\n",
      "Buffer update speed: -27.0/s\n",
      "Number of environment steps: 6939575\n",
      "Average episode return: 42.1089\n",
      "Number of training steps: 37574\n",
      "Training speed: 5.4/s\n",
      "Loss: 0.7086\n",
      "\n",
      "Buffer size: 32756\n",
      "Buffer update speed: 11.5/s\n",
      "Number of environment steps: 6950191\n",
      "Average episode return: 40.9027\n",
      "Number of training steps: 37647\n",
      "Training speed: 7.3/s\n",
      "Loss: 0.6686\n",
      "\n",
      "Buffer size: 32989\n",
      "Buffer update speed: 23.1/s\n",
      "Number of environment steps: 6962408\n",
      "Average episode return: 40.8624\n",
      "Number of training steps: 37743\n",
      "Training speed: 9.6/s\n",
      "Loss: 0.6989\n",
      "\n",
      "Buffer size: 33043\n",
      "Buffer update speed: 11.4/s\n",
      "Number of environment steps: 6974454\n",
      "Average episode return: 42.5874\n",
      "Number of training steps: 37784\n",
      "Training speed: 4.2/s\n",
      "Loss: 0.6917\n",
      "\n",
      "Buffer size: 32660\n",
      "Buffer update speed: -49.9/s\n",
      "Number of environment steps: 6987381\n",
      "Average episode return: 43.1405\n",
      "Number of training steps: 37856\n",
      "Training speed: 7.1/s\n",
      "Loss: 0.6620\n",
      "\n",
      "Buffer size: 31840\n",
      "Buffer update speed: -78.8/s\n",
      "Number of environment steps: 7000323\n",
      "Average episode return: 42.4950\n",
      "Number of training steps: 37924\n",
      "Training speed: 6.8/s\n",
      "Loss: 0.5921\n",
      "\n",
      "Buffer size: 32029\n",
      "Buffer update speed: 11.3/s\n",
      "Number of environment steps: 7014979\n",
      "Average episode return: 39.0851\n",
      "Number of training steps: 37989\n",
      "Training speed: 6.7/s\n",
      "Loss: 0.6390\n",
      "\n",
      "Buffer size: 32813\n",
      "Buffer update speed: 80.8/s\n",
      "Number of environment steps: 7031288\n",
      "Average episode return: 35.0086\n",
      "Number of training steps: 38089\n",
      "Training speed: 9.8/s\n",
      "Loss: 0.7226\n",
      "\n",
      "Buffer size: 32699\n",
      "Buffer update speed: -10.8/s\n",
      "Number of environment steps: 7047718\n",
      "Average episode return: 34.3236\n",
      "Number of training steps: 38219\n",
      "Training speed: 13.0/s\n",
      "Loss: 0.8378\n",
      "\n",
      "Buffer size: 32258\n",
      "Buffer update speed: -46.7/s\n",
      "Number of environment steps: 7061933\n",
      "Average episode return: 38.2811\n",
      "Number of training steps: 38283\n",
      "Training speed: 6.5/s\n",
      "Loss: 0.8506\n",
      "\n",
      "Buffer size: 32170\n",
      "Buffer update speed: -6.3/s\n",
      "Number of environment steps: 7074427\n",
      "Average episode return: 35.8835\n",
      "Number of training steps: 38350\n",
      "Training speed: 6.4/s\n",
      "Loss: 0.7806\n",
      "\n",
      "Buffer size: 32102\n",
      "Buffer update speed: -10.9/s\n",
      "Number of environment steps: 7086230\n",
      "Average episode return: 36.2733\n",
      "Number of training steps: 38404\n",
      "Training speed: 5.4/s\n",
      "Loss: 0.7737\n",
      "\n",
      "Buffer size: 32423\n",
      "Buffer update speed: 28.0/s\n",
      "Number of environment steps: 7098075\n",
      "Average episode return: 32.8116\n",
      "Number of training steps: 38456\n",
      "Training speed: 5.2/s\n",
      "Loss: 0.7500\n",
      "\n",
      "Buffer size: 32267\n",
      "Buffer update speed: -10.0/s\n",
      "Number of environment steps: 7112231\n",
      "Average episode return: 36.5699\n",
      "Number of training steps: 38513\n",
      "Training speed: 5.7/s\n",
      "Loss: 0.7735\n",
      "\n",
      "Buffer size: 31895\n",
      "Buffer update speed: -40.6/s\n",
      "Number of environment steps: 7127914\n",
      "Average episode return: 35.3326\n",
      "Number of training steps: 38573\n",
      "Training speed: 6.0/s\n",
      "Loss: 0.6912\n",
      "\n",
      "Buffer size: 31634\n",
      "Buffer update speed: -27.8/s\n",
      "Number of environment steps: 7142776\n",
      "Average episode return: 34.6183\n",
      "Number of training steps: 38674\n",
      "Training speed: 10.1/s\n",
      "Loss: 0.7360\n",
      "\n",
      "Buffer size: 31412\n",
      "Buffer update speed: -20.7/s\n",
      "Number of environment steps: 7154827\n",
      "Average episode return: 35.7722\n",
      "Number of training steps: 38778\n",
      "Training speed: 10.4/s\n",
      "Loss: 0.7176\n",
      "\n",
      "Buffer size: 31684\n",
      "Buffer update speed: 24.3/s\n",
      "Number of environment steps: 7167722\n",
      "Average episode return: 36.1408\n",
      "Number of training steps: 38833\n",
      "Training speed: 5.5/s\n",
      "Loss: 0.7453\n",
      "\n",
      "Buffer size: 31673\n",
      "Buffer update speed: -6.0/s\n",
      "Number of environment steps: 7182538\n",
      "Average episode return: 36.2676\n",
      "Number of training steps: 38905\n",
      "Training speed: 7.3/s\n",
      "Loss: 0.6830\n",
      "\n",
      "Buffer size: 31738\n",
      "Buffer update speed: 6.4/s\n",
      "Number of environment steps: 7196851\n",
      "Average episode return: 38.5526\n",
      "Number of training steps: 38973\n",
      "Training speed: 6.6/s\n",
      "Loss: 0.7220\n",
      "\n",
      "Buffer size: 31187\n",
      "Buffer update speed: -51.4/s\n",
      "Number of environment steps: 7211386\n",
      "Average episode return: 37.1607\n",
      "Number of training steps: 39052\n",
      "Training speed: 7.9/s\n",
      "Loss: 0.7026\n",
      "\n",
      "Buffer size: 31334\n",
      "Buffer update speed: 13.8/s\n",
      "Number of environment steps: 7222024\n",
      "Average episode return: 36.7378\n",
      "Number of training steps: 39147\n",
      "Training speed: 9.5/s\n",
      "Loss: 0.7465\n",
      "\n",
      "Buffer size: 31805\n",
      "Buffer update speed: 46.1/s\n",
      "Number of environment steps: 7236924\n",
      "Average episode return: 35.4976\n",
      "Number of training steps: 39226\n",
      "Training speed: 7.9/s\n",
      "Loss: 0.8129\n",
      "\n",
      "Buffer size: 32417\n",
      "Buffer update speed: 61.2/s\n",
      "Number of environment steps: 7253087\n",
      "Average episode return: 36.1502\n",
      "Number of training steps: 39343\n",
      "Training speed: 11.7/s\n",
      "Loss: 0.7886\n",
      "\n",
      "Buffer size: 32234\n",
      "Buffer update speed: -16.9/s\n",
      "Number of environment steps: 7266881\n",
      "Average episode return: 37.8017\n",
      "Number of training steps: 39437\n",
      "Training speed: 9.4/s\n",
      "Loss: 0.7435\n",
      "\n",
      "Buffer size: 31668\n",
      "Buffer update speed: -53.7/s\n",
      "Number of environment steps: 7282602\n",
      "Average episode return: 41.1073\n",
      "Number of training steps: 39497\n",
      "Training speed: 6.2/s\n",
      "Loss: 0.7249\n",
      "\n",
      "Buffer size: 31678\n",
      "Buffer update speed: 2.7/s\n",
      "Number of environment steps: 7299057\n",
      "Average episode return: 41.6540\n",
      "Number of training steps: 39583\n",
      "Training speed: 8.4/s\n",
      "Loss: 0.6484\n",
      "\n",
      "Buffer size: 31920\n",
      "Buffer update speed: 21.0/s\n",
      "Number of environment steps: 7311765\n",
      "Average episode return: 40.1792\n",
      "Number of training steps: 39652\n",
      "Training speed: 7.0/s\n",
      "Loss: 0.6704\n",
      "\n",
      "Buffer size: 32173\n",
      "Buffer update speed: 22.7/s\n",
      "Number of environment steps: 7322225\n",
      "Average episode return: 36.7148\n",
      "Number of training steps: 39697\n",
      "Training speed: 4.4/s\n",
      "Loss: 0.6562\n",
      "\n",
      "Buffer size: 32045\n",
      "Buffer update speed: -13.9/s\n",
      "Number of environment steps: 7334350\n",
      "Average episode return: 36.7190\n",
      "Number of training steps: 39781\n",
      "Training speed: 8.4/s\n",
      "Loss: 0.7183\n",
      "\n",
      "Buffer size: 31972\n",
      "Buffer update speed: -7.3/s\n",
      "Number of environment steps: 7350435\n",
      "Average episode return: 33.2365\n",
      "Number of training steps: 39845\n",
      "Training speed: 6.4/s\n",
      "Loss: 0.7304\n",
      "\n",
      "Buffer size: 31677\n",
      "Buffer update speed: -28.3/s\n",
      "Number of environment steps: 7363795\n",
      "Average episode return: 33.5516\n",
      "Number of training steps: 39917\n",
      "Training speed: 7.2/s\n",
      "Loss: 0.7693\n",
      "\n",
      "Buffer size: 31689\n",
      "Buffer update speed: 1.5/s\n",
      "Number of environment steps: 7376147\n",
      "Average episode return: 34.2320\n",
      "Number of training steps: 39960\n",
      "Training speed: 4.2/s\n",
      "Loss: 0.7079\n",
      "\n",
      "Buffer size: 31721\n",
      "Buffer update speed: 1.7/s\n",
      "Number of environment steps: 7389459\n",
      "Average episode return: 35.7962\n",
      "Number of training steps: 40044\n",
      "Training speed: 8.5/s\n",
      "Loss: 0.7430\n",
      "\n",
      "Buffer size: 31143\n",
      "Buffer update speed: -57.7/s\n",
      "Number of environment steps: 7401366\n",
      "Average episode return: 31.5146\n",
      "Number of training steps: 40088\n",
      "Training speed: 4.3/s\n",
      "Loss: 0.7686\n",
      "\n",
      "Buffer size: 29689\n",
      "Buffer update speed: -145.4/s\n",
      "Number of environment steps: 7417127\n",
      "Average episode return: 28.0642\n",
      "Number of training steps: 40142\n",
      "Training speed: 5.3/s\n",
      "Loss: 0.8926\n",
      "\n",
      "Buffer size: 30349\n",
      "Buffer update speed: 66.0/s\n",
      "Number of environment steps: 7437005\n",
      "Average episode return: 28.7685\n",
      "Number of training steps: 40258\n",
      "Training speed: 11.6/s\n",
      "Loss: 1.1339\n",
      "\n",
      "Buffer size: 31750\n",
      "Buffer update speed: 140.2/s\n",
      "Number of environment steps: 7452599\n",
      "Average episode return: 31.4838\n",
      "Number of training steps: 40338\n",
      "Training speed: 8.0/s\n",
      "Loss: 1.0739\n",
      "\n",
      "Buffer size: 32140\n",
      "Buffer update speed: 40.1/s\n",
      "Number of environment steps: 7464133\n",
      "Average episode return: 32.5398\n",
      "Number of training steps: 40400\n",
      "Training speed: 6.3/s\n",
      "Loss: 0.8839\n",
      "\n",
      "Buffer size: 31195\n",
      "Buffer update speed: -93.3/s\n",
      "Number of environment steps: 7478592\n",
      "Average episode return: 31.4881\n",
      "Number of training steps: 40462\n",
      "Training speed: 6.1/s\n",
      "Loss: 0.8850\n",
      "\n",
      "Buffer size: 31386\n",
      "Buffer update speed: 16.8/s\n",
      "Number of environment steps: 7493382\n",
      "Average episode return: 37.9791\n",
      "Number of training steps: 40528\n",
      "Training speed: 6.5/s\n",
      "Loss: 0.8677\n",
      "\n",
      "Buffer size: 32062\n",
      "Buffer update speed: 60.0/s\n",
      "Number of environment steps: 7508055\n",
      "Average episode return: 42.7122\n",
      "Number of training steps: 40599\n",
      "Training speed: 7.1/s\n",
      "Loss: 0.8264\n",
      "\n",
      "Buffer size: 32014\n",
      "\n",
      "Buffer update speed: -0.2/sNumber of environment steps: 7520902\n",
      "Average episode return: 40.0124\n",
      "Number of training steps: 40659\n",
      "Training speed: 6.0/s\n",
      "Loss: 0.7089\n",
      "\n",
      "Buffer size: 32324\n",
      "Buffer update speed: 39.0/s\n",
      "Number of environment steps: 7534933\n",
      "Average episode return: 36.4686\n",
      "Number of training steps: 40729\n",
      "Training speed: 6.9/s\n",
      "Loss: 0.7555\n",
      "\n",
      "Buffer size: 32519\n",
      "Buffer update speed: 14.5/s\n",
      "Number of environment steps: 7546498\n",
      "Average episode return: 37.5523\n",
      "Number of training steps: 40775\n",
      "Training speed: 4.3/s\n",
      "Loss: 0.8044\n",
      "\n",
      "Buffer size: 32320\n",
      "Buffer update speed: -22.3/s\n",
      "Number of environment steps: 7559556\n",
      "Average episode return: 37.7333\n",
      "Number of training steps: 40826\n",
      "Training speed: 5.1/s\n",
      "Loss: 0.7593\n",
      "\n",
      "Buffer size: 32185\n",
      "Buffer update speed: -13.9/s\n",
      "Number of environment steps: 7571662\n",
      "Average episode return: 39.4369\n",
      "Number of training steps: 40891\n",
      "Training speed: 6.5/s\n",
      "Loss: 0.7302\n",
      "\n",
      "Buffer size: 32480\n",
      "Buffer update speed: 29.5/s\n",
      "Number of environment steps: 7584367\n",
      "Average episode return: 39.8276\n",
      "Number of training steps: 40959\n",
      "Training speed: 6.8/s\n",
      "Loss: 0.7420\n",
      "\n",
      "Buffer size: 32544\n",
      "Buffer update speed: 6.4/s\n",
      "Number of environment steps: 7598111\n",
      "Average episode return: 40.0702\n",
      "Number of training steps: 41019\n",
      "Training speed: 6.0/s\n",
      "Loss: 0.7521\n",
      "\n",
      "Buffer size: 33010\n",
      "Buffer update speed: 44.0/s\n",
      "Number of environment steps: 7609613\n",
      "Average episode return: 36.5143\n",
      "Number of training steps: 41067\n",
      "Training speed: 4.8/s\n",
      "Loss: 0.7478\n",
      "\n",
      "Buffer size: 33192\n",
      "Buffer update speed: 16.6/s\n",
      "Number of environment steps: 7620728\n",
      "Average episode return: 35.5417\n",
      "Number of training steps: 41112\n",
      "Training speed: 4.5/s\n",
      "Loss: 0.8085\n",
      "\n",
      "Buffer size: 33023\n",
      "Buffer update speed: -10.7/s\n",
      "Number of environment steps: 7632367\n",
      "Average episode return: 39.3492\n",
      "Number of training steps: 41163\n",
      "Training speed: 5.1/s\n",
      "Loss: 0.7824\n",
      "\n",
      "Buffer size: 32252\n",
      "Buffer update speed: -75.0/s\n",
      "Number of environment steps: 7643512\n",
      "Average episode return: 39.5196\n",
      "Number of training steps: 41206\n",
      "Training speed: 4.5/s\n",
      "Loss: 0.7226\n",
      "\n",
      "Buffer size: 31623\n",
      "Buffer update speed: -62.8/s\n",
      "Number of environment steps: 7655545\n",
      "Average episode return: 38.5240\n",
      "Number of training steps: 41270\n",
      "Training speed: 6.2/s\n",
      "Loss: 0.7312\n",
      "\n",
      "Buffer size: 32025\n",
      "Buffer update speed: 37.6/s\n",
      "Number of environment steps: 7667764\n",
      "Average episode return: 38.3302\n",
      "Number of training steps: 41360\n",
      "Training speed: 9.0/sLoss: 0.7304\n",
      "\n",
      "\n",
      "Buffer size: 31899\n",
      "Buffer update speed: -7.5/s\n",
      "Number of environment steps: 7680825\n",
      "Average episode return: 39.6942\n",
      "Number of training steps: 41456\n",
      "Training speed: 9.6/s\n",
      "Loss: 0.7575\n",
      "\n",
      "Buffer size: 31933\n",
      "Buffer update speed: 1.2/s\n",
      "Number of environment steps: 7694303\n",
      "Average episode return: 39.7404\n",
      "Number of training steps: 41545\n",
      "Training speed: 8.9/s\n",
      "Loss: 0.7592\n",
      "\n",
      "Buffer size: 32433\n",
      "Buffer update speed: 50.0/s\n",
      "Number of environment steps: 7708119\n",
      "Average episode return: 36.8172\n",
      "Number of training steps: 41668\n",
      "Training speed: 12.3/s\n",
      "Loss: 0.7891\n",
      "\n",
      "Buffer size: 32851\n",
      "Buffer update speed: 41.8/s\n",
      "Number of environment steps: 7720145\n",
      "Average episode return: 35.7560\n",
      "Number of training steps: 41736\n",
      "Training speed: 6.8/s\n",
      "Loss: 0.8008\n",
      "\n",
      "Buffer size: 33155\n",
      "Buffer update speed: 28.3/s\n",
      "Number of environment steps: 7733147\n",
      "Average episode return: 37.3966\n",
      "Number of training steps: 41812\n",
      "Training speed: 7.6/s\n",
      "Loss: 0.8033\n",
      "\n",
      "Buffer size: 32730\n",
      "Buffer update speed: -40.3/s\n",
      "Number of environment steps: 7745667\n",
      "Average episode return: 37.2619\n",
      "Number of training steps: 41876\n",
      "Training speed: 6.4/s\n",
      "Loss: 0.8424\n",
      "\n",
      "Buffer size: 33319\n",
      "Buffer update speed: 58.8/s\n",
      "Number of environment steps: 7761240\n",
      "Average episode return: 38.9102\n",
      "Number of training steps: 41958\n",
      "Training speed: 8.2/s\n",
      "Loss: 0.8063\n",
      "\n",
      "Buffer size: 33198\n",
      "Buffer update speed: -12.1/s\n",
      "Number of environment steps: 7778082\n",
      "Average episode return: 38.8268\n",
      "Number of training steps: 42034\n",
      "Training speed: 7.6/s\n",
      "Loss: 0.7585\n",
      "\n",
      "Buffer size: 32592\n",
      "Buffer update speed: -60.6/s\n",
      "Number of environment steps: 7795299\n",
      "Average episode return: 41.2878\n",
      "Number of training steps: 42105\n",
      "Training speed: 7.1/s\n",
      "Loss: 0.7677\n",
      "\n",
      "Buffer size: 32479\n",
      "Buffer update speed: -9.5/s\n",
      "Number of environment steps: 7807812\n",
      "Average episode return: 40.2355\n",
      "Number of training steps: 42170\n",
      "Training speed: 6.5/s\n",
      "Loss: 0.7504\n",
      "\n",
      "Buffer size: 32648\n",
      "Buffer update speed: 15.0/s\n",
      "Number of environment steps: 7819723\n",
      "Average episode return: 41.6411\n",
      "Number of training steps: 42245\n",
      "Training speed: 7.5/s\n",
      "Loss: 0.7993\n",
      "\n",
      "Buffer size: 32788\n",
      "Buffer update speed: 11.3/s\n",
      "Number of environment steps: 7831265\n",
      "Average episode return: 43.7481\n",
      "Number of training steps: 42324\n",
      "Training speed: 7.7/s\n",
      "Loss: 0.7528\n",
      "\n",
      "Buffer size: 32499\n",
      "Buffer update speed: -22.7/s\n",
      "Number of environment steps: 7845431\n",
      "Average episode return: 42.9273\n",
      "Number of training steps: 42379\n",
      "Training speed: 5.5/s\n",
      "Loss: 0.7059\n",
      "\n",
      "Buffer size: 32166\n",
      "Buffer update speed: -36.8/s\n",
      "Number of environment steps: 7856029\n",
      "Average episode return: 43.4065\n",
      "Number of training steps: 42434\n",
      "Training speed: 5.5/s\n",
      "Loss: 0.6537\n",
      "\n",
      "Buffer size: 32163\n",
      "Buffer update speed: -0.3/s\n",
      "Number of environment steps: 7868830\n",
      "Average episode return: 40.9006\n",
      "Number of training steps: 42553\n",
      "Training speed: 12.1/s\n",
      "Loss: 0.7138\n",
      "\n",
      "Buffer size: 32154\n",
      "Buffer update speed: -1.7/s\n",
      "Number of environment steps: 7881681\n",
      "Average episode return: 40.1375\n",
      "Number of training steps: 42610\n",
      "Training speed: 5.5/s\n",
      "Loss: 0.8113\n",
      "\n",
      "Buffer size: 32234\n",
      "Buffer update speed: 8.7/s\n",
      "Number of environment steps: 7893456\n",
      "Average episode return: 36.8423\n",
      "Number of training steps: 42673\n",
      "Training speed: 6.4/s\n",
      "Loss: 0.7658\n",
      "\n",
      "Buffer size: 32486\n",
      "Buffer update speed: 23.5/s\n",
      "Number of environment steps: 7906005\n",
      "Average episode return: 39.0906\n",
      "Number of training steps: 42727\n",
      "Training speed: 5.3/s\n",
      "Loss: 0.8405\n",
      "\n",
      "Buffer size: 32199\n",
      "Buffer update speed: -26.4/s\n",
      "Number of environment steps: 7922921\n",
      "Average episode return: 34.9855\n",
      "Number of training steps: 42817\n",
      "Training speed: 9.0/s\n",
      "Loss: 0.8066\n",
      "\n",
      "Buffer size: 31684\n",
      "Buffer update speed: -50.5/s\n",
      "Number of environment steps: 7939689\n",
      "Average episode return: 35.7346\n",
      "Number of training steps: 42908\n",
      "Training speed: 9.1/s\n",
      "Loss: 0.7779\n",
      "\n",
      "Buffer size: 31215\n",
      "Buffer update speed: -47.6/s\n",
      "Number of environment steps: 7950684\n",
      "Average episode return: 36.2748\n",
      "Number of training steps: 42958\n",
      "Training speed: 5.0/s\n",
      "Loss: 0.7832\n",
      "\n",
      "Buffer size: 30963\n",
      "Buffer update speed: -20.9/s\n",
      "Number of environment steps: 7962854\n",
      "Average episode return: 33.9833\n",
      "Number of training steps: 43029\n",
      "Training speed: 7.1/s\n",
      "Loss: 0.7647\n",
      "\n",
      "Buffer size: 30698\n",
      "Buffer update speed: -29.1/s\n",
      "Number of environment steps: 7975068\n",
      "Average episode return: 30.4450\n",
      "Number of training steps: 43091\n",
      "Training speed: 6.2/s\n",
      "Loss: 0.7986\n",
      "\n",
      "Buffer size: 30432\n",
      "Buffer update speed: -21.4/s\n",
      "Number of environment steps: 7992579\n",
      "Average episode return: 27.4701\n",
      "Number of training steps: 43187\n",
      "Training speed: 9.6/s\n",
      "Loss: 0.9109\n",
      "\n",
      "Buffer size: 30162\n",
      "Buffer update speed: -31.2/s\n",
      "\n",
      "Number of environment steps: 8006309Average episode return: 27.2375\n",
      "Number of training steps: 43261\n",
      "Training speed: 7.4/s\n",
      "Loss: 0.9648\n",
      "\n",
      "Buffer size: 30447\n",
      "Buffer update speed: 29.0/s\n",
      "Number of environment steps: 8019163\n",
      "Average episode return: 30.2000\n",
      "Number of training steps: 43333\n",
      "Training speed: 6.9/s\n",
      "Loss: 0.8969\n",
      "\n",
      "Buffer size: 31609\n",
      "Buffer update speed: 115.9/s\n",
      "Number of environment steps: 8032365\n",
      "Average episode return: 33.2265\n",
      "Number of training steps: 43426\n",
      "Training speed: 9.3/s\n",
      "Loss: 0.8512\n",
      "\n",
      "Buffer size: 31696\n",
      "Buffer update speed: 10.5/s\n",
      "Number of environment steps: 8048938\n",
      "Average episode return: 35.6333\n",
      "Number of training steps: 43524\n",
      "Training speed: 10.0/s\n",
      "Loss: 0.7584\n",
      "\n",
      "Buffer size: 31048\n",
      "Buffer update speed: -63.3/s\n",
      "Number of environment steps: 8060602\n",
      "Average episode return: 31.6393\n",
      "Number of training steps: 43607\n",
      "Training speed: 8.1/s\n",
      "Loss: 0.7680\n",
      "\n",
      "Buffer size: 30487\n",
      "Buffer update speed: -56.5/s\n",
      "Number of environment steps: 8073661\n",
      "Average episode return: 32.5661\n",
      "Number of training steps: 43687\n",
      "Training speed: 8.0/s\n",
      "Loss: 0.8357\n",
      "\n",
      "Buffer size: 30632\n",
      "Buffer update speed: 14.2/s\n",
      "Number of environment steps: 8091387\n",
      "Average episode return: 31.0826\n",
      "Number of training steps: 43819\n",
      "Training speed: 13.2/s\n",
      "Loss: 0.9561\n",
      "\n",
      "Buffer size: 31393\n",
      "Buffer update speed: 75.9/s\n",
      "Number of environment steps: 8105246\n",
      "Average episode return: 33.7167\n",
      "Number of training steps: 43934\n",
      "Training speed: 11.5/s\n",
      "Loss: 1.0018\n",
      "\n",
      "Buffer size: 32066\n",
      "Buffer update speed: 68.7/s\n",
      "Number of environment steps: 8118755\n",
      "Average episode return: 35.3963\n",
      "Number of training steps: 44019\n",
      "Training speed: 8.5/s\n",
      "Loss: 0.8866\n",
      "\n",
      "Buffer size: 31608\n",
      "Buffer update speed: -46.8/s\n",
      "Number of environment steps: 8135261\n",
      "Average episode return: 37.9630\n",
      "Number of training steps: 44119\n",
      "Training speed: 10.0/s\n",
      "Loss: 0.8185\n",
      "\n",
      "Buffer size: 31255\n",
      "Buffer update speed: -39.8/s\n",
      "Number of environment steps: 8151048\n",
      "Average episode return: 39.5675\n",
      "Number of training steps: 44212\n",
      "Training speed: 9.3/s\n",
      "Loss: 0.7660\n",
      "\n",
      "Buffer size: 31395\n",
      "Buffer update speed: 16.9/s\n",
      "Number of environment steps: 8161893\n",
      "Average episode return: 38.8669\n",
      "Number of training steps: 44249\n",
      "Training speed: 3.7/s\n",
      "Loss: 0.6917\n",
      "\n",
      "Buffer size: 31381\n",
      "Buffer update speed: -1.2/s\n",
      "Number of environment steps: 8178310\n",
      "Average episode return: 38.6986\n",
      "Number of training steps: 44353\n",
      "Training speed: 10.4/s\n",
      "Loss: 0.7459\n",
      "\n",
      "Buffer size: 31882\n",
      "Buffer update speed: 51.6/s\n",
      "Number of environment steps: 8191894\n",
      "Average episode return: 37.3840\n",
      "Number of training steps: 44434\n",
      "Training speed: 8.1/s\n",
      "Loss: 0.7647\n",
      "\n",
      "Buffer size: 31975\n",
      "Buffer update speed: 17.9/s\n",
      "Number of environment steps: 8206284\n",
      "Average episode return: 38.8595\n",
      "Number of training steps: 44526\n",
      "Training speed: 9.1/s\n",
      "Loss: 0.7722\n",
      "\n",
      "Buffer size: 31847\n",
      "Buffer update speed: -20.1/s\n",
      "Number of environment steps: 8219852\n",
      "Average episode return: 38.9799\n",
      "Number of training steps: 44598\n",
      "Training speed: 7.2/s\n",
      "Loss: 0.8018\n",
      "\n",
      "Buffer size: 31929\n",
      "\n",
      "Buffer update speed: 8.1/sNumber of environment steps: 8233794\n",
      "Average episode return: 40.3947\n",
      "Number of training steps: 44645\n",
      "Training speed: 4.7/s\n",
      "Loss: 0.7850\n",
      "\n",
      "Buffer size: 32066\n",
      "Buffer update speed: 12.1/s\n",
      "Number of environment steps: 8250151\n",
      "Average episode return: 38.7358\n",
      "Number of training steps: 44724\n",
      "Training speed: 7.5/s\n",
      "Loss: 0.7987\n",
      "\n",
      "Buffer size: 32123\n",
      "Buffer update speed: 7.3/s\n",
      "Number of environment steps: 8262196\n",
      "Average episode return: 37.1858\n",
      "Number of training steps: 44802\n",
      "Training speed: 7.8/s\n",
      "Loss: 0.7801\n",
      "\n",
      "Buffer size: 32491\n",
      "Buffer update speed: 40.2/s\n",
      "Number of environment steps: 8274262\n",
      "Average episode return: 38.2803\n",
      "Number of training steps: 44869\n",
      "Training speed: 6.6/s\n",
      "Loss: 0.7920\n",
      "\n",
      "Buffer size: 32092\n",
      "Buffer update speed: -43.3/s\n",
      "Number of environment steps: 8287198\n",
      "Average episode return: 35.6105\n",
      "Number of training steps: 44933\n",
      "Training speed: 6.4/s\n",
      "Loss: 0.8465\n",
      "\n",
      "Buffer size: 32055\n",
      "Buffer update speed: 0.2/s\n",
      "Number of environment steps: 8298271\n",
      "Average episode return: 37.4175\n",
      "Number of training steps: 44998\n",
      "Training speed: 6.5/s\n",
      "Loss: 0.8435\n",
      "\n",
      "Buffer size: 32576\n",
      "Buffer update speed: 51.1/s\n",
      "Number of environment steps: 8312462\n",
      "Average episode return: 37.1417\n",
      "Number of training steps: 45047\n",
      "Training speed: 4.9/s\n",
      "Loss: 0.8226\n",
      "\n",
      "Buffer size: 32534\n",
      "Buffer update speed: -0.2/s\n",
      "Number of environment steps: 8325736\n",
      "Average episode return: 38.6754\n",
      "Number of training steps: 45100\n",
      "Training speed: 5.3/s\n",
      "Loss: 0.7838\n",
      "\n",
      "Buffer size: 32430\n",
      "Buffer update speed: -14.2/s\n",
      "Number of environment steps: 8336983\n",
      "Average episode return: 40.8913\n",
      "Number of training steps: 45183\n",
      "Training speed: 8.3/s\n",
      "Loss: 0.7861\n",
      "\n",
      "Buffer size: 32339\n",
      "Buffer update speed: -12.6/s\n",
      "Number of environment steps: 8349007\n",
      "Average episode return: 41.1399\n",
      "Number of training steps: 45253\n",
      "Training speed: 6.9/s\n",
      "Loss: 0.7564\n",
      "\n",
      "Buffer size: 32457\n",
      "Buffer update speed: 8.6/s\n",
      "Number of environment steps: 8360116\n",
      "Average episode return: 42.1221\n",
      "Number of training steps: 45303\n",
      "Training speed: 5.0/s\n",
      "Loss: 0.7797\n",
      "\n",
      "Buffer size: 32224\n",
      "Buffer update speed: -24.5/s\n",
      "Number of environment steps: 8373786\n",
      "Average episode return: 42.5639\n",
      "Number of training steps: 45397\n",
      "Training speed: 9.2/s\n",
      "Loss: 0.7226\n",
      "\n",
      "Buffer size: 32607\n",
      "Buffer update speed: 39.5/s\n",
      "Number of environment steps: 8386982\n",
      "Average episode return: 42.4740\n",
      "Number of training steps: 45475\n",
      "Training speed: 7.8/s\n",
      "Loss: 0.6932\n",
      "\n",
      "Buffer size: 32428\n",
      "Buffer update speed: -14.5/s\n",
      "Number of environment steps: 8399023\n",
      "Average episode return: 39.3497\n",
      "Number of training steps: 45565\n",
      "Training speed: 9.0/s\n",
      "Loss: 0.7609\n",
      "\n",
      "Buffer size: 32029\n",
      "Buffer update speed: -41.5/s\n",
      "Number of environment steps: 8415109\n",
      "Average episode return: 39.7956\n",
      "Number of training steps: 45672\n",
      "Training speed: 10.9/s\n",
      "Loss: 0.8183\n",
      "\n",
      "Buffer size: 32152\n",
      "Buffer update speed: 12.3/s\n",
      "Number of environment steps: 8426662\n",
      "Average episode return: 35.2862\n",
      "Number of training steps: 45758\n",
      "Training speed: 8.4/s\n",
      "Loss: 0.8551\n",
      "\n",
      "Buffer size: 32431\n",
      "Buffer update speed: 33.2/s\n",
      "Number of environment steps: 8442312\n",
      "Average episode return: 38.1171\n",
      "Number of training steps: 45847\n",
      "Training speed: 8.9/s\n",
      "Loss: 0.8418\n",
      "\n",
      "Buffer size: 32352\n",
      "Buffer update speed: -10.9/s\n",
      "Number of environment steps: 8458718\n",
      "Average episode return: 39.0214\n",
      "Number of training steps: 45922\n",
      "Training speed: 7.5/s\n",
      "Loss: 0.8512\n",
      "\n",
      "Buffer size: 32138\n",
      "Buffer update speed: -24.3/s\n",
      "Number of environment steps: 8472569\n",
      "Average episode return: 38.8459\n",
      "Number of training steps: 45983\n",
      "Training speed: 6.1/s\n",
      "Loss: 0.8242\n",
      "\n",
      "Buffer size: 31641\n",
      "Buffer update speed: -47.9/s\n",
      "Number of environment steps: 8484583\n",
      "Average episode return: 39.5182\n",
      "Number of training steps: 46040\n",
      "Training speed: 5.7/s\n",
      "Loss: 0.7213\n",
      "\n",
      "Buffer size: 31866\n",
      "Buffer update speed: 21.6/s\n",
      "Number of environment steps: 8500332\n",
      "Average episode return: 38.0411\n",
      "Number of training steps: 46136\n",
      "Training speed: 9.6/s\n",
      "Loss: 0.7946\n",
      "\n",
      "Buffer size: 32188\n",
      "Buffer update speed: 32.9/s\n",
      "\n",
      "Number of environment steps: 8512881Average episode return: 36.2688\n",
      "Number of training steps: 46223\n",
      "Training speed: 8.5/s\n",
      "Loss: 0.7312\n",
      "\n",
      "Buffer size: 31978\n",
      "Buffer update speed: -23.5/s\n",
      "Number of environment steps: 8525659\n",
      "Average episode return: 35.0467\n",
      "Number of training steps: 46268\n",
      "Training speed: 4.5/s\n",
      "Loss: 0.8213\n",
      "\n",
      "Buffer size: 32237\n",
      "Buffer update speed: 25.9/s\n",
      "Number of environment steps: 8537821\n",
      "Average episode return: 35.9583\n",
      "Number of training steps: 46329\n",
      "Training speed: 6.1/s\n",
      "Loss: 0.7928\n",
      "\n",
      "Buffer size: 32165\n",
      "Buffer update speed: -8.3/s\n",
      "Number of environment steps: 8548604\n",
      "Average episode return: 37.0651\n",
      "Number of training steps: 46388\n",
      "Training speed: 5.9/s\n",
      "Loss: 0.8761\n",
      "\n",
      "Buffer size: 32052\n",
      "Buffer update speed: -10.2/s\n",
      "Number of environment steps: 8562050\n",
      "Average episode return: 35.7719\n",
      "Number of training steps: 46480\n",
      "Training speed: 9.1/s\n",
      "Loss: 0.8099\n",
      "\n",
      "Buffer size: 31541\n",
      "Buffer update speed: -54.0/s\n",
      "Number of environment steps: 8579408\n",
      "Average episode return: 34.0884\n",
      "Number of training steps: 46594\n",
      "Training speed: 11.4/s\n",
      "Loss: 0.8145\n",
      "\n",
      "Buffer size: 31325\n",
      "Buffer update speed: -18.6/s\n",
      "Number of environment steps: 8593147\n",
      "Average episode return: 32.9903\n",
      "Number of training steps: 46658\n",
      "Training speed: 6.4/s\n",
      "Loss: 0.8709\n",
      "\n",
      "Buffer size: 30799\n",
      "Buffer update speed: -56.6/s\n",
      "Number of environment steps: 8608762\n",
      "Average episode return: 32.9221\n",
      "Number of training steps: 46723\n",
      "Training speed: 6.5/s\n",
      "\n",
      "Loss: 0.8543\n",
      "Buffer size: 30350\n",
      "Buffer update speed: -44.9/s\n",
      "Number of environment steps: 8621912\n",
      "Average episode return: 32.7930\n",
      "Number of training steps: 46793\n",
      "Training speed: 7.0/s\n",
      "Loss: 0.8125\n",
      "\n",
      "Buffer size: 30380\n",
      "Buffer update speed: -1.0/s\n",
      "Number of environment steps: 8641620\n",
      "Average episode return: 33.0050\n",
      "Number of training steps: 46874\n",
      "Training speed: 8.1/s\n",
      "Loss: 0.8731\n",
      "\n",
      "Buffer size: 30452\n",
      "Buffer update speed: 11.2/s\n",
      "Number of environment steps: 8655736\n",
      "Average episode return: 30.7538\n",
      "Number of training steps: 46978\n",
      "Training speed: 10.4/s\n",
      "Loss: 0.9487\n",
      "\n",
      "Buffer size: 30347\n",
      "Buffer update speed: -11.1/s\n",
      "Number of environment steps: 8668689\n",
      "Average episode return: 29.6636\n",
      "Number of training steps: 47053\n",
      "Training speed: 7.5/s\n",
      "Loss: 0.9151\n",
      "\n",
      "Buffer size: 30665\n",
      "Buffer update speed: 34.5/s\n",
      "Number of environment steps: 8680659\n",
      "Average episode return: 32.0647\n",
      "Number of training steps: 47115\n",
      "Training speed: 6.2/s\n",
      "Loss: 0.9041\n",
      "\n",
      "Buffer size: 31416\n",
      "Buffer update speed: 74.7/s\n",
      "Number of environment steps: 8696002\n",
      "Average episode return: 34.8141\n",
      "Number of training steps: 47219\n",
      "Training speed: 10.4/s\n",
      "Loss: 0.8817\n",
      "\n",
      "Buffer size: 31921\n",
      "Buffer update speed: 50.4/s\n",
      "Number of environment steps: 8707255\n",
      "Average episode return: 35.0248\n",
      "Number of training steps: 47274\n",
      "Training speed: 5.3/s\n",
      "Loss: 0.7944\n",
      "\n",
      "Buffer size: 31782\n",
      "Buffer update speed: -20.2/s\n",
      "Number of environment steps: 8719115\n",
      "Average episode return: 33.9914\n",
      "Number of training steps: 47366\n",
      "Training speed: 9.2/s\n",
      "Loss: 0.7743\n",
      "\n",
      "Buffer size: 31335\n",
      "Buffer update speed: -43.1/s\n",
      "Number of environment steps: 8737117\n",
      "Average episode return: 32.8761\n",
      "Number of training steps: 47471\n",
      "Training speed: 10.5/s\n",
      "Loss: 0.8224\n",
      "\n",
      "Buffer size: 31329\n",
      "Buffer update speed: 0.5/s\n",
      "Number of environment steps: 8750935\n",
      "Average episode return: 33.3114\n",
      "Number of training steps: 47519\n",
      "Training speed: 4.8/s\n",
      "Loss: 0.7659\n",
      "\n",
      "Buffer size: 31322\n",
      "Buffer update speed: -2.1/s\n",
      "Number of environment steps: 8763513\n",
      "Average episode return: 31.7619\n",
      "Number of training steps: 47559\n",
      "Training speed: 4.0/s\n",
      "Loss: 0.8058\n",
      "\n",
      "Buffer size: 30817\n",
      "Buffer update speed: -47.0/s\n",
      "Number of environment steps: 8774210\n",
      "Average episode return: 32.3884\n",
      "Number of training steps: 47622\n",
      "Training speed: 6.3/s\n",
      "Loss: 0.8360\n",
      "\n",
      "Buffer size: 30842\n",
      "Buffer update speed: -2.2/s\n",
      "Number of environment steps: 8786691\n",
      "Average episode return: 35.0140\n",
      "Number of training steps: 47690\n",
      "Training speed: 6.7/s\n",
      "Loss: 0.8688\n",
      "\n",
      "Buffer size: 30961\n",
      "Buffer update speed: 16.1/s\n",
      "Number of environment steps: 8799366\n",
      "Average episode return: 34.1613\n",
      "Number of training steps: 47739\n",
      "Training speed: 4.9/s\n",
      "Loss: 0.7693\n",
      "\n",
      "Buffer size: 30929\n",
      "Buffer update speed: -3.2/s\n",
      "Number of environment steps: 8810015\n",
      "Average episode return: 34.4401\n",
      "Number of training steps: 47784\n",
      "Training speed: 4.5/s\n",
      "Loss: 0.7360\n",
      "\n",
      "Buffer size: 30986\n",
      "Buffer update speed: 0.4/s\n",
      "Number of environment steps: 8821404\n",
      "Average episode return: 38.6610\n",
      "Number of training steps: 47884\n",
      "Training speed: 10.0/s\n",
      "Loss: 0.7753\n",
      "\n",
      "Buffer size: 31046\n",
      "Buffer update speed: 7.8/s\n",
      "Number of environment steps: 8835022\n",
      "Average episode return: 36.5645\n",
      "Number of training steps: 47979\n",
      "Training speed: 9.5/s\n",
      "Loss: 0.7402\n",
      "\n",
      "Buffer size: 31108\n",
      "Buffer update speed: 11.2/s\n",
      "Number of environment steps: 8847181\n",
      "Average episode return: 34.0141\n",
      "Number of training steps: 48071\n",
      "Training speed: 9.2/s\n",
      "Loss: 0.7638\n",
      "\n",
      "Buffer size: 31337\n",
      "Buffer update speed: 22.9/s\n",
      "Number of environment steps: 8860258\n",
      "Average episode return: 33.2259\n",
      "Number of training steps: 48144\n",
      "Training speed: 7.3/s\n",
      "Loss: 0.8086\n",
      "\n",
      "Buffer size: 31728\n",
      "Buffer update speed: 37.6/s\n",
      "Number of environment steps: 8871861\n",
      "Average episode return: 33.0142\n",
      "Number of training steps: 48182\n",
      "Training speed: 3.8/s\n",
      "Loss: 0.8531\n",
      "\n",
      "Buffer size: 32001\n",
      "Buffer update speed: 27.3/s\n",
      "Number of environment steps: 8883994\n",
      "Average episode return: 33.2775\n",
      "Number of training steps: 48223\n",
      "Training speed: 4.1/s\n",
      "Loss: 0.8455\n",
      "\n",
      "Buffer size: 31586\n",
      "Buffer update speed: -45.6/s\n",
      "Number of environment steps: 8897684\n",
      "Average episode return: 31.3204\n",
      "Number of training steps: 48295\n",
      "Training speed: 7.2/s\n",
      "Loss: 0.8489\n",
      "\n",
      "Buffer size: 31110\n",
      "Buffer update speed: -47.2/s\n",
      "Number of environment steps: 8913278\n",
      "Average episode return: 31.9236\n",
      "Number of training steps: 48370\n",
      "Training speed: 7.4/s\n",
      "Loss: 0.8506\n",
      "\n",
      "Buffer size: 31237\n",
      "Buffer update speed: 12.8/s\n",
      "Number of environment steps: 8928909\n",
      "Average episode return: 32.5396\n",
      "Number of training steps: 48497\n",
      "Training speed: 12.4/s\n",
      "Loss: 0.9207\n",
      "\n",
      "Buffer size: 31943\n",
      "Buffer update speed: 67.1/s\n",
      "Number of environment steps: 8942907\n",
      "Average episode return: 33.6442\n",
      "Number of training steps: 48566\n",
      "Training speed: 6.9/s\n",
      "Loss: 0.8555\n",
      "\n",
      "Buffer size: 32652\n",
      "Buffer update speed: 70.9/s\n",
      "Number of environment steps: 8958284\n",
      "Average episode return: 34.5724\n",
      "Number of training steps: 48637\n",
      "Training speed: 6.9/s\n",
      "Loss: 0.9443\n",
      "\n",
      "Buffer size: 32461\n",
      "Buffer update speed: -19.0/s\n",
      "Number of environment steps: 8969805\n",
      "Average episode return: 36.0156\n",
      "Number of training steps: 48704\n",
      "Training speed: 6.7/s\n",
      "Loss: 0.8944\n",
      "\n",
      "Buffer size: 32330\n",
      "Buffer update speed: -13.1/s\n",
      "Number of environment steps: 8983889\n",
      "Average episode return: 36.9659\n",
      "Number of training steps: 48789\n",
      "Training speed: 8.5/s\n",
      "Loss: 0.9205\n",
      "\n",
      "Buffer size: 32514\n",
      "Buffer update speed: 19.2/s\n",
      "Number of environment steps: 8997166\n",
      "Average episode return: 37.4000\n",
      "Number of training steps: 48838\n",
      "Training speed: 5.0/s\n",
      "Loss: 0.8533\n",
      "\n",
      "Buffer size: 32754\n",
      "Buffer update speed: 23.2/s\n",
      "Number of environment steps: 9014285\n",
      "Average episode return: 35.2137\n",
      "Number of training steps: 48907\n",
      "Training speed: 6.8/s\n",
      "Loss: 0.8672\n",
      "\n",
      "Buffer size: 32905\n",
      "Buffer update speed: 14.1/s\n",
      "Number of environment steps: 9028947\n",
      "Average episode return: 35.2428\n",
      "Number of training steps: 48966\n",
      "Training speed: 5.9/s\n",
      "Loss: 0.8996\n",
      "\n",
      "Buffer size: 32938\n",
      "Buffer update speed: 2.3/s\n",
      "Number of environment steps: 9042917\n",
      "Average episode return: 37.9233\n",
      "Number of training steps: 49079\n",
      "Training speed: 11.3/s\n",
      "Loss: 0.9293\n",
      "\n",
      "Buffer size: 32724\n",
      "Buffer update speed: -16.1/s\n",
      "Number of environment steps: 9053989\n",
      "Average episode return: 42.3460\n",
      "Number of training steps: 49123\n",
      "Training speed: 4.4/s\n",
      "Loss: 0.9163\n",
      "\n",
      "Buffer size: 32868\n",
      "Buffer update speed: 14.4/s\n",
      "Number of environment steps: 9067612\n",
      "Average episode return: 46.4536\n",
      "Number of training steps: 49211\n",
      "Training speed: 8.8/s\n",
      "Loss: 0.8245\n",
      "\n",
      "Buffer size: 33071\n",
      "Buffer update speed: 23.5/s\n",
      "Number of environment steps: 9082017\n",
      "Average episode return: 44.6118\n",
      "Number of training steps: 49296\n",
      "Training speed: 8.5/s\n",
      "Loss: 0.8030\n",
      "\n",
      "Buffer size: 33195\n",
      "Buffer update speed: 9.2/s\n",
      "Number of environment steps: 9096345\n",
      "Average episode return: 43.7933\n",
      "Number of training steps: 49397\n",
      "Training speed: 10.1/s\n",
      "Loss: 0.7832\n",
      "\n",
      "Buffer size: 32776\n",
      "Buffer update speed: -41.9/s\n",
      "Number of environment steps: 9112463\n",
      "Average episode return: 43.5718\n",
      "Number of training steps: 49454\n",
      "Training speed: 5.7/s\n",
      "Loss: 0.8047\n",
      "\n",
      "Buffer size: 32810\n",
      "Buffer update speed: 5.2/s\n",
      "Number of environment steps: 9128964\n",
      "Average episode return: 42.3660\n",
      "Number of training steps: 49527\n",
      "Training speed: 6.9/s\n",
      "Loss: 0.7830\n",
      "\n",
      "Buffer size: 33172\n",
      "Buffer update speed: 39.0/s\n",
      "Number of environment steps: 9140118\n",
      "Average episode return: 39.7419\n",
      "Number of training steps: 49577\n",
      "Training speed: 5.0/s\n",
      "Loss: 0.7846\n",
      "\n",
      "Buffer size: 32777\n",
      "Buffer update speed: -50.4/s\n",
      "Number of environment steps: 9157119\n",
      "Average episode return: 40.0962\n",
      "Number of training steps: 49708\n",
      "Training speed: 13.2/s\n",
      "Loss: 0.8158\n",
      "\n",
      "Buffer size: 32512\n",
      "Buffer update speed: -26.4/s\n",
      "Number of environment steps: 9169914\n",
      "Average episode return: 39.2485\n",
      "Number of training steps: 49768\n",
      "Training speed: 6.0/s\n",
      "Loss: 0.7778\n",
      "\n",
      "Buffer size: 32909\n",
      "Buffer update speed: 41.8/s\n",
      "Number of environment steps: 9182654\n",
      "Average episode return: 36.9096\n",
      "Number of training steps: 49831\n",
      "Training speed: 6.2/s\n",
      "Loss: 0.8433\n",
      "\n",
      "Buffer size: 32945\n",
      "Buffer update speed: 5.6/s\n",
      "Number of environment steps: 9193560\n",
      "Average episode return: 37.8754\n",
      "Number of training steps: 49912\n",
      "Training speed: 8.1/s\n",
      "Loss: 0.8107\n",
      "\n",
      "Buffer size: 32346\n",
      "Buffer update speed: -62.3/s\n",
      "Number of environment steps: 9206516\n",
      "Average episode return: 37.3217\n",
      "Number of training steps: 49982\n",
      "Training speed: 6.9/s\n",
      "Loss: 0.8247\n",
      "\n",
      "Buffer size: 32071\n",
      "Buffer update speed: -27.4/s\n",
      "Number of environment steps: 9221957\n",
      "Average episode return: 37.7585\n",
      "Number of training steps: 50000\n",
      "Training speed: 1.7/s\n",
      "Loss: 0.8165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "env = create_env(game_name)\n",
    "n_observations = env.observation_space.shape[0]\n",
    "n_actions = env.action_space.n\n",
    "env.close()\n",
    "\n",
    "model = Network(n_observations, n_actions)\n",
    "model.share_memory()\n",
    "sample_queue_list = [mp.Queue() for _ in range(num_actors)]\n",
    "batch_queue = mp.Queue(num_actors)\n",
    "priority_queue = mp.Queue(num_actors)\n",
    "\n",
    "buffer = ReplayBuffer(sample_queue_list, batch_queue, priority_queue)\n",
    "learner = Learner(batch_queue, priority_queue, model)\n",
    "actors = [Actor(get_epsilon(i), model, sample_queue_list[i]) for i in range(num_actors)]\n",
    "\n",
    "actor_procs = [mp.Process(target=actor.run) for actor in actors]\n",
    "for proc in actor_procs:\n",
    "    proc.start()\n",
    "\n",
    "buffer_proc = mp.Process(target=buffer.run)\n",
    "buffer_proc.start()\n",
    "\n",
    "learner.run()\n",
    "\n",
    "buffer_proc.join()\n",
    "\n",
    "for proc in actor_procs:\n",
    "    proc.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dddba3",
   "metadata": {},
   "source": [
    "### 3h training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f45d632",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a15ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3264dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: RuntimeWarning: Your system is avx2 capable but pygame was not built with support for it. The performance of some of your blits could be adversely affected. Consider enabling compile time detection with environment variables like PYGAME_DETECT_AVX2=1 if you are compiling without cross compilation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(game_name, render_mode='human')\n",
    "obs, _ = env.reset()\n",
    "state = AgentState(torch.from_numpy(obs).unsqueeze(0), n_actions)\n",
    "done = False\n",
    "total_reward = 0\n",
    "while not done:\n",
    "    with torch.no_grad():\n",
    "        q_value = model(state)\n",
    "    action = torch.argmax(q_value, 1).item()\n",
    "    obs, reward, terminated, truncated, _, = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    total_reward += reward\n",
    "    state.update(obs, action, reward)\n",
    "env.close()\n",
    "print(total_reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
